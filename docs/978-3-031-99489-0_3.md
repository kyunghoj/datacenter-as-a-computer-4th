# 3장. WSC 워크로드 개요

## 3.1 WSC 워크로드

### 3.1.1 WSC 시스템 스택

전형적인 WSC(Warehouse-Scale Computer, 웨어하우스 규모 컴퓨터) 배포 환경은 고수준 워크로드 및 애플리케이션 프레임워크부터 클러스터 수준의 모니터링 소프트웨어, 그리고 개발 및 플랫폼 소프트웨어에 이르는 다계층 소프트웨어 스택을 포함합니다. WSC에서 실행되는 애플리케이션과 소프트웨어는 많은 시스템 설계의 트레이드오프 결정을 주도합니다. 이 장과 다음 장에서는 대규모 인터넷 서비스에서 실행되는 소프트웨어의 특징적인 특성 중 일부와 완전한 컴퓨팅 플랫폼을 위해 필요한 시스템 소프트웨어 및 도구에 대해 간략히 설명합니다. 전형적인 WSC 배포 환경의 다양한 소프트웨어 계층은 다음과 같습니다.

*   **애플리케이션 레벨 소프트웨어 (Application-level software)**: 특정 서비스를 구현하는 소프트웨어입니다. 애플리케이션 레벨 소프트웨어는 온라인 서비스와 오프라인 연산으로 나누는 것이 유용한데, 이는 두 가지가 서로 다른 요구 사항을 가지는 경향이 있기 때문입니다. 온라인 서비스의 예로는 Google 검색, Gmail, Google 지도 등이 있습니다. 오프라인 연산은 일반적으로 대규모 데이터 분석이나 온라인 서비스에서 사용되는 데이터를 생성하는 파이프라인의 일부로 사용됩니다. 예를 들어, 웹 인덱스를 구축하거나 온라인 서비스를 위한 지도 타일을 생성하기 위해 위성 이미지를 처리하는 작업 등이 있습니다.
*   **애플리케이션 프레임워크 (Application frameworks)**: 애플리케이션을 더 쉽게 구현할 수 있도록 하는 구성 요소들입니다. 프론트엔드나 이미지 서빙을 위한 서빙 인프라, 사용자 세션 분석 도구, 공통 애플리케이션 요소를 위한 UI 위젯 등이 포함됩니다.
*   **클러스터 인프라 (Cluster infrastructure)**: 자원을 관리하고 클러스터 수준에서 서비스를 제공하는 분산 시스템 소프트웨어의 집합입니다. 궁극적으로 우리는 이러한 서비스들을 데이터 센터를 위한 운영체제로 간주합니다. 그 예로는 분산 파일 시스템, 스케줄러, 원격 프로시저 호출(RPC) 라이브러리, 그리고 MapReduce [1], Hadoop [2], Sawzall [3], BigTable [4], Dynamo [5], Dremel [6], Spanner [7], Chubby [8]와 같이 데이터 센터 규모에서 자원 사용을 단순화하는 프로그래밍 모델이 있습니다.
*   **자원 관리 (Resource management)**: 특정 머신에 컴퓨팅 작업을 스케줄링하고 스토리지 할당량을 강제하는 등 자원을 관리하고 할당하기 위한 인프라입니다(예: Google의 Borg 스케줄러 [9], [10]).
*   **플랫폼 소프트웨어 (Platform software)**: 기본적인 머신 추상화 계층을 제공하기 위해 모든 개별 서버 플랫폼에 존재할 것으로 예상되는 공통 펌웨어, 커널, 운영체제 배포판 및 라이브러리입니다.
*   **하드웨어 (Hardware)**: 서버, 가속기(머신러닝, 비디오), 스토리지 어플라이언스, 네트워크 스위치, 데이터 센터 인프라 등입니다.
*   **도구 (Tools)**: 애플리케이션 성능을 모니터링하고, 시스템 병목 현상을 식별하며, 클러스터의 하드웨어 상태를 측정하는 소프트웨어입니다.

그림 3.1은 이러한 계층들을 요약한 것입니다. 이 장에서는 그림의 상위 두 계층에 초점을 맞출 것입니다. (4장에서는 이 그림의 나머지 구성 요소들에 대해 논의할 것입니다.) 이 책은 WSC에 대해 "내부적 관점(inside view)"을 취하고 있으므로, 위에서 정의한 계층은 인프라, 플랫폼, 애플리케이션을 구분하는 업계에서 흔히 사용되는 분류법[11]과는 다릅니다.

*   **서비스형 인프라 (Infrastructure as a Service, IaaS)**: 소비자가 임의의 소프트웨어를 실행할 수 있도록 처리 능력, 스토리지, 네트워킹을 제공합니다. 소비자는 기본 클라우드 인프라를 관리하거나 제어하지 않지만, 운영체제, 스토리지, 배포된 애플리케이션에 대한 제어권이 있으며, 일부 네트워킹 구성 요소(예: 호스트 방화벽)에 대한 제한적인 제어권을 가질 수 있습니다. 예를 들어, GCP의 IaaS 제품은 GCE[12]로, 다양한 가상 머신과 블록 스토리지 옵션을 제공합니다.
*   **서비스형 플랫폼 (Platform as a Service, PaaS)**: 애플리케이션을 프로비저닝, 인스턴스화, 실행 및 관리하는 도구를 제공하여 개발자와 운영자가 자체 툴체인을 구축해야 하는 부담을 덜어줍니다. 예를 들어, GKE[13]와 Cloud Run[14]은 Kubernetes 클러스터 관리를 자동화하고, Cloud SQL[15]은 완전 관리형 데이터베이스를 제공하며, Terraform[16]과 같은 도구는 표준화된 구성을 가능하게 합니다.
*   **서비스형 소프트웨어 (Software as a Service, SaaS)**: 완전 관리형 애플리케이션을 제공하여 고객이 해당 애플리케이션과 관련된 대부분 또는 모든 운영 작업(예: 설치, 프로비저닝, 업그레이드 등)을 수행할 필요가 없게 합니다. 인터넷 소비자 서비스는 항상 SaaS 서비스였으므로, 이 용어는 주로 엔터프라이즈 소프트웨어를 설명하는 데 사용됩니다. 예를 들어, Google Workspace[17]는 SaaS 애플리케이션입니다.

> **그림 3.1** 웨어하우스 규모 컴퓨터를 위한 Google 소프트웨어 스택

### 3.1.2 컴퓨팅 소비 모델

WSC의 워크로드는 공유(멀티 테넌트) 또는 전용 하드웨어 구성에서 실행될 수 있습니다. 이들은 특정 애플리케이션(Gmail, YouTube, 검색 등)일 수도 있고, 더 광범위한 애플리케이션 프레임워크나 플랫폼(GCE, Spanner, BigTable, VertexAI 등)일 수도 있습니다. 또한 내부적, 전통적, 하이퍼스케일 워크로드일 수도 있고 클라우드 고객에게 제공되는 외부용일 수도 있습니다. 클라우드 내에서 고객 워크로드는 Google Compute Engine(GCE)이나 Google Kubernetes Engine(GKE)과 같은 IaaS 플랫폼에서 실행되거나, 더 높은 수준의 관리형 서비스(예: VertexAI, DataFlow, DataProc, MemoryStore, CloudSQL 등)를 제공할 수 있습니다. 또한, TPU 포드(6장에서 논의됨)와 같은 가속기 플랫폼은 특정 머신러닝 워크로드와 프레임워크를 실행할 수 있으며, 디스크 및 플래시 어플라이언스는 더 전문화된 스토리지 워크로드를 실행할 수 있습니다.

추가로, 워크로드는 서비스 가용성 및 지연 시간(latency) 민감도에 해당하는 서비스 수준 목표(SLO)에 따라 다양한 등급(tier)으로 광범위하게 분류됩니다. 예를 들어, 현재 Google에서는 다음과 같은 워크로드 등급을 사용합니다.

1.  **HALO (High-availability latency optimized)**: 고가용성 지연 시간 최적화. 이 등급은 중단이 발생해서는 안 되며 아주 작은 방해(예: 공유 코어로 인한)조차 허용하지 않는 워크로드를 위한 것으로, 가장 강력한 가용성 SLO를 제공합니다. 전형적인 예로는 GCE VM, 데이터베이스 또는 애플리케이션 프론트엔드가 있습니다.
2.  **HALS (High-availability latency sensitive)**: 고가용성 지연 시간 민감. 이 등급은 HALO와 동일한 가용성을 제공하지만, 성능상의 작은(밀리초 단위) 일시적 문제를 허용할 수 있습니다. 예로는 데이터 웨어하우스 및 스트리밍 데이터 파이프라인이 있습니다.
3.  **HALT (High-availability latency tolerant)**: 고가용성 지연 시간 허용. 이 등급은 HALO와 동일한 가용성을 제공하지만, 몇 분 정도의 지연을 허용할 수 있는 애플리케이션을 위한 것입니다. 중요한 배치(batch) 작업이나 거의 필요하지 않은 용량 예비(capacity reserve)가 그 예입니다.
4.  **MALS/MALT (Mostly-available latency-sensitive/tolerant)**: 대부분 가용 지연 시간 민감/허용. 이 워크로드들은 HA(고가용성) 등급의 비용 최적화 변형으로, 오버서브스크립션(초과 할당, 9장 참조)을 허용하기 위해 용량이 가끔 축소될 수 있습니다. 전형적인 SLO는 "시간의 1% 동안 자원의 최대 10%를 잃을 수 있음"과 같을 수 있습니다.
5.  **WALS/WALT (Weakly-available latency-sensitive/tolerant)**: 약한 가용성 지연 시간 민감/허용. 이 등급은 처리량 보장만 필요한 장기 실행 배치 작업을 위한 것으로, 훨씬 더 완화된 SLO를 제공합니다("하루 동안 요청한 작업 시간의 최소 50%를 받게 됨").
6.  **BE (Best-effort)**: 최선 노력. 이 등급은 무기한 연기될 수 있는 작업을 위한 것으로, 이 등급의 수요에 대해서는 자원이 프로비저닝되지 않습니다. 유휴 자원이 있으면 작업이 실행되지만, 선점(preempted)될 수 있으며 며칠 또는 몇 주 동안 자원을 사용하지 못할 수도 있어 주어진 작업이 실행될 것이라는 보장이 없습니다.

퍼블릭 클라우드는 현재 이러한 등급을 제공하지 않지만, 대부분 선점형 VM(Preemptible VMs) 또는 스팟 VM(Spot VMs)으로 VM에 대한 BE 등급을 제공합니다. 등급을 사용한 용량 관리는 상당한 비용 절감 효과를 제공할 수 있지만 상당한 복잡성을 추가하므로, 클라우드 소비자가 아닌 클라우드 제공업체에 가장 적합합니다.

### 3.1.3 퍼블릭 클라우드 대 하이퍼스케일

WSC는 처음에는 Google 검색, Facebook, YouTube와 같은 데이터 집약적인 온라인 웹 워크로드를 위해 설계되었지만, 현재는 Amazon, Google, Microsoft의 퍼블릭 클라우드도 지원하고 있습니다. 오늘날 퍼블릭 클라우드는 WSC에서 실행되는 가장 큰 워크로드가 되었으며, 퍼블릭 클라우드에 할당된 총 데이터 센터 용량은 프라이빗 하이퍼스케일러 클라우드가 사용하는 총 용량을 크게 넘어섰습니다. 사실 Google과 Meta의 서비스를 제외하면, 가장 인기 있는 소비자 애플리케이션의 거의 대부분이 오늘날 퍼블릭 클라우드에서 실행됩니다.

하이퍼스케일(hyperscale)이라는 용어는 대규모 인프라("하이퍼스케일 데이터 센터")를 나타내는 말로 인기를 얻었습니다. 두 용어는 관련이 있지만 동일하지는 않습니다. 예를 들어, 순수 데이터 센터 제공업체는 WSC와 비슷한 규모의 대규모 데이터 센터를 건설할 수 있지만, 건물 내의 모든 서버를 웨어하우스 규모 컴퓨터로 전환할 수 있는 소프트웨어 스택은 제외하고 건물만 제공할 수 있습니다. 그러나 하이퍼스케일러(hyperscaler)라는 용어는 순수하게 자체 하이퍼스케일 애플리케이션을 위해(Meta) 또는 클라우드 컴퓨팅을 제공하기 위해(AWS, Microsoft) 또는 둘 다를 위해(Google) WSC를 구축하는 회사를 설명하는 데 일반적으로 사용됩니다. 따라서 하이퍼스케일러는 대규모 데이터 센터와 그 위에 구축된 대규모 서비스를 모두 운영하는 회사입니다.

언뜻 보기에 퍼블릭 클라우드 컴퓨팅은 하이퍼스케일 애플리케이션과 매우 달라 보입니다. 후자의 경우 단일 애플리케이션이 수만 대의 서버에서 실행될 수 있는 반면, 퍼블릭 클라우드에서 실행되는 대부분의 엔터프라이즈 애플리케이션은 소수의 서버만 사용합니다. 그러나 WSC 스택의 상당 부분 관점에서 볼 때, 퍼블릭 클라우드는 수만 대의 서버를 소비하는 하나의 거대한 애플리케이션처럼 보입니다. 예를 들어, Google의 인프라 입장에서 GCE(VM을 제공하는 GCP 서비스)는 단일 대규모 애플리케이션처럼 보입니다. Google은 하이퍼스케일 소비자 애플리케이션과 대규모 퍼블릭 클라우드를 모두 보유하고 있다는 점에서 독특하며, 이 장에서는 동일한 인프라가 어떻게 대규모 온라인 내부 서비스와 대규모 퍼블릭 클라우드 제품을 모두 지원할 수 있는지 설명할 것입니다.

## 3.2 하이퍼스케일 애플리케이션

### 3.2.1 포괄적 개요

웹 검색은 광범위한 인기를 얻은 최초의 대규모 인터넷 서비스 중 하나였습니다. 90년대 중반 웹 콘텐츠의 양이 폭발적으로 증가하면서, 이 방대한 양의 정보를 정리하기 위해 당시 존재하지 않았던 새로운 인프라가 필요했습니다. 검색은 전형적인 대규모 처리 과제가 되었습니다. 웹의 성장(모든 웹 페이지를 인덱싱해야 하므로)과 인터넷 사용자의 증가에 맞춰 확장되는 서비스를 어떻게 구축할 것인가?

하지만 꽤 빠르게 이메일, 소셜 네트워크, 스트리밍 비디오, 게임 등 다른 많은 하이퍼스케일 애플리케이션이 등장했습니다. 또한 개별 하이퍼스케일 애플리케이션 자체가 여러 부분으로 구성될 수 있습니다. 예를 들어, 오늘날의 웹 검색에는 이미지 검색, AI 요약, 지도 등이 포함됩니다. 결과적으로 하이퍼스케일 애플리케이션은 단일 워크로드가 아니라 여러 하이퍼스케일 하위 서비스로 구성됩니다. 그림 3.2는 Google 데이터 센터의 워크로드 전반에 걸친 사이클의 누적 분포를 보여줍니다. 상위 50개 바이너리는 전체 WSC 사이클의 약 60%만을 차지하며, 긴 꼬리(long tail)가 나머지 사이클을 차지합니다[18]. 거의 10년 간격으로 분리된 두 추세선은 서비스의 다양성이 꾸준히 증가하고 있음을 보여줍니다.

다양한 서비스의 요구 사항을 감안할 때, 데이터 센터 자체는 범용 컴퓨팅 시스템이어야 합니다. 특수 하드웨어 솔루션이 서비스의 개별 부분에는 적합할 수 있지만, 요구 사항의 폭이 넓기 때문에 범용 시스템 설계에 집중하는 것이 중요합니다. 하드웨어를 지나치게 전문화하는 것에 반대하는 또 다른 요인은 워크로드 변경 속도입니다. 제품 요구 사항은 빠르게 진화하며, 똑똑한 프로그래머들은 경험을 통해 배우고 하드웨어가 진화하는 속도보다 훨씬 빠르게 기본 알고리즘과 데이터 구조를 다시 작성할 것입니다. 따라서 전문화된 솔루션이 구현될 때쯤이면, 하드웨어-소프트웨어 공동 설계에 상당한 초점을 맞춘 분야가 아니라면, 원래 설계된 문제 영역에조차 더 이상 적합하지 않을 상당한 위험이 있습니다. 그렇긴 하지만, 전문화가 상당한 이득을 가져온 경우도 있으며, 이에 대해서는 6장에서 더 자세히 논의할 것입니다.

다음 섹션에서는 웹 검색, 비디오 서빙, 머신러닝, Gmail, 데이터 처리 및 클라우드에 사용되는 워크로드에 대해 설명합니다. 특히 이 시장의 역동적인 특성상 출판 시점에는 내용이 구식이 될 수 있으므로, 이러한 인터넷 서비스 워크로드의 구현을 자세히 설명하지는 않습니다. 그러나 WSC 워크로드의 주요 특징을 설명하고 온라인 서비스의 주요 카테고리와 배치(오프라인) 처리 시스템 간의 차이점을 강조하기 위해 몇 가지 워크로드를 높은 수준에서 설명하는 것은 여전히 유용합니다. 이 논의는 향후 아키텍처 설계 트레이드오프를 위한 무대를 마련할 것입니다.

> **그림 3.2** 2014년과 2024년 WSC 워크로드의 다양성

### 3.2.2 사례 연구: 검색

검색은 전형적인 "건초더미에서 바늘 찾기" 문제입니다. 특정 시점의 웹 크기를 정확하게 파악하기는 어렵지만, 수조 개의 개별 문서로 구성되어 있으며 계속 증가하고 있다고 말해도 무방합니다. 웹이 1,000억 개의 문서를 포함하고 평균 문서 텍스트 크기가 10KB(압축 후)라고 가정하면, 건초더미는 약 1,000TB입니다. (실제로 인덱스는 훨씬 더 큽니다. Google은 공개적으로 수천억 개의 웹페이지를 다루며 크기가 100,000TB를 훨씬 넘는다고 밝혔습니다 [19].) 웹 검색을 위한 데이터베이스는 해당 문서 세트를 역전(inverting)시켜 그림 3.3과 같은 논리적 형식의 저장소를 생성함으로써 구축된 인덱스입니다.

어휘(Lexicon) 구조는 저장소의 모든 용어(term)에 ID를 연결합니다. termID는 해당 용어가 발생하는 문서 목록인 포스팅 리스트(posting list)와 위치 및 다양한 기타 속성(예: 용어가 문서 제목에 있는지 여부)과 같은 맥락 정보를 식별합니다.

결과적으로 생성되는 역인덱스(inverted index)의 크기는 특정 구현에 따라 다르지만, 원본 저장소와 동일한 자릿수(order of magnitude)의 크기를 갖는 경향이 있습니다. 일반적인 검색 쿼리는 일련의 용어로 구성되며, 시스템의 작업은 모든 용어를 포함하는 문서(AND 쿼리)를 찾아내고 사용자에게 만족을 줄 가능성이 가장 높은 문서를 결정하는 것입니다. 쿼리는 선택적으로 대체(OR 연산자)를 나타내거나 특정 순서로 용어가 발생하는 것으로 검색을 제한(구문 연산자)하는 특수 연산자를 포함할 수 있습니다. 간결함을 위해 아래 예제에서는 더 일반적인 AND 쿼리에 집중합니다.

[palo alto library]와 같은 쿼리를 고려해 보십시오. 검색 알고리즘은 세 가지 용어(palo, alto, library)가 모두 포함된 문서를 찾을 때까지 각 용어의 포스팅 리스트를 순회해야 합니다. 또한 언어 모델이 쿼리를 해석하여 이 경우 "palo alto"가 지명임을 발견할 것입니다 [20]. 그런 다음 알고리즘은 문서의 전반적인 중요도(Google의 경우 PageRank 점수[21] 및 문서 내 용어 발생 빈도, 위치 등과 같은 기타 속성)와 같은 다양한 매개변수를 사용하여 찾은 문서의 순위를 매기고 가장 높은 순위의 문서를 사용자에게 반환합니다.

> **그림 3.3** 웹 인덱스의 논리적 뷰

인덱스의 거대한 크기를 감안할 때, 이 검색 알고리즘은 수천 대의 머신에서 실행되어야 할 수 있습니다. 이는 인덱스를 부하가 균형 잡힌 하위 파일로 분할("샤딩")하고 모든 머신에 분산시킴으로써 달성됩니다. 인덱스 파티셔닝은 문서 또는 용어별로 수행할 수 있습니다. 사용자 쿼리는 프론트엔드 웹 서버에서 수신되어 인덱스 클러스터의 모든 머신에 배포됩니다. 처리량이나 내결함성을 위해 필요에 따라 인덱스 하위 파일의 사본을 여러 머신에 배치할 수 있으며, 이 경우 머신의 일부만 주어진 쿼리에 참여합니다. 인덱스 서빙 머신은 로컬 결과를 계산하고 사전 순위를 매긴 다음 최상의 결과를 프론트엔드 시스템(또는 중간 서버)으로 전송하며, 프론트엔드 시스템은 전체 클러스터에서 최상의 결과를 선택합니다. 이 시점에서는 결과 웹 페이지 적중(hit)에 해당하는 doc_ID 목록만 알려져 있습니다. 실제 제목, URL, 그리고 검색어 주변의 맥락을 사용자에게 제공하는 쿼리별 문서 스니펫(snippet)을 계산하기 위해 두 번째 단계가 필요합니다. 이 단계는 문서 자체의 사본을 포함하는 머신 세트에 doc_ID 목록을 전송하여 구현됩니다. 다시 말하지만, 이 크기의 저장소는 파티셔닝(샤딩)되어 많은 수의 서버에 배치되어야 합니다.

위에서 설명한 작업에 대한 총 사용자 체감 지연 시간은 1초 미만이어야 합니다. 따라서 이 아키텍처는 지연 시간 감소에 중점을 둡니다. 그러나 인기 있는 서비스는 초당 수천 개의 쿼리를 지원해야 할 수 있으므로 높은 처리량 또한 핵심 성능 지표입니다. 인덱스는 자주 업데이트되지만 단일 쿼리를 처리하는 세분성(granularity)에서는 읽기 전용 구조로 간주될 수 있습니다. 또한, 최종 병합 단계를 제외하고는 서로 다른 머신에서의 인덱스 조회가 서로 통신할 필요가 없으므로 계산이 매우 효율적으로 병렬화됩니다. 마지막으로, 서로 다른 웹 검색 쿼리 간에 논리적 상호 작용이 없다는 사실을 활용하여 추가적인 병렬 처리가 가능합니다.

인덱스가 doc_ID로 샤딩된 경우, 이 워크로드는 평균 대역폭 측면에서 상대적으로 적은 네트워킹 요구 사항을 갖습니다. 머신 간에 교환되는 데이터의 양은 쿼리 자체의 크기(수백 바이트 정도)보다 크게 크지 않지만, 다소 버스트(bursty)한 동작을 보입니다. 기본적으로 프론트엔드의 서버는 단일 쿼리를 매우 많은 수의 서버에 분배하므로 트래픽 증폭기 역할을 합니다. 이는 요청 경로뿐만 아니라 응답 경로에서도 트래픽 폭주를 일으킬 수 있습니다. 따라서 전체 네트워크 사용률이 낮더라도 혼잡을 최소화하기 위해 네트워크 흐름을 신중하게 관리해야 합니다.

마지막으로, 웹 검색은 온라인 서비스이므로 사용자가 하루 중 다른 시간에 웹에서 더 활동적이기 때문에 정상적인 트래픽 변동을 겪습니다. 그림 3.4는 이러한 효과를 보여주며, 피크 사용 시간대의 트래픽이 비수기보다 5배 높을 수 있음을 보여줍니다. 이러한 가변성은 서비스가 평균 트래픽이 아닌 피크 트래픽에 맞춰 크기를 조정해야 하므로 시스템 운영자에게 과제를 제시합니다.

> **그림 3.4** 한 데이터 센터의 검색 서비스 일일 트래픽

글로벌 로드 밸런싱은 프로비저닝에 도움이 될 수 있습니다. 그림 3.4는 미국의 일반적인 클러스터에서의 대화형 검색 트래픽을 보여줍니다. 이 클러스터는 북미 지역의 사용자 수요에 비례하여 트래픽을 수신합니다. 14:00 PST(5pm EDT)의 작은 하락은 퇴근 시간 동안 검색이 줄어든 것입니다. 새벽 2시의 큰 하락은 북미 대부분(전부는 아님)이 잠을 자는 시간입니다. 피크 시간대에는 로드 밸런서가 지연 시간을 기준으로 여러 데이터 센터 간의 트래픽 분배를 미세 조정하므로 트래픽 수준이 진동합니다.

### 3.2.3 사례 연구: YouTube

IP 비디오 트래픽은 전 세계 인터넷 트래픽의 75–85%를 차지합니다. YouTube에서 사용자는 분당 수백 시간 분량의 비디오를 업로드하고 매일 수십억 시간의 YouTube 비디오를 시청합니다. 비디오 트랜스코딩(한 형식의 비디오를 디코딩하고 다른 형식으로 인코딩하는 것)은 모든 비디오 공유 인프라의 중요한 부분입니다. 비디오는 형식, 코덱, 해상도, 프레임 속도, 색 공간 등의 수많은 조합으로 업로드됩니다. 이러한 비디오는 클라이언트 장치가 재생할 수 있는 코덱, 해상도 및 형식의 하위 집합으로 변환되어야 하며, 사용자 경험을 최적화하기 위해 사용 가능한 네트워크 대역폭에 맞춰 조정되어야 합니다.

비디오 서빙에는 세 가지 주요 비용 구성 요소가 있습니다: 비디오 트랜스코딩으로 인한 컴퓨팅 비용, 비디오 카탈로그(원본 및 트랜스코딩된 버전 모두)에 대한 스토리지 비용, 트랜스코딩된 비디오를 최종 사용자에게 전송하는 네트워크 이그레스(egress) 비용입니다. 비디오 압축 코덱의 개선은 스토리지 및 이그레스 비용을 개선하지만 더 높은 컴퓨팅 비용을 희생합니다. YouTube 비디오 처리 파이프라인은 비디오의 인기 프로필을 기반으로 이 세 가지 요소의 균형을 맞추며, 매우 인기 있는 비디오를 압축하는 데에만 추가적인 노력을 투자합니다. 아래에서는 주문형 비디오(VOD)가 어떻게 작동하는지 설명합니다. 즉석 트랜스코딩이나 라이브 비디오 스트리밍과 같은 다른 비디오 서빙 사용 사례는 높은 수준에서는 유사하지만 최적화되는 목적 함수가 달라 다른 아키텍처로 이어집니다.

YouTube에 업로드된 모든 비디오는 먼저 원래 업로드 형식에서 임시 고품질 공통 중간 형식으로 트랜스코딩[22]되어 나머지 파이프라인에서 균일한 처리가 가능하도록 합니다(그림 3.5). 그런 다음 비디오는 세그먼트로 나뉘어 여러 출력 해상도와 코덱으로 트랜스코딩되므로, 사용자가 비디오를 요청할 때 사용 가능한 네트워크 대역폭과 플레이어 장치의 기능을 스트리밍할 비디오 청크의 최적 버전과 일치시킬 수 있습니다. 비디오 청크는 여러 머신에 분산되어 각 비디오 세그먼트를 여러 형식으로 트랜스코딩하는 작업을 병렬화하고 처리량과 지연 시간을 모두 최적화합니다. 마지막으로, 비디오가 매우 인기 있는 것으로 식별되면 두 번째 비디오 트랜스코딩 패스를 거치게 되며, 여기서 동일한 지각 품질에서 더 작은 비디오를 생성하기 위해 추가적인 컴퓨팅 노력이 투자됩니다. 이를 통해 사용자는 동일한 네트워크 대역폭에서 더 높은 해상도의 비디오 버전을 얻을 수 있으며, 더 높은 컴퓨팅 비용은 많은 재생 횟수에 따른 이그레스 절감으로 상쇄됩니다.

비디오 청크가 데이터 센터에서 재생 준비된 형식으로 트랜스코딩되면, 가장 최근에 시청한 비디오를 캐시하는 엣지(Edge) 네트워크를 통해 배포됩니다.

> **그림 3.5** YouTube 비디오 처리 파이프라인

이는 지연 시간을 최소화하고 이그레스 대역폭을 증폭시키기 위함입니다. 사용자가 엣지 캐시에서 즉시 사용할 수 없는 비디오를 요청하면, 요청은 가장 가까운 데이터 센터나 피어 엣지 위치로 전달되고 요청된 비디오는 카탈로그에서 업로드됩니다.

### 3.2.4 사례 연구: Gmail

Gmail은 대규모 이메일 서비스입니다. 수십억 개의 활성 계정을 보유하고 있어 Gmail의 이메일 수는 웹 페이지 수와 동일한 자릿수(order of magnitude)입니다. Gmail의 기능에는 분명한 것(이메일 송수신)뿐만 아니라 스팸, 피싱 및 멀웨어로부터의 보호, 이메일 자동 분류 및 카테고리화, 이메일에 대한 빠른 검색, 사용자가 이메일을 작성하고 응답하는 것을 돕는 AI 도구와 같은 다른 많은 기능이 포함됩니다. Gmail은 단일 데이터 센터에서 지연 시간과 신뢰성을 갖추고 이 규모의 데이터를 제공할 수 없으므로, 결과적으로 Gmail은 전 세계적으로 분산된 시스템입니다.

기능의 병렬적이고 독립적인 개발을 가능하게 하기 위해 Gmail은 많은 구성 요소를 가지고 있으며, 각 구성 요소는 별도의 팀이 소유합니다. 총체적으로 이러한 구성 요소들은 Gmail의 많은 기능을 구현합니다. 이 구성 요소들은 크게 두 가지 범주로 나뉩니다: (i) 비즈니스 로직을 구현하고 영구 상태가 없는 애플리케이션 구성 요소; (ii) 데이터를 내구성 있게 일관되게 저장하는 책임을 지는 스토리지 구성 요소. Gmail은 두 가지 주요 스토리지 시스템을 사용합니다: Spanner는 이메일, 인덱스 및 메타데이터를 저장하고, Blobstore(GCS 또는 S3와 유사한 API)는 첨부 파일(이미지, 비디오 등)을 저장합니다. Gmail은 데이터 종류에 따라 요구 사항이 다르기 때문에 여러 스토리지 시스템이 필요합니다. Spanner는 세분화된 단위로 변경 가능한 데이터(예: 이메일 라벨 변경)를 저장하는 반면, Blobstore는 Gmail이 하나의 단위로 읽고 쓰는 "바이트 가방(bags of bytes)"을 저장합니다. 나쁜 Spanner 이벤트(예: 루트 테이블 손상)가 광범위한 비가용성을 유발하지 않도록 하기 위해, Gmail은 사용자를 100개 이상의 Spanner 데이터베이스에 분할하며 어떤 중요한 작업도 둘 이상의 데이터베이스를 수정할 수 없습니다. 스토리지 시스템에 관계없이 모든 데이터는 유휴 상태(at rest)와 전송 중(in flight)일 때 암호화됩니다.

대부분의 Gmail 요청은 애플리케이션과 스토리지 구성 요소 간의 여러 번의 왕복을 수반합니다. 예를 들어, 사용자가 이메일을 열면 Gmail은 먼저 사용자 계정이 침해되었는지 확인하기 위해 신호를 읽고, 그 다음 첨부 파일을 포함한 이메일 내용을 읽고, 스토리지를 업데이트하여 해당 이메일을 읽은 상태로 표시한 다음, 마지막으로 사용자가 이미 읽은(또는 읽지 않은) 메시지를 쉽게 검색할 수 있도록 인덱스를 업데이트합니다. 결과적으로 모든 사용자 요청은 전이적으로 수백 개의 RPC(원격 프로시저 호출)를 발생시키므로 모든 요청은 롱테일(long-tail) 동작과 씨름해야 합니다. 사용자 요청당 수백 개의 RPC가 있는 경우, 균일한 실패 확률을 가정할 때 사용자 요청의 절반 이상이 100번에 1번 발생하는 실패 이벤트의 영향을 받게 됩니다. 15억 개 이상의 계정과 곱해지면 매우 낮은 확률의 문제조차도 다반사가 됩니다. 따라서 높은 지연 시간이나 사용자 비가용성을 유발하지 않도록 이벤트를 처리하는 것이 Gmail 설계의 핵심입니다.

사용자 요청을 충족하기 위해 Gmail이 발행하는 RPC의 지연 시간 오버헤드를 최소화하기 위해 Gmail은 애플리케이션과 스토리지 시스템을 코로케이션(colocate)합니다. 데이터 센터의 구성 요소는 주로 동일한 데이터 센터의 다른 구성 요소와 통신합니다. 이는 지연 시간에 도움이 될 뿐만 아니라(예: RPC가 모두 동일한 데이터 센터 내에 있으며 데이터 센터 내 캐시를 사용할 수 있음) 신뢰성에도 도움이 됩니다. 예를 들어 셀(cell)에 있는 구성 요소의 잘못된 푸시는 해당 셀의 트래픽에만 영향을 미치므로 문제의 폭발 반경(blast radius)을 제한합니다.

고가용성을 보장하기 위해 Gmail은 Spanner를 사용하여 각 사용자의 데이터를 3개의 데이터 센터에 일관되게 복제합니다. Gmail 사용자는 일관된 읽기(consistent reads)를 기대합니다. 예를 들어, 메시지에 라벨을 적용한 후 사용자는 해당 라벨이 있는 메시지에 대한 후속 검색에 해당 메시지가 포함될 것으로 기대합니다. Spanner는 일관된 읽기를 지원하지만 사용자에 대한 최신 상태를 항상 보유하고 있는 Paxos 리더[23]로 가지 않으면 비용이 많이 들 수 있습니다. 이러한 지연을 피하기 위해 Gmail과 Spanner는 사용자 계정에 대한 Spanner 리더를 선택하도록 조정합니다. 사용자의 모든 요청은 이 리더를 제공하는 데이터 센터로 라우팅되므로 이 데이터 센터는 사용자의 "주(primary)" 데이터 센터가 됩니다. 이 데이터 센터를 사용할 수 없게 되면 Gmail은 사용자 데이터의 복제본이 있는 다른 데이터 센터 중 하나를 사용자의 주 데이터 센터로 선택하는 프로토콜을 시작합니다.

Gmail은 또한 Blobstore를 사용하여 사용자의 첨부 파일을 여러 위치에 복제합니다. 첨부 파일은 읽기 전용이며 부분 변경을 지원하지 않으므로, 첨부 파일 복제는 Spanner의 Paxos 구현과 대조적으로 더 간단하고(저렴한) 백그라운드 복제 메커니즘을 사용합니다.

ISP가 불안정할 때도 사용자에게 고가용성을 제공하기 위해 Gmail 클라이언트는 최근 이메일을 동기화하고 적용되지 않은 변경 사항(예: 이메일 전송)을 사용자 기기에 기록합니다. 클라이언트가 서버에 연결되면 Gmail은 이러한 변경 사항을 트랜잭션 방식으로 적용합니다. 이는 또한 일부 트랜잭션을 크리티컬 패스(critical path)에서 제거하므로 클라이언트가 체감하는 지연 시간을 줄여줍니다.

Gmail 사용자의 지연 시간을 최소화하기 위한 단순한 전략은 사용자의 데이터를 물리적으로 사용자와 가까운 데이터 센터에 배치하는 것입니다. 불행히도 이 전략은 비용(Google 입장에서), 프로비저닝 복잡성(Google 입장에서), 지연 시간 측면에서 나쁜 선택임이 드러납니다. 비용 측면에서 나쁜 선택인 이유는 두 가지입니다. 첫째, 한 시간대(time zone)의 업무 시간 동안 로컬 데이터 센터는 바쁜 반면 몇 시간대 떨어져 있는 데이터 센터는 유휴 상태이지만 사용할 수 없으므로 리소스 활용률이 낮아집니다. 둘째, 각 지리적 지역은 해당 지역의 데이터 센터 중단을 처리할 수 있는 충분한 로컬 용량이 필요하므로 활용률이 더 낮아집니다. 데이터 센터 근처의 사용자 인구에 따라 모든 데이터 센터가 서로 다른 활용률, 프로비저닝 및 지연 시간 프로필을 갖게 되므로 복잡성 측면에서 나쁜 선택입니다. 결과적으로 Gmail은 각 데이터 센터마다 서로 다른 프로비저닝 전략이 필요할 수 있습니다. Gmail은 바쁜 로컬 데이터 센터에서 사용자에게 서비스를 제공하므로 롱테일 지연 시간이 좋지 않을 것이기 때문에 지연 시간 측면에서도 나쁜 선택입니다.

따라서 Gmail은 단순한 전략을 사용하는 대신 일관된 해싱(consistent hashing)을 사용하여 사용자 데이터의 복제본을 전 세계 데이터 센터에 분산시키거나, 데이터 위치 요구 사항이 있는 경우 특정 지역(region)에 분산시킵니다. 이 전략은 데이터 센터 전체에 균일한 활용률을 보장하고 사용자 요청이 바쁜 로컬 데이터 센터에 제한되지 않으므로 더 나은 롱테일 지연 시간을 보장합니다. Gmail의 배치 전략은 모든 데이터 센터가 유사한 활용률과 사용자 구성을 갖도록 하여 프로비저닝을 단순화합니다. 구체적으로 Gmail은 계정에서 리소스로의 간단한 매핑을 사용할 수 있습니다. 각 계정은 계정이나 사용자의 위치에 관계없이 (평균적으로) 일정량의 CPU, 메모리, IOPS 및 스토리지가 필요합니다. 따라서 Gmail은 모든 데이터 센터에서 동일한 프로비저닝 전략을 사용할 수 있습니다. 또한 스토리지와 처리의 깔끔한 분리를 통해 두 풀을 독립적으로 확장할 수 있어 프로비저닝을 더욱 단순화하고 활용률을 높일 수 있습니다.

요약하면, Gmail은 가용성(지리적으로 다양한 위치에 복제), 지연 시간(예: 데이터 센터의 핫스팟 회피 또는 각 종류의 데이터에 최적화된 서로 다른 스토리지 시스템 사용), 비용(예: 일관된 해싱 사용)에 최적화된 분산 시스템입니다.

## 3.3 AI 워크로드

지금까지 검색, Gmail 등과 같은 특정 서비스에 대해 논의했습니다. 다음으로 AI/ML(인공지능/머신러닝) 워크로드 범주에 대해 논의하겠습니다.

심층 신경망(DNN)과 AI 워크로드(자연어 처리("AI 봇"), 음성 인식 및 합성, 컴퓨터 비전, 단백질 접힘, 기상 예측 등 다양한 분야의 발전을 주도하며)는 현대 데이터 센터 애플리케이션의 초석이 되었습니다. 이러한 워크로드는 집약적인 계산 및 데이터 수요를 특징으로 하며, 대규모 학습 및 추론을 처리하기 위해 전문화된 인프라가 필요합니다.

DNN은 인간 뇌의 구조와 기능에서 영감을 받은 머신러닝 알고리즘의 한 종류입니다. 이는 상호 연결된 뉴런의 여러 계층(layer)으로 구성되며, 각 뉴런은 입력 데이터를 처리하고 그 결과를 다음 계층으로 전달합니다(그림 3.6). 신경망의 깊이(depth)는 포함된 계층의 수를 나타내며, "심층(deep)"은 일반적으로 여러 은닉 계층(hidden layers)이 있는 네트워크를 나타냅니다. 클라우드의 대규모 데이터 세트는 더 크고 추가적인 계층을 사용하여 더 복잡한 패턴과 고수준의 추상화를 포착함으로써 더 정확한 모델을 가능하게 합니다.

> **그림 3.6** 심층 신경망 (DNN)

DNN은 특정 데이터 유형 및 작업에 맞게 조정된 다양한 아키텍처를 포함합니다. 다층 퍼셉트론(MLP)은 분류 및 회귀에 사용되는 초기 모델입니다. 합성곱 신경망(CNN)은 이미지 처리에 탁월하며, 순환 신경망(RNN)은 텍스트와 같은 순차적 데이터를 처리합니다. 트랜스포머(Transformers)[24]는 어텐션(attention) 메커니즘으로 자연어 처리에 혁명을 일으켰으며, 대규모 데이터 세트에서 학습된 확장된 트랜스포머 아키텍처인 모든 대규모 언어 모델(LLM)을 구동합니다. 이들은 인간과 유사한 텍스트를 이해하고 생성하는 데 탁월하며, 확산(diffusion) 모델과의 통합을 통해 그 기능은 이미지, 비디오 및 오디오 생성과 같은 다른 양식(modality)으로 확장됩니다. 추천 모델은 사용자-아이템 상호 작용을 활용하여 선호도를 예측하며, 이는 개인화된 광고 및 랭킹에 중요합니다. 이러한 각 DNN 클래스는 고유한 계산 특성을 수반하므로 컴퓨팅 인프라의 신중한 설계가 필요합니다.

DNN을 개발하고 배포하는 데는 각각 고유한 계산 요구 사항이 있는 별개의 단계가 포함됩니다. (사전)학습((Pre-)Training)은 (라벨이 지정된) 데이터로부터 모델 가중치를 학습하는 것을 포함합니다. 그 뒤를 이어 작업별 데이터에 대한 추가적인 미세 조정(fine-tuning) 및 증류(distillation)가 (선택적으로) 뒤따릅니다. 마지막으로 추론(inference) 또는 모델 서빙은 새로운 데이터에 대해 예측을 수행합니다. (최근에는 생각하는 모델(thinking models)과 함께 추가적인 추론 시간 컴퓨팅도 있습니다.)

### 3.3.1 학습

DNN 개발의 기초인 학습은 라벨이 지정된 데이터를 사용하여 모델 매개변수를 반복적으로 조정하는 작업을 포함하며, 종종 수천 개의 특수 가속기(TPU, GPU)를 사용하여 몇 주 동안 대규모로 수행됩니다. 이 계산 집약적인 프로세스는 분산 학습 기술을 활용하여 여러 학습자가 데이터 하위 집합을 처리하고 중앙 집중식 서버 또는 집합적 리덕션(collective reduction)을 통해 매개변수를 조정합니다. DNN 학습 알고리즘은 일반적으로 매우 동기적인 방식으로 작동하므로 작업자 노드 간의 빈번한 통신이 필요하여 일관된 매개변수 업데이트와 모델 수렴을 보장합니다. 이러한 동기적 특성은 통신 병목 현상을 피하기 위해 신중한 최적화가 필요합니다. 단 하나의 느린 작업자(laggard)라도 전체 학습 프로세스를 중단시킬 수 있기 때문입니다. 또한 주기적인 모델 체크포인팅, 성능 저하 없는 빠른 복구, 실패를 원활하게 처리하기 위한 프로그래밍 추상화를 포함하여 규모에 따른 강력한 내결함성 메커니즘을 요구합니다. 이러한 대규모 워크로드의 동기화는 전력 및 열 스파이크를 처리하기 위한 새로운 설계 최적화도 필요로 합니다. 마지막으로, 대규모 데이터 세트를 처리하고, 이를 성능면에서 효율적으로 전처리하며, 특수 가속기에 데이터를 효과적으로 공급하기 위해서는 효율적인 데이터 처리 파이프라인이 중요합니다.

### 3.3.2 추론

학습된 모델의 적용인 추론(또는 서빙)은 새로운 데이터에 대해 예측을 수행하며, 종종 사용자 대면 애플리케이션에 대한 엄격한 지연 시간 요구 사항을 갖습니다. 규모에 맞는 서빙은 다양한 하드웨어 및 소프트웨어 환경에 걸쳐 배포 가능해야 하며, 초당 수백만 개의 쿼리를 처리할 수 있는 확장성을 보장하고, 고가용성 및 내결함성을 유지해야 합니다. 효율적인 자원 활용과 로드 밸런싱은 성능 및 비용 효율성 목표를 달성하는 데 중요합니다. 그림 3.7은 모델 개발 중의 주요 워크로드를 보여줍니다. 사전 학습은 방대한 양의 학습 데이터를 수집하여 기본 모델 가중치를 결정합니다. 지도 미세 조정(SFT) 및 인간 피드백을 통한 강화 학습(RLHF)은 특정 사용 사례(챗봇 등)에 맞게 모델을 조정하며, 증류는 성능을 최적화하기 위해 크기를 줄입니다.

### 3.3.3 대규모 언어 모델

대규모 언어 모델(LLM)은 워크플로에 추가 단계를 도입합니다. 장기간에 걸쳐 대규모 범용 데이터 세트에 대한 사전 학습은 방대한 컴퓨팅 자원을 요구합니다. 작업별 적응을 위한 미세 조정은 더 작은 데이터 세트와 더 적은 계산을 사용합니다. 선택적 증류는 서빙을 위한 더 작고 자원 효율적인 모델을 생성합니다. LLM 사전 학습에는 수만에서 수십만 개의 칩이 필요하며, 때로는 여러 데이터 센터에 걸쳐 있기도 합니다. LLM 미세 조정 역시 상당한 계산 능력을 필요로 하지만, 더 국지적인 가속기 클러스터에서 수행될 수 있습니다.

> **그림 3.7** DNN 모델의 개발 및 배포 단계

LLM 서빙은 고유한 과제를 제시합니다. LLM의 큰 메모리 풋프린트는 여러 호스트 CPU와 가속기(TPU, GPU)에 분산되어야 하며, 추론은 고도로 계산 집약적인 단계부터 고도로 메모리 대역폭 집약적인 단계까지 다양한 단계를 포함합니다. 또한 대규모로 LLM을 서빙하려면 효율적인 컨텍스트 및 상태 관리와 짧은 지연 시간 응답이 필요하며 동시에 비용 효율적이어야 합니다. 다행히 추론 효율성은 지난 몇 년 동안 매우 잘 발전하여 (동일하거나 더 나은 품질에서) 2배 이상의 개선을 가져왔습니다.

### 3.3.4 AI 연산 특성

대규모 선형 대수 연산, 특히 행렬 곱셈이 DNN 워크로드를 지배합니다. 그림 3.8은 초기 DNN(ResNet)부터 최근 LLM(Google Gemini [25], OpenAI GPT-4 [26], [27], Meta Llama [28], Anthropic Claude [29])에 이르기까지 최첨단 모델을 학습시키는 데 필요한 FLOPS를 시간 경과에 따라 나타낸 것입니다. 이러한 근본적인 속성은 이러한 연산을 효율적으로 실행하도록 최적화된 TPU 및 GPU와 같은 특수 하드웨어 가속기의 개발을 주도했습니다. 높은 비트 폭의 수치(fp64, fp32)를 활용하는 기존 및 HPC 워크로드와 달리, DNN 모델은 낮은 정밀도 수치(bf16, fp8, fp4, ocp-mx)를 사용할 수 있습니다. 이러한 낮은 정밀도 형식은 메모리 풋프린트를 줄이고 FLOPS의 더 효율적인 프로비저닝을 가능하게 하여 가속기의 면적 및 에너지 효율성을 모두 향상시킵니다. 모델 크기가 계속 커지고 더 많은 데이터로 학습됨에 따라 확장성이 중요해지며, 효과적인 확장을 위해 고대역폭 상호 연결을 갖춘 시스템이 필요합니다. 또한 전력 및 탄소 발자국이 점점 더 중요해지고 있습니다. 연속적인 가속기 세대(TPU, GPU)는 운영 에너지 효율성에 중점을 두고 있으며, 데이터 센터에서 친환경 에너지를 활용하기 위한 지능형 스케줄링 및 대규모 DNN 워크로드의 전력 특성을 활용하기 위한 전력 공급 최적화(예: 오버서브스크립션)와 같은 기술로 보완됩니다.

> **그림 3.8** 지난 10년 동안의 ML 워크로드 컴퓨팅 수요

이러한 하드웨어 발전을 보완하는 전용 소프트웨어 추상화는 연구자들이 빠른 속도로 혁신할 수 있도록 지원합니다. 고성능 컴파일러와 런타임은 알고리즘을 도메인별 하드웨어에 맞는 효율적인 코드로 변환합니다. 융합(Fusion) 기술은 여러 작업을 단일 커널로 결합하여 메모리 접근 오버헤드를 줄임으로써 메모리 대역폭의 효과적인 활용을 보장합니다. 효율적인 프리페칭(prefetching)과 컴퓨팅과 통신 작업의 중첩(overlapping)은 유휴 시간을 최소화하고 처리량을 극대화하는 데 도움이 됩니다. 모델 크기가 커짐에 따라 여러 칩에 샤딩되어야 하므로 다양한 병렬화 전략이 필요합니다: 데이터 병렬성(서로 다른 데이터 배치를 서로 다른 칩에 분배), 모델 병렬성(모델 가중치를 여러 칩에 분할), 파이프라인 병렬성(모델 계층을 여러 칩에 걸쳐 단계로 나눔).

TensorFlow, PyTorch, JAX와 같은 소프트웨어 프레임워크는 고수준의 추상화를 제공하여 연구자들이 자동 미분과 같은 기능을 통합하면서 복잡한 모델을 쉽게 표현할 수 있도록 합니다. 감소된 정밀도 수치(예: bf16, fp8, int8, int4) 활용 및 auto-ML 기술 채택과 같은 스택 간 최적화는 AI 워크로드를 특정 하드웨어 플랫폼 및 애플리케이션 요구 사항에 맞게 조정하여 효율성과 성능을 극대화할 수 있게 합니다.

요약하자면, AI 워크로드, 특히 DNN과 LLM은 엄청난 계산 규모(예: TPU/GPU와 같은 특수 가속기에서의 분산 학습을 통해)와 효율적이고 지연 시간이 짧은 추론(예: 모델/소프트웨어 최적화 및 다양한 하드웨어 배포를 통해)을 위해 설계되었습니다. 그러나 AI 워크로드는 빠르게 진화하고 있으며, 이 논의는 빠르게 발전하는 분야의 작성 시점에서의 스냅샷으로 보아야 합니다.

## 3.4 사례 연구: Google Compute Engine

Google Compute Engine(GCE)은 고객이 Google 인프라에서 워크로드를 안전하고 효율적으로 실행할 수 있도록 합니다. GCE의 인프라는 세 가지 종류의 컴퓨팅 인스턴스를 지원합니다: 가상화된 자원이 기본 하드웨어에 직접 매핑되는 성능 최적화 가상 머신(VM), 고객이 자원 요구 사항에 따라 기본 하드웨어에 동적으로 매핑되는 사용자 지정 머신 형태(shapes)를 사용할 수 있는 비용 최적화 VM, 그리고 고객이 기본 컴퓨팅 하드웨어에 직접 액세스할 수 있는 베어 메탈 인스턴스입니다.

그림 3.9는 GCE 아키텍처의 개요를 보여줍니다. 호스트의 하드웨어에는 보안(Titan) 및 네트워킹과 스토리지 가상화(Titanium)를 위한 특수 하드웨어 가속기가 포함되어 있어, 베어 메탈 인스턴스조차도 이들에 대한 직접적인 하드웨어 액세스 권한을 갖지 않습니다. 호스트 내 I/O 가속기는 모든 I/O 기능을 자체적으로 수행하지 않고 일부 기능을 네트워크 "호버보드(hoverboards, 특수 고성능 패킷 프로세서)" 및 스토리지 에이전트로 오프로드합니다. 메일이나 검색과 같은 개별 서비스와 달리 GCE는 다른 워크로드를 실행하기 위한 플랫폼을 나타냅니다. 아래에서는 WSC 설계와 관련된 이 플랫폼의 세 가지 주요 측면을 논의합니다.

### 3.4.1 검증된 부팅

Google이 자체 설계한 Titan [30] 보안 마이크로컨트롤러는 호스트의 모든 펌웨어와 소프트웨어 [31]를 암호학적으로 검증하기 위한 하드웨어 신뢰 루트(root of trust)를 제공합니다. 하드웨어 신뢰 루트는 호스트의 부트 펌웨어를 암호학적으로 검증합니다. 그런 다음 부트 펌웨어는 GCE가 가상 머신 인스턴스를 지원하기 위해 사용하는 커널 및 KVM 기반 하이퍼바이저를 포함한 시스템 소프트웨어를 검증합니다. 마지막으로 시스템 소프트웨어는 바이너리 인증을 사용하여 시스템 데몬과 같은 사용자 공간 소프트웨어를 검증합니다.

> **그림 3.9** 계층화된 오프로드를 갖춘 GCE 노드
> **그림 3.10** 검증된 부팅 시퀀스

호스트의 펌웨어 또는 소프트웨어가 의도한 상태에서 벗어나면 플릿(fleet) 내에서 작동하는 데 필요한 자격 증명에 액세스할 수 없습니다. 이러한 머신은 고객 워크로드 또는 기타 Google 서비스를 실행하는 데 참여할 수 없으며, 머신 관리 인프라가 자동 복구 조치를 트리거할 때까지 대기합니다.

검증된 부팅 아키텍처는 두 가지 중요한 이점을 제공합니다. 첫째, 상위 계층이 하위 계층의 적절한 상태(코드 및 구성)에 의존할 수 있는 계층화된 보안 아키텍처의 기반 역할을 합니다(그림 3.10). 이것이 없다면 강력하게 보안된 운영체제라도 의존하는 펌웨어를 조작함으로써 무력화될 수 있습니다. 둘째, 보안 침해로부터 빠르게 복구할 수 있는 방법을 제공합니다. 호스트나 게스트에 공격자가 존재한다고 의심되는 경우 재부팅은 해당 공격자를 제거하고 기본 상태를 복원하도록 보장합니다. 동일한 기능을 사용하여 이전 고객이 베어 메탈 액세스 권한을 가졌더라도 새 고객에게 할당하기 전에 머신을 정리할 수 있습니다.

### 3.4.2 계층화된 오프로드

역사적으로 가상 머신은 호스트 소프트웨어에 의존하여 물리적 네트워크의 물리적 IP 주소를 가진 물리적 네트워크 인터페이스 카드(NIC)를 가상 사설 LAN의 가상 IP를 가진 가상 NIC로 변환하고 나가는 패킷을 캡슐화하고 들어오는 패킷의 캡슐화를 해제했습니다. (역사적인 이유로 이러한 가상 LAN은 종종 VPC(Virtual Private Cloud)라고 불립니다.) 마찬가지로 PCIe 또는 NVMe 인터페이스가 있는 물리적 I/O 장치를 가상화하려면 호스트 지원이 필요했습니다.

오늘날 GCE는 호스트 내 오프로드를 호스트 외부에서 실행되는 스케일 아웃 오프로드로 보완하는 오프로드 시스템인 Titanium [32], [33]을 통해 가상 머신 또는 베어 메탈 인스턴스에서 실행되는 고객 워크로드를 지원합니다. 이 아키텍처는 소프트웨어 기반 접근 방식보다 보안, 성능 및 유연성을 향상시킵니다. 다른 클라우드도 유사한 아키텍처를 사용하지만 계층(tiers)이 없습니다. 예를 들어 Amazon의 Elastic Block Store(EBS)용 Nitro 가속기는 모든 블록 스토리지 기능을 단일 카드에 포함하고 있습니다. 이 아키텍처는 단순하다는 이점이 있지만, 하드웨어 업그레이드 없이 호스트나 VM의 I/O 용량을 변경할 수 있는 유연한 I/O 용량을 제공하기 어렵게 만듭니다.

GCE의 호스트 내 Titanium 어댑터는 호스트 CPU가 수행하는 작업을 최소화하기 위한 인프라 처리 장치(IPU)(IPU에 대해서는 6장에서 자세히 논의할 것임)입니다. 이는 I/O 가상화를 위한 하드웨어 가속을 제공합니다. 네트워킹의 경우 네트워크 패킷의 캡슐화/역캡슐화를 가속화하고 스케일 및 오프로드에 최적화된 PSP 보안 프로토콜 [34]로 네트워크 트래픽을 암호화합니다. 스토리지의 경우 가상 NVMe 블록 장치를 고성능, 유연성, 확장성 및 내구성이 뛰어난 Hyperdisk 볼륨에 매핑합니다.

호스트 내 오프로드 외에도 다른(스케일 아웃, 호스트 외부) 오프로드를 통해 GCE는 각 호스트에서 제공할 수 있는 실제 한계를 넘어 VM 서비스를 확장할 수 있습니다. 호스트에 장착되는 가속기 카드의 스토리지 가상화 성능에 제한받는 대신, Hyperdisk 블록 스토리지 [35]는 두 곳에서 작업을 수행합니다. 기본 처리는 로컬 Titanium 어댑터에서 발생하지만, 실제 영구 스토리지 처리는 Google의 클러스터 수준 파일 시스템인 Colossus 전체에 I/O를 분산시키는 별도 호스트의 스케일 아웃 오프로드 계층에서 발생합니다. 기존 오프로드 아키텍처의 경우 더 높은 블록 스토리지 IOPS를 위해서는 워크로드가 필요하든 그렇지 않든 더 많은 vCPU(또는 더 큰 가속기 카드)가 있는 VM이 필요합니다. 이러한 긴밀한 결합은 자원 낭비와 더 높은 비용을 초래합니다. Hyperdisk는 GCE가 인스턴스 크기와 스토리지 오프로드 작업을 독립적으로 조정할 수 있으므로 컴퓨팅 인스턴스 크기를 스토리지 성능과 분리합니다. 따라서 GCE는 비교적 작은 범용 VM으로도 높은 스토리지 성능을 지원할 수 있습니다.

스케일 아웃 오프로드의 또 다른 예로, GCE는 네트워크 가상화를 확장하기 위해 "호버보드" [36]를 사용합니다. 호버보드는 일부 흐름(flows)에 대해 기본 라우터 역할을 하는 독립형 소프트웨어 스위치입니다. Titanium을 사용하면 Titanium 어댑터의 Google Andromeda 가상 네트워킹 스택(Andromeda에 대해서는 6장과 7장에서 더 자세히 다룸)은 라우트가 없는 모든 패킷을 모든 가상 네트워크에 대한 전달 정보를 가지고 있는 호버보드 게이트웨이로 보냅니다.

### 3.4.3 프로비저닝 워크플로

GCE의 제어 평면(control plane)은 사용자가 가상 클러스터를 생성하고 구성할 수 있게 하며 Google이 이를 안정적이고 효율적으로 실행할 수 있게 합니다(그림 3.11). 예를 들어 고객은 GCE API를 사용하여 원하는 가상 머신 구성의 표현을 저장할 수 있으며, CPU 수, 메모리 양, Hyperdisk 볼륨의 수와 크기, 네트워크 방화벽 규칙 등을 지정할 수 있습니다.

VM의 의도된 상태 업데이트를 Spanner에 저장한 후, GCE API 서버는 사용자의 의도를 수행하기 위해 여러 특수 제어 평면과 통신합니다. 먼저 GCE는 Borg(4장에서 더 자세히 논의됨)를 호출하여 VM 인스턴스를 호스트에 효율적으로 빈 패킹(bin-pack)하면서 동일한 프로젝트의 인스턴스를 호스트 간에 분산시키고 유지 관리 이벤트가 대기 중인 호스트를 피하는 등의 다른 제약 조건을 충족시킵니다. 그런 다음 Borg는 대상 호스트에서 VM 인스턴스 컨트롤러를 시작합니다.

VM 인스턴스 컨트롤러가 올바른 호스트에서 실행되면, GCE는 VM 크기와 같은 기본 정보와 Hyperdisk 볼륨을 포함한 가상 장치를 구성하는 정보를 포함하는 VM 사양을 보냅니다. Hyperdisk 클라이언트는 VM의 볼륨을 제공하기 위해 스케일 아웃 Hyperdisk 에이전트 세트를 구성하고, 이 에이전트들은 관련 Colossus 파일을 엽니다.

> **그림 3.11** GCE 프로비저닝 흐름

그런 다음 GCE는 Andromeda [36] 패브릭 매니저를 호출하여 새 VM 호스트의 Titanium 컨트롤러에 있는 가상 스위치를 구성하여 가상 네트워크의 다른 가상 머신과 통신할 수 있는 경로를 설정합니다. 패브릭 매니저는 또한 가상 네트워크의 다른 VM이 새 VM으로 직접 패킷을 보낼 수 있도록 다른 호스트의 가상 스위치를 선제적으로 프로그래밍할 수도 있습니다. 대안으로 이 단계를 생략할 수 있으며, 이 경우 새 VM으로 전송된 패킷은 호버보드 스위치를 통해 라우팅됩니다.

### 3.4.4 라이브 마이그레이션

라이브 마이그레이션(VM을 종료하지 않고 한 물리적 호스트에서 다른 호스트로 VM을 마이그레이션하는 것 [37])은 이러한 많은 부분이 어떻게 함께 작동하는지 보여줍니다. 가상 머신(VM) 인스턴스의 기본 하드웨어에 대한 계획된 유지 관리 이벤트 동안 Compute Engine은 라이브 마이그레이션을 사용하여 실행 중인 VM을 다른 호스트로 이동할 수 있습니다. 마이그레이션을 위해 VM을 선택한 후 GCE는 게스트에게 곧 마이그레이션이 발생할 것임을 알립니다. 지연 후 마이그레이션 프로세스는 GCE가 Borg를 사용하여 대상 호스트의 용량을 예약하는 것으로 시작됩니다.

그런 다음 GCE는 마이그레이션의 사전 복사(pre-copy) 단계를 시작하여 소스 호스트에서 대상 호스트로 메모리 페이지를 복사하는 동시에 여전히 실행 중인 VM에 의해 쓰여진 페이지를 추적합니다. GCE는 또한 사전 복사 중에 업데이트된 추가 블록을 계속 버퍼링하고 쓰는 동안 더티(dirty) Hyperdisk 블록을 스토리지로 플러시(flush)합니다.

마이그레이션의 다음 단계는 소스 호스트의 VM이 일시 중지되고, VCPU 상태가 대상 호스트로 전송되고, 남은 더티 Hyperdisk 블록이 플러시되고, 남은 더티 메모리 페이지 목록이 대상 호스트로 전송되며, Andromeda 네트워킹이 호버보드와 다른 VM의 가상 스위치를 프로그래밍하여 VM의 패킷을 대상 호스트로 보내기 시작하는 짧은 블랙아웃(blackout) 단계입니다. 대부분의 VM의 경우 이 블랙아웃 기간은 1초 미만으로 유지될 수 있습니다.

마지막으로 사후 복사(post-copy) 단계에서 GCE는 VM을 재개합니다. VM이 재개되면 GCE는 남은 더티 메모리 페이지를 소스 호스트에서 대상 호스트로 비동기적으로 복사합니다. VM이 대상에 복사되기 전에 더티 페이지에 액세스하면 페이지 폴트가 발생하고 대상 호스트는 소스 호스트에서 페이지를 가져와 VM이 최소한의 중단으로 계속 진행할 수 있도록 합니다. 또한 분산 Andromeda 시스템이 VM의 새 위치를 참조하도록 가상 스위치를 업데이트하는 동안 소스 호스트는 수신한 VM의 패킷을 대상 호스트로 전달합니다.

요약하면, Google Compute Engine(GCE)은 안전한 워크로드 실행(Titan 하드웨어를 사용한 검증된 부팅 프로세스를 통해)과 유연하고 고성능인 I/O(Titanium IPU 및 스토리지와 네트워킹을 위한 특수 스케일 아웃 시스템을 포함한 계층화된 오프로드를 통해)에 최적화된 플랫폼입니다. 고객 워크로드를 위한 효율적인 VM 프로비저닝 워크플로와 중단 없는 라이브 마이그레이션은 효율성을 최적화합니다.

## 3.5 사례 연구: 데이터 처리 인프라

마지막으로 논의할 WSC 워크로드 세트는 데이터베이스 및 데이터 분석 워크로드를 포함한 데이터 처리 관련입니다. 전 세계적으로 데이터 분석은 1,000억 달러 이상의 산업이며, 매일 수 엑사바이트의 정형 및 비정형 데이터가 생성되고 분석됩니다. 전통적으로 데이터 분석은 정형 데이터에 초점을 맞추었지만, AI는 점점 더 정형 데이터와 비정형 데이터가 원활하게 통합될 수 있는 하이브리드 세계로 초점을 확장하고 있습니다 [38]. 이러한 하이브리드 사용 사례의 경우, 분리형(disaggregated) 시스템은 스토리지(표 형식에서 멀티 모달로)와 컴퓨팅(전통적인 CPU에서 가속기로)에 대한 빠르게 변화하는 요구 사항을 분리(decoupling)하는 데 매우 유용합니다. BigQuery와 Dataflow라는 두 가지 제품은 WSC가 제공하는 분리의 이점을 보여줍니다.

### 3.5.1 BigQuery

BigQuery는 데이터 센터 규모에서 운영할 수 있는 데이터 웨어하우스로, 공유 작업자 풀에서 들어오는 쿼리에 대해 컴퓨팅 용량을 동적으로 프로비저닝합니다. BigQuery의 전신인 Dremel [6]은 처음에 로그 처리 도구로 사용되어 분리형 스토리지 시스템(Colossus 및 그 전신인 GFS)에 저장된 로그 파일 전반에 걸쳐 단순화되고 능률적인 쿼리 인터페이스를 제공했습니다. 이러한 사용 사례 중 다수는 데이터에 대한 반복적이고 즉각적인(ad hoc) 쿼리가 필요했습니다. 따라서 Dremel의 중요한 설계 목표는 미리 계획된 컴퓨팅/스토리지 비율(예: 제한된 컴퓨팅으로 인한 대형 쿼리의 병목 현상 및/또는 자주 쿼리되지 않는 데이터에 액세스하기 위한 데이터 이동 요구)에 내재된 불균형을 피하기 위해 컴퓨팅과 스토리지를 분리하는 것이었습니다.

10년이 지난 지금, 이러한 컴퓨팅과 스토리지의 분리는 필수 불가결한 요소입니다. 데이터 웨어하우스가 컴퓨팅과 스토리지를 긴밀하게 결합하면 결과 시스템은 많은 단점을 갖게 됩니다. 필연적으로 주어진 웨어하우스의 형태를 최적화하려면 컴퓨팅이나 스토리지의 낭비적인 과잉 프로비저닝을 피하기 위한 세심한 튜닝이 필요합니다. 그러한 튜닝이 가능하다 하더라도 웨어하우스가 비교적 균일한 정상 상태 부하를 갖거나, 유휴 자원을 피하기 위해 복잡한 오토스케일링 로직이 필요하다고 가정합니다. 오토스케일링은 본질적으로 컴퓨팅과 스토리지를 결합하는 시스템에 더 복잡합니다. 예를 들어, 해당 스토리지가 동적으로 복제되지 않는 한 시스템에 컴퓨팅을 추가하는 것만으로는 추가 쿼리 대역폭으로 즉시 변환되지 않을 수 있습니다.

BigQuery의 핵심 시스템 설계는 단순함에서 우아함을 찾을 수 있습니다(그림 3.12). 작업자는 효율성과 성능을 위해 특수 컬럼형(columnar) 파일 형식(Capacitor [40])을 사용하여 분리형 스토리지(Colossus [39])에서 읽습니다. 작업자는 일반적인 OSS 파일 형식에서도 읽을 수 있습니다. 이 초기 읽기 단계를 지나면 시스템은 메모리, SSD 및 HDD에 걸쳐 계층화될 수 있는 분산 셔플 계층을 사용하여 작업자 간의 집계 및 조인을 수행합니다. 비동기적으로 시스템은 별도의 컴퓨팅 자원 풀을 사용하여 스토리지 계층에 대한 업데이트(압축, 키 순환, 재파티셔닝, 심지어 데이터 센터 간 이동)를 수행하여 라이브 쿼리 경로에 영향을 주지 않으면서 스토리지 성능을 투명하게 최적화합니다.

분리는 위의 모든 단계에서 중요합니다. 작업자를 동적으로 할당함으로써 BigQuery는 용량 사용을 최적화하고 유휴 자원을 최소화할 수 있습니다. 이를 통해 대규모 및/또는 높은 중요도의 워크로드는 정상 상태의 과잉 프로비저닝 없이도 일시적으로 사용량을 폭발(burst)시킬 수 있습니다 [41]. 데이터를 읽을 때 컴퓨팅과 스토리지의 분리는 시스템이 미리 결정된 사용 가능한 데이터 사본 수에 병목 현상을 겪는 대신 주어진 작업의 필요에 따라 병렬성을 극대화할 수 있게 합니다.

분리는 셔플 작업 중에 더욱 중요합니다. 셔플 중에 작업자 노드는 하나의 키에 속하는 모든 데이터가 동일한 작업자 노드에 위치하도록 데이터를 재분배합니다. 전통적인 셔플에서는 치우친(skewed) 데이터 분포가 성능 병목 현상을 일으킬 수 있지만, BigQuery의 인메모리 셔플 계층은 데이터의 동적 재파티셔닝 [42]을 허용하여 이러한 문제를 제거합니다. 또한 이 셔플 계층은 처리 그래프의 생산자 단계를 소비자 단계와 분리하여 내결함성 데이터 처리를 제공합니다.

데이터 양이 계속 증가함에 따라 메타데이터 수준에서도 분리가 중요합니다. 데이터 웨어하우스가 특정 크기에 도달하면 메타데이터는 더 이상 단일 샤드에 맞지 않습니다. 일부 시스템은 메타데이터를 여러 샤드로 분할하여 이를 처리하지만, 이러한 샤드 자체가 컴퓨팅과 스토리지를 결합하면(즉, 주어진 메타데이터 조각을 쿼리하려면 주어진 스토리지 샤드에 상주하는 컴퓨팅을 사용해야 함) 위에서 설명한 것과 동일한 단점이 발생합니다. 대신 BigQuery는 데이터를 처리하는 것과 동일한 방식으로 메타데이터에 접근합니다. 컴퓨팅과 스토리지를 분리하는 메타데이터를 위한 유사한 메커니즘 [43]을 사용함으로써 BigQuery는 샤딩 방식의 해당 단점 없이 매우 큰 메타데이터 크기를 수용합니다(그림 3.12).

BigQuery는 10년 전 SQL 테이블에 정형 데이터를 저장하도록 설계된 데이터 웨어하우스로 시작되었습니다. 데이터는 저장되기 전에 정제되고 미리 정의된 스키마로 처리됩니다. 최근 몇 년 동안 정형, 반정형(JSON 또는 XML 등) 및 이미지, 오디오, 비디오 파일과 같은 비정형 데이터를 포함한 모든 유형의 데이터를 저장하는 데이터 "레이크하우스(lakehouse)"(데이터 레이크 + 데이터 웨어하우스)로 진화했습니다 [44]. 또한 쿼리 언어에 대한 확장을 통해 사용자는 이제 SQL, AI 모델 평가 및 Flink나 Spark와 같은 외부 시스템을 조합하여 데이터를 처리하고 여러 클라우드에 저장된 데이터를 처리할 수 있습니다. 이러한 진화는 시스템의 많은 측면에 상당한 영향을 미치지만 핵심 처리 아키텍처는 그대로 유지되었습니다.

> **그림 3.12** BigQuery 아키텍처

### 3.5.2 Cloud Dataflow

Dataflow [45]는 페타바이트 규모의 이기종 입력에 대해 스트리밍 및 배치 처리를 모두 수행할 수 있는 데이터 처리 엔진입니다(그림 3.13). 전용 파일 형식을 사용하는 대신 Dataflow는 클라우드 주소 지정 가능한 위치에 상주하는 임의의 데이터 소스를 읽도록 사용자 지정할 수 있습니다. BigQuery와 마찬가지로 분리형 데이터 소스는 Dataflow에서 병렬성을 실현하는 데 중요합니다. 데이터가 시스템에 들어오면 배치 데이터는 BigQuery와 유사한 메커니즘(메모리와 디스크에 걸쳐 계층화됨)을 사용하여 단계 간에 셔플될 수 있습니다.

Dataflow와 그 내부 전신(Flume [46])을 설계할 때 핵심 목표는 물리적 및 논리적 데이터 처리 계획을 분리하는 것이었습니다(개념적으로 또 다른 형태의 분리). 이러한 시스템 이전에는 사용자가 MapReduce의 복잡한 토폴로지를 함께 연결하여 물리적 계획(예: 작업 B 후에 작업 A 실행)을 명시적으로 정의하는 반면 논리적 계획(예: 데이터 세트 A와 B를 결합한 다음 집계 수행)은 암시적으로 정의했습니다. 물리적 계획을 입력하는 대신 사용자는 Dataflow에 논리적 계획을 제공하고, Dataflow는 시스템이 실제로 실행하는 물리적 계획으로 컴파일하는 다양한 최적화(예: 불필요한 데이터 세트 구체화 건너뛰기)를 수행합니다.

위의 최적화 로직은 배치 및 스트리밍 워크로드 모두에 적용될 수 있습니다. 특히 스트리밍 워크로드의 경우 Dataflow는 동적으로 결정된 키 범위에 따라 들어오는 스트림을 자동으로 파티셔닝합니다. 배치 셔플 작업과 마찬가지로 이러한 범위는 병목 현상을 방지하기 위해 재조정 [47]되어야 할 수 있습니다(스트리밍의 경우 지연 시간에 민감한 파이프라인 정지).

> **그림 3.13** Cloud Dataflow 아키텍처

여기서 분리는 시스템의 생존 가능성에 필수적입니다. Dataflow는 스트리밍 상태 및 체크포인트를 컴퓨팅 계층에서 분리된 시스템 관리 스토어에 저장하여 키 범위를 독립적으로 분할하고 병합할 수 있도록 합니다.

스토리지와 컴퓨팅의 분리는 워크로드의 다양한 물리적 단계의 동적 배치도 허용합니다. 종종 동일한 지리적 위치에 컴퓨팅과 스토리지를 코로케이션하는 것이 최선의 정책이지만, 물리적 계획을 최적화하기 위해 비용과 이점을 다른 실행 전략(예: 위치 간 소규모 데이터 세트 이동)과 비교하여 동적으로 평가합니다. 이를 통해 단일 논리적 계획이 시간이 지남에 따라(물리적 제약 조건의 변경에 따라) 진화할 수 있으며, 이는 특히 서로 다른 가속기 제품군에 걸친 이기종 컴퓨팅에서 중요합니다. 특정 단계가 실행되는 동안 컴퓨팅 자원은 자원 가용성 및 원하는 처리량에 따라 동적으로 확장됩니다(그림 3.13).

요약하면, 컴퓨팅과 스토리지의 분리는 Google의 데이터 처리 포트폴리오 전반에 걸쳐 효율적이고 확장 가능한 서비스를 제공하기 위한 필수 메커니즘입니다. BigQuery와 Dataflow에서 입증된 바와 같이, 이러한 분리는 각각의 시스템 설계의 여러 계층에서 작동합니다. 두 시스템 모두 더 높은 수준의 추상화(BigQuery의 경우 SQL, Flume의 경우 논리적 계획)를 사용하여 처리 로직을 표현함으로써 이러한 이점을 증폭시킵니다.

## 3.6 WSC 워크로드 트레이드오프와 인프라에 대한 시사점

많은 대규모 서비스는 고성능이나 고가용성을 달성하는 데 있어 유사한 문제에 직면합니다. 이 섹션에서는 가장 널리 퍼진 개념 중 일부를 설명합니다. 많은 논문과 책에서 다양한 조직의 흥미로운 추가 관점을 제공합니다 [48], [49], [50], [51].

### 3.6.1 복제와 샤딩

데이터 복제는 처리량과 가용성을 모두 향상시킬 수 있습니다. 복제된 데이터가 자주 수정되지 않는 경우 특히 강력한데, 복제는 업데이트를 더 복잡하게 만들기 때문입니다.

대조적으로 샤딩은 데이터 세트를 더 작은 조각(샤드)으로 나누고 이를 여러 머신에 분산시킵니다. 데이터 세트에 대한 작업은 일부 또는 모든 샤드로 디스패치되고 호출자는 결과를 병합합니다. 샤딩 정책은 공간 제약 및 성능 고려 사항에 따라 달라질 수 있습니다. 매우 작은 샤드(또는 마이크로샤딩)를 사용하는 것은 로드 밸런싱 및 복구에 특히 유리합니다.

종종 데이터베이스 관리 시스템이 제공하는 전통적인 보장을 사용하여 여러 복제본을 최신 상태로 유지하면 복잡성이 크게 증가하고 성능이 저하되며 분산 애플리케이션의 가용성이 감소합니다 [50]. 다행히 대규모 애플리케이션 클래스는 더 완화된 요구 사항을 가지고 있으며, 시스템이 결국 안정적인 일관성 상태로 돌아간다면(최종 일관성, eventual consistency) 제한된 기간 동안 일관되지 않은 뷰를 허용할 수 있습니다. 그러나 최종 일관성을 사용하는 스토리지는 직관적이지 않은 상황을 올바르게 처리해야 하므로 애플리케이션에 복잡성을 가중시키는 경향이 있습니다. 예를 들어 값을 업데이트한 후 후속 읽기가 다른 복제본으로 이동하여 이전 값을 반환할 수 있습니다. 이러한 합병증은 Spanner [7]와 같이 확장 가능하면서도 여전히 완전히 일관된(consistent) 스토리지 시스템의 설계를 동기 부여했습니다.

### 3.6.2 오류 코드와 무결성 검사

데이터 복제는 내결함성과 처리량 향상을 모두 제공합니다. 데이터의 모든 사본이 (N)번 복제되면 (N)배 더 큰 읽기 처리량과 기하급수적으로 더 높은 가용성 및 내구성을 얻습니다. 예를 들어 디스크의 연간 고장률(AFR)이 2%인 경우, 데이터 손실의 연간 위험은 (N)=1일 때 2%에서, 실패한 디스크를 교체하지 않더라도 (N)=3일 때 (2% * 2% * 2% = 0.0008%)로 줄어들며, 48시간 내에 실패한 디스크를 교체하면 그보다 훨씬 낮아집니다.

복제는 스토리지 비용을 증가시키며, 애플리케이션이 추가 처리량을 필요로 하지 않는 경우(예: 거의 액세스하지 않는 아카이브 스토리지), 오류 수정 코드(ECC)가 더 효율적인 방식으로 가용성과 내구성을 제공할 수 있습니다. 대부분의 분산 스토리지 시스템은 삭제 코드(erasure codes)를 사용하는데, 이는 비트의 하위 집합의 삭제(손실)로부터 보호하기 때문에 그렇게 불립니다. 삭제 코딩의 가장 일반적인 형태는 리드-솔로몬(Reed-Solomon, RS) 코딩으로, 데이터의 나머지 조각에서 누락된 데이터를 재생성할 수 있습니다. (k, m) RS 코드는 k개의 데이터 "청크" 세트를 (k + m)개의 청크로 인코딩합니다. 전체 청크 세트는 스트라이프(stripe)를 구성합니다. (k + m)개의 청크 중 적어도 (k)개를 사용할 수 있는 한, RS(k, m)은 전체 데이터를 복구할 수 있습니다.

WSC 스토리지는 데이터 손상(corruption)과 스토리지 성능 저하(degradation)라는 두 가지 추가적인 문제에 직면해 있습니다. 디스크, SSD, 네트워크 및 DRAM 모두 데이터 손상으로부터 보호하기 위한 오류 수정 코드(ECC)를 가지고 있지만, 이러한 보호 기능은 규모에 따른 모든 비트 오류를 감지할 만큼 강력하지 않습니다. 예를 들어 TCP 체크섬은 1비트 오류만 감지합니다.

그러나 낮은 수준의 ECC를 충분히 강력하게 개선하는 것이 반드시 효율적인 것은 아닙니다! 예를 들어, SSD가 ECC에 의해 감지되지 않는 다중 비트 플립(multi-bit flip)을 겪을 확률이 100만분의 1이라고 가정해 보겠습니다. 분명히 100만 개의 SSD가 있는 스토리지 시스템에서는 이 수준의 보호가 불충분합니다. 동시에 이미 삭제 코딩 및 소프트웨어 무결성 보장(SSD 펌웨어 버그로 인한 데이터 손상 가능성도 방어함)을 사용하는 파일 시스템의 일부인 모든 SSD에서 감지 기능을 허용 가능한 수준으로 개선하기 위해 각 장치의 ECC 비트를 확장하는 것은 비효율적입니다. 따라서 높은 내구성은 하드웨어가 아닌 파일 시스템에 의해 제공됩니다. 나중에 10장에서는 무성 데이터 손상(silent data corruption)으로 인한 최근의 오류 증가에 대해서도 논의할 것입니다.

두 번째 과제는 데이터 성능 저하입니다. ECC 비트는 액세스 시에만 확인되므로 자주 액세스하지 않는 데이터의 느린 저하를 발견하지 못합니다. 이러한 저하를 방지하기 위해 WSC 스토리지 시스템은 주기적으로 모든 데이터를 스윕(sweep)하여 각 블록의 무결성이 최소 N주 또는 N개월마다 한 번씩 검증되도록 하는 백그라운드 무결성 검사를 구현합니다.

### 3.6.3 브라운아웃

WSC 운영 경험에서 얻은 놀라운 통찰력은 장애(failure)는 상대적으로 처리하기 쉽지만 준장애(near-failure)는 어렵다는 것입니다. 준장애는 고장 난 장치가 완전히 고장 나지는 않지만 성능이 허용할 수 없는 수준으로 떨어지는 성능 저하 상태에 들어갈 때입니다. 예를 들어 표면 오염이 있는 디스크는 장치의 ECC 보호가 모든 데이터를 복구할 수 있기 때문에 실제로 읽기에 실패하지 않을 수 있지만, "깨끗한" 읽기를 얻기 전에 해당 미디어를 여러 번 읽어야 하므로 탐색(seek) 성능이 훨씬 느려집니다. 전기 용어를 차용하여 이러한 상황을 완전한 고장(블랙아웃)과 구별하기 위해 브라운아웃(brownouts)이라고 합니다.

장애를 방지하기 위해 WSC 시스템은 여러 가지 보호 기능을 사용합니다. 요청 수준에서는 서버가 너무 느리거나 도달할 수 없음을 신속하게 확인하고 새 요청을 피하는 것이 중요합니다. 원격 프로시저 호출은 장기 실행 요청을 중단하기 위해 정보에 입각한 타임아웃 값을 설정해야 하며, 인프라 수준 소프트웨어는 지속적으로 고장 난 서버나 장치를 확인하고 적절한 조치를 취해야 합니다. 이를 성공적으로 수행하려면 섬세한 균형이 필요합니다. 너무 관대하면 서비스 SLO가 손상되고(백만 개의 장치가 있는 환경에서 브라운아웃은 거의 지속적으로 발생함), 너무 공격적이면 처리량 손실 위험이 있으며 심지어 중단을 유발할 수도 있습니다. 예를 들어 서비스가 프로비저닝된 용량 근처에서 실행 중인 경우 응답은 평소보다 느려질 것입니다. 일부 서버나 장치는 브라운아웃을 겪고 있다고 암시할 만큼 느릴 수 있습니다. 해당 시스템을 서비스에서 제거하거나 복제본으로 전송하여 요청을 재시도하면 서비스가 완전한 과부하 상태로 몰려 전체 중단이 발생할 수 있습니다.

### 3.6.4 상태 모니터링과 카나리아

위의 예에서 알 수 있듯이 서비스 상태 모니터링은 놀랍도록 어려울 수 있습니다. 기본 수준에서는 서비스에 관련된 각 장치와 각 작업을 모니터링하는 것이 포함됩니다. 모니터링에는 수동적인 데이터 수집(예: CPU 사용률)뿐만 아니라 모니터링 시스템이 주기적인 요청을 보내 서비스 구성 요소가 여전히 건강한지 확인하는 능동적인 상태 확인(active health check)이 포함될 수 있습니다.

드물지만 현실적인 재앙적 실패 시나리오는 버그로 인해 해당 서버를 충돌시키는 "죽음의 쿼리(Query of Death, QoD)"로 구성됩니다. QoD의 경우 가용성을 향상시키기 위한 상위 수준 메커니즘이 실제로 문제를 증폭시킵니다. 예를 들어 QoD를 재시도하면 추가 서버가 충돌합니다. 마찬가지로 단일 요청이 모든 서버로 전송되는 팬아웃(fan-out)이 높은 서비스에서 QoD는 동시 충돌과 완전한 중단으로 이어질 것입니다. 요청을 하는 클라이언트는 일반적으로 오류를 받은 후 재시도하므로 빠른 재시작도 도움이 되지 않기 때문입니다.

QoD를 방지하기 위해 로드 밸런서나 RPC 재시도 로직과 같은 트래픽 관리 시스템은 요청을 수신하는 서버의 충돌과 상관관계가 있는 요청을 추적해야 합니다. 서버는 언제든지 수천 개의 보류 중인 요청을 가질 수 있으므로 첫 번째 충돌 후 QoD를 잡기는 어렵습니다. QoD로 식별되면 요청은 다시 전송되지 않도록 차단 목록(blocklist)에 추가되고 경고가 발생합니다. 팬아웃이 높은 서비스는 추가적으로 카나리아(canarying)를 사용할 수 있습니다. 즉, 각 요청을 더 작은 하위 집합의 서버에 보내고 해당(카나리아) 요청이 성공적으로 완료되면 나머지 시스템에 제출합니다. 지연 시간이 두 배가 되는 비용이 들지만 카나리아는 QoD로 인한 중단을 방지하는 데 매우 효과적입니다.

더 일반적으로 카나리아는 새 버전의 롤아웃을 보호합니다. 중단을 방지하기 위해 새 버전은 먼저 소수의 서버나 사용자("카나리아")에게 배포되며, 이 카나리아 세트는 더 큰 플릿(fleet)과 별도로 모니터링되어 편차(예: 성능 저하, 오류, 충돌)가 이전 버전을 실행하는 훨씬 더 큰 플릿의 신호("평균적으로 모든 것이 좋아 보임")에 의해 가려지지 않도록 합니다. 새 릴리스가 이 카나리아 단계를 통과해야만 결국 서버나 사용자의 100%에 도달할 때까지 점진적 롤아웃이 계속됩니다.

### 3.6.5 로드 밸런싱

대규모 서비스에서 서비스 수준 성능은 종종 많은 서버 중 가장 느린 응답자에 의존합니다. 검색 쿼리가 천 개의 샤드로 전송되면 응답 시간은 샤드 응답 시간의 최댓값입니다. 따라서 응답 시간 분산을 줄이는 것이 중요합니다.

높은 수준에서 로드 밸런싱은 서버당 작업량을 균등하게 해야 합니다. 예를 들어, 각 서버는 이상적으로 분산 스토리지 서비스에서 동일한 양의 스토리지를 담당해야 합니다. 서버의 용량이 불평등하거나 다양할 때 이 목표는 더 어려워집니다. 예를 들어 하드웨어가 다르거나, 동일한 서버에서 실행되는 다른 작업으로 인해 성능이 손상되거나, 서버가 요청 시점에 추가 작업(예: 압축 또는 실패 후 청크 재구성)을 수행 중일 수 있습니다. 요청은 비용이 매우 가변적일 수 있으므로 초당 요청의 균형을 맞추는 것이 부하의 균형을 달성하지 못할 수 있습니다. 가장 중요한 것은 실제 요청 부하가 고르게 분산되지 않을 수 있어, 많은 클라이언트가 단일 샤드에서 서비스되는 요청을 동시에 수행하는 핫스팟 현상(hotspotting)으로 이어질 수 있다는 것입니다.

좋은 성능을 달성하기 위해 로드 밸런서는 종종 로드 밸런싱되는 서비스의 협력을 필요로 합니다. 예를 들어 서버는 현재 부하를 보고할 수 있으며(비싼 요청이 올바르게 반영되도록), 로드 밸런서가 건강하지 않은 서버를 삭제할 수 있도록 하는 상태 확인을 지원할 수 있습니다. 가장 간단한 경우 상태 확인은 일반적인 요청(예: 웹 서버의 홈페이지 가져오기)일 수도 있고 서버가 구현한 특별한 요청(예: 구성의 일관성 확인)일 수도 있습니다. 어느 쪽이든 상태 확인은 버그가 있는 경우 의도치 않은 글로벌 중단을 일으킬 수 있으므로 신중하게 테스트해야 합니다.

컴퓨팅과 스토리지를 분리(disaggregate)할 수 있다면 로드 밸런싱이 더 간단해질 수 있으며, 이를 통해 스토리지 용량과 독립적으로 컴퓨팅 용량을 확장할 수 있습니다. 우리는 BigQuery 시스템에 대한 논의에서 실제 예를 보았습니다. 특정 샤드를 처리하는 서버가 지속적인 핫스팟을 경험하는 경우, 분리형 스토리지를 통해 해당 샤드를 동적으로 분할하여 요청 처리를 여러 서버에 분산시킬 수 있습니다.

### 3.6.6 합의

우리 모두는 합의가 중요하다는 것에 동의합니다! 분산 시스템에서 "합의(consensus)"는 참가자 그룹에 의한 시스템 상태에 대한 동의를 나타냅니다. 예를 들어, 특정 서비스가 가동 중입니까, 중단 중입니까? 이 두 서버 중 어느 것이 주(primary) 서버이고 어느 것이 백업(즉, 주 서버가 건강합니까, 아니면 백업이 역할을 인계받았습니까)입니까?

이론적으로 단일 주 서버가 있는 분산 시스템은 결과 시스템 가용성을 해당 서버의 가용성으로 제한합니다. 실제로 중앙 집중식 제어는 구현하기가 더 간단하고 일반적으로 더 반응이 빠른 제어 조치를 산출합니다. Google에서는 불가능한 경우를 제외하고는 대부분의 소프트웨어 인프라에 대해 중앙 집중식 제어 모델을 지향해 왔습니다.

합의가 필요한 애플리케이션(예: 구성 상태에 대한)의 경우 Chubby 락 서비스 [8]는 합의를 확립하는 간단한 방법을 제공합니다. Chubby는 굵은 입자(coarse-grained) 잠금 기능이 있는 POSIX 유사 파일 API를 제공합니다. 예를 들어 현재 주 서버의 신원을 포함하는 파일을 생성하여 Chubby를 사용하여 주 서버를 선출하는 것은 간단합니다. 주 서버가 되고자 하는 모든 엔티티는 쓰기 모드로 파일을 열려고 시도합니다. 그중 하나만 쓰기 모드 액세스 권한을 얻고 자신의 신원을 파일에 씁니다. 다른 모든 엔티티는 파일 수정 이벤트를 받고 이제 현재 주 서버에 대해 알게 됩니다. 주 서버의 "Keep-alive" 호출은 소유권을 유지합니다. 만료되면 다른 작성자의 시도가 성공하고 해당 서버가 새로운 주 서버가 됩니다. Apache ZooKeeper [52] 및 Kubernetes의 etcd [53]를 포함하여 여러 인기 있는 오픈 소스 시스템이 유사한 API를 구현합니다.

### 3.6.7 압축과 암호화

스토리지는 현대 데이터 센터에서 상당한 비용을 차지하며 압축은 이러한 비용을 크게 줄일 수 있습니다. 압축은 증가된 컴퓨팅 비용(압축 및 압축 해제용)을 줄어든 스토리지 비용과 교환합니다. 최신 CPU와 NIC에는 압축을 위한 하드웨어 지원이 포함되어 있어 이러한 트레이드오프가 보통 유리합니다. 일반적인 압축 알고리즘도 꽤 잘 수행할 수 있지만, 애플리케이션별 압축 방식은 훨씬 뛰어난 압축률이나 더 나은 압축 해제 속도를 달성할 수 있습니다. 예를 들어 Google의 검색 인덱스는 애플리케이션별 기술로 압축됩니다.

압축된 데이터는 유효 캐시 크기를 증가시키며, 이는 높은 처리량 요구 사항이 있는 서비스에 중요한 부수적 이점이 될 수 있습니다. 대부분의 압축 알고리즘의 경우 압축 해제가 압축보다 훨씬 저렴하므로 읽기 트래픽이 지배적인 애플리케이션에 압축된 캐시가 특히 유용합니다.

모든 데이터는 유휴 상태일 때 암호화되어야 합니다. 불행히도 좋은 암호화는 압축할 수 없는 거의 무작위적인 데이터를 생성합니다. 따라서 스토리지 시스템은 두 가지 이점을 모두 얻기 위해 이 둘을 신중하게 조정해야 합니다. 예를 들어 압축은 데이터가 암호화되기 전에 write() 호출의 일부로 클라이언트에서 수행될 수 있습니다.

### 3.6.8 테일(Tail) 내성

초대형 규모 시스템에서 병렬 작업의 완료는 하위 작업의 아주 작은 비율의 느린 실행으로 인해 지연될 수 있습니다. 시스템이 클수록 이러한 상황이 발생할 가능성이 높아집니다. 때로는 하위 작업의 실행을 소규모로 중복하면 속도가 크게 향상될 수 있습니다.

이 장의 앞부분에서 우리는 고성능과 가용성을 달성하기 위해 대규모 소프트웨어 시스템에서 일반적으로 사용되는 여러 기술을 설명했습니다. 시스템이 더 강력한 온라인 웹 서비스를 지원하도록 확장됨에 따라 우리는 이러한 기술이 허용 가능한 테일 레이턴시(Tail latency) 수준으로 서비스 전반의 응답성을 제공하기에는 불충분하다는 것을 발견했습니다. (테일 레이턴시는 가장 느린 요청의 지연 시간, 즉 지연 시간 분포의 꼬리를 나타냅니다.) 충분히 큰 규모에서는 개별 시스템 구성 요소의 모든 가능한 성능 가변성 소스를 제거하는 것은 대규모 내결함성 시스템의 모든 구성 요소를 무결점으로 만드는 것만큼이나 비실용적입니다 [54].

각 서버가 일반적으로 10ms 내에 응답하지만 99번째 백분위수 지연 시간이 1초인 가상 시스템을 생각해 보십시오. 즉, 사용자 요청이 그러한 서버 단 한 곳에서만 처리된다면 100건 중 1건의 사용자 요청이 느릴 것입니다(1초 소요). 그림 3.14는 이 가상의 시나리오에서 클러스터 크기가 증가함에 따라 아주 적은 비율의 지연 시간 이상치(outliers)가 서비스 수준 지연 시간에 어떻게 영향을 미치는지 보여줍니다. 사용자 요청이 병렬로 100개의 서버로부터 응답을 수집해야 한다면 사용자 요청의 63%가 1초 이상 걸릴 것입니다.

> **그림 3.14** 테일 이벤트에 따른 서비스 지연 시간 변동

단일 서버 수준에서 10,000건 중 1건의 요청만이 1초 이상의 지연 시간을 겪는 서비스의 경우에도, 그러한 서버가 2,000개인 서비스는 사용자 요청 5건 중 거의 1건이 1초 이상 걸리는 것을 보게 될 것입니다.

이러한 종류의 지연 시간 가변성을 허용하고 여전히 서비스 수준에서 낮은 테일 레이턴시를 제공하려면 특별한 노력이 필요합니다 [54]. 종종 이러한 기술은 내결함성을 위해 이미 프로비저닝된 리소스 복제를 활용하여 기존 시스템에 작은 추가 오버헤드만 도입합니다. 예를 들어 헤지된 요청(hedged requests)의 경우 클라이언트는 먼저 가장 적절하다고 생각되는 서버에 하나의 요청을 보낸 다음, 잠시 지연 후(예: 첫 번째 요청이 이 클래스의 요청에 대해 예상되는 95번째 백분위수 지연 시간보다 오래 보류될 때까지) 보조 요청을 보내는 것으로 대체합니다.

이와 별개로 네트워크와 스토리지의 지연 시간이 마이크로초 범위로 줄어들면서 지연 시간에 대한 시스템 최적화가 점점 더 중요해지고 있습니다. 지원 소프트웨어가 이렇게 작은 지연 시간에 맞춰 튜닝되지 않으면 마이크로초 장치의 모든 이점을 탕진하기가 비교적 쉽습니다 [55].

## 3.7 몇 가지 반복되는 주제들

WSC 서비스의 소프트웨어 개발은 여러 면에서 기존의 데스크톱/서버 모델과 다릅니다.

### 3.7.1 풍부한 병렬성

WSC 서비스는 데이터 및 요청 수준 병렬성 모두에서 비롯되는 많은 양의 병렬성을 보여줍니다. 일반적으로 문제는 병렬성을 찾는 것이 아니라 애플리케이션에 내재된 명시적인 병렬성을 관리하고 효율적으로 활용하는 것입니다. 데이터 병렬성은 클라우드 고객이 저장한 수십억 개의 파일이나 수십억 줄의 로그 라인과 같이 처리가 필요한 비교적 독립적인 레코드의 대규모 데이터 세트에서 발생합니다. 이러한 대규모 데이터 세트는 종종 각 병렬(하위) 작업에 대해 상당한 계산을 요구하며, 이는 통신 및 동기화 오버헤드를 숨기거나 견디는 데 도움이 됩니다. 마찬가지로 요청 수준 병렬성은 해당 서비스가 수신하는 초당 수백 또는 수천 건의 요청에서 비롯됩니다. 이러한 요청은 데이터의 읽기-쓰기 공유나 요청 간의 동기화를 거의 수반하지 않습니다. 예를 들어 검색 요청은 본질적으로 독립적이며 대부분 읽기 전용 데이터베이스를 다룹니다. 따라서 계산은 요청 내에서 그리고 서로 다른 요청 간에 쉽게 분할될 수 있습니다. 마찬가지로 서로 다른 GCP 사용자의 요청은 각 고객이 자신의 데이터에만 액세스하므로 본질적으로 서로 독립적이어서 데이터 파티셔닝 및 동시성의 자연스러운 단위를 생성합니다. 업데이트 속도가 낮은 한, 고도로 상호 연결된 데이터가 있는 시스템(예: 소셜 네트워킹 백엔드)조차도 높은 요청 병렬성의 이점을 누릴 수 있습니다.

### 3.7.2 워크로드의 진화

WSC 서비스 사용자는 비교적 잘 정의되고 안정적인 고수준 API에 의해 서비스의 구현 세부 정보로부터 격리되어 있어 새로운 소프트웨어를 빠르게 배포하기가 훨씬 쉽습니다. 예를 들어 Google Cloud 스택 전반에 걸쳐 매일 수천 개의 개별 바이너리가 릴리스됩니다.

이러한 환경은 빠른 제품 혁신을 선호하지만 시스템 설계자가 기존 서비스에서 유용한 벤치마크를 추출하기 어렵게 만듭니다. 또한 새로운 제품과 서비스가 등장할 수 있으며 고객의 성공은 데이터 센터의 결과 워크로드 구성에 직접적인 영향을 미칩니다. 예를 들어 YouTube와 같은 비디오 서비스는 비교적 짧은 기간에 번창했으며 데이터 센터의 컴퓨팅 사이클의 기존 대규모 고객과 매우 다른 요구 사항 세트를 제시하여 WSC의 최적 설계 지점에 잠재적으로 영향을 미칠 수 있습니다. 이 공격적인 소프트웨어 배포 환경의 유익한 부작용은 하드웨어 아키텍트가 변경 불가능한 코드 조각에 대해 좋은 성능을 제공해야 하는 부담을 굳이 가질 필요가 없다는 것입니다. 대신 아키텍트는 새로운 하드웨어 기능이나 장치를 활용하기 위해 중요한 소프트웨어 재작성 가능성을 고려할 수 있습니다.

### 3.7.3 플랫폼의 동질성과 추상화

데이터 센터는 일반적으로 소프트웨어 개발을 위한 대상 플랫폼으로서 온프레미스 서버나 데스크톱 및 랩톱보다 더 동질적인 환경입니다. 대규모 인터넷 서비스 운영은 일반적으로 특정 시점에 상대적으로 적은 수의 하드웨어 및 시스템 소프트웨어 구성을 배포합니다. 사실 무어의 법칙이 여전히 강세를 보이고 새로운 하드웨어 세대가 이전 플랫폼보다 두 배 빠를 수 있었던 하이퍼스케일러의 초기 시절에는, 특정 시점에 단 하나의 "오늘의 머신(machine of the day)"만 배포하고 다음 세대가 도착하면 다음 것으로 전환하는 것이 일반적이었습니다.

더 이상 그렇지 않습니다. 서버 플랫폼은 훨씬 더 천천히 개선되므로 특수 플랫폼(예: 코어당 메모리 대역폭 또는 최대 코어 수에 최적화됨)은 차세대 일반 플랫폼이 제공하는 것보다 특정 워크로드에 대해 더 큰 TCO 개선을 제공할 수 있습니다. 또한 서버 수명이 6년 이상으로 늘어남에 따라 더 많은 세대의 하드웨어가 동시에 서비스되고 있습니다. 제공업체가 특정 연도에 소수의 플랫폼만 도입하더라도(단순히 동일한 플랫폼의 다른 구성이 아니라 다른 CPU 유형, 마더보드 등), 언제든지 수십 개의 플랫폼이 데이터 센터 현장에서 라이브 상태일 것입니다.

이 하드웨어 이기종성(heterogeneity)을 처리하는 가장 좋은 방법은 관리 기능을 다른 곳으로 이동하여 시스템 스택의 대부분에서 숨기는 것입니다. 예를 들어 위에서 논의한 오프로드 카드는 가상화를 별도의 카드로 이동하여 서버별 코드를 줄이거나 제거합니다. 마찬가지로 6장에서는 서버 관리 및 모니터링(예: 팬 속도 제어)이 별도의 카드로 이동한 방법을 설명합니다. 7장에서는 소프트웨어 정의 인프라가 소프트웨어 래퍼 및 관리를 통해 하드웨어 복잡성을 어떻게 더욱 추상화하는지 논의할 것입니다.

WSC 제공업체는 여전히 온프레미스 제공업체보다 훨씬 더 균일한 환경을 봅니다. 온프레미스 시스템용 소프트웨어는 배포된 하드웨어 또는 소프트웨어 플랫폼에 대해 거의 가정할 수 없으며, 수천 또는 수백만 개의 하드웨어 및 시스템 소프트웨어 구성을 지원해야 할 필요성으로 인해 복잡성과 성능 특성이 저하될 수 있습니다.

### 3.7.4 장애 관리

인터넷 서비스 애플리케이션은 수십만 대의 머신에서 실행되므로 몇 시간마다 또는 그 이하로 어떤 유형의 장애가 예상됩니다(자세한 내용은 10장에서 제공됨). 결과적으로 데스크톱급 소프트웨어가 몇 달 또는 몇 년 동안 장애 없는 하드웨어 작동을 가정하는 것이 합리적일 수 있지만, WSC 서비스의 경우 이는 사실이 아닙니다. 이러한 서비스는 장애가 일상 생활의 일부인 환경에서 작동해야 합니다. 이상적으로 클러스터 수준 시스템 소프트웨어는 애플리케이션 수준 소프트웨어에서 대부분의 복잡성을 숨기는 계층을 제공해야 하지만, 모든 유형의 애플리케이션에 대해 그 목표를 달성하기는 어려울 수 있습니다.

풍부한 스레드 수준 병렬성과 더 동질적인 컴퓨팅 플랫폼은 데스크톱 시스템에 비해 인터넷 서비스의 소프트웨어 개발 복잡성을 줄이는 데 도움이 되지만, 규모, 하드웨어 장애 상황에서의 운영 필요성 및 워크로드 변경 속도는 반대 효과를 가져옵니다.

## 참고 문헌

1. J. Dean and S. Ghemawat, “MapReduce: Simplified data processing on large clusters,” 1, vol. 51, New York, NY, USA: Association for Computing Machinery, Jan. 1, 2008, pp. 107–113.
2. Apache Software Foundation, Apache Hadoop, https://hadoop.apache.org/.
3. R. Pike, S. Dorward, R. Griesemer, and S. Quinlan, “Interpreting the data: Parallel analysis with Sawzall,” Scientific Programming, vol. 13, no. 4, pp. 277–298, 2005.
4. F. Chang, J. Dean, S. Ghemawat, et al., “Bigtable: A distributed storage system for structured data,” in Proceedings of the 7th Symposium on Operating Systems Design and Implementation, ser. OSDI ’06, USA: USENIX Association, Nov. 6, 2006, pp. 205–218.
5. G. DeCandia, D. Hastorun, M. Jampani, et al., “Dynamo: Amazon’s highly available key-value store,” in Proceedings of twenty-first ACM SIGOPS Symposium on Operating Systems Principles, ser. SOSP ’07, New York, NY, USA: Association for Computing Machinery, Oct. 14, 2007, pp. 205–220.
6. S. Melnik, A. Gubarev, J. J. Long, et al., ”Dremel: Interactive analysis of web-scale datasets,” 1-2, vol. 3, VLDB Endowment, Sep. 1, 2010, pp. 330–339.
7. J. C. Corbett, J. Dean, M. Epstein, et al., “Spanner: Google’s globally-distributed database,” in Proceedings of the 10th USENIX Conference on Operating Systems Design and Implementation, ser. OSDI’12, USA: USENIX Association, Oct. 8, 2012, pp. 251–264.
8. M. Burrows, “The Chubby lock service for loosely-coupled distributed systems,” in Proceedings of the 7th Symposium on Operating Systems Design and Implementation, ser. OSDI ’06, USA: USENIX Association, Nov. 6, 2006, pp. 335–350.
9. A. Verma, L. Pedrosa, M. Korupolu, et al., “Large-scale cluster management at Google with Borg,” in Proceedings of the Tenth European Conference on Computer Systems, ser. EuroSys ’15, New York, NY, USA: Association for Computing Machinery, Apr. 17, 2015, pp. 1–17.
10. M. Tirmazi, A. Barker, N. Deng, et al., “Borg: The next generation,” in Proceedings of the 15th European Conference on Computer Systems, ser. EuroSys ’20, New York, NY, USA: Association for Computing Machinery, Apr. 17, 2020, pp. 1–14.
11. P. Mell, The NIST definition of cloud computing, https://csrc.nist.gov/pubs/sp/800/145/final, 2011.
12. Google Cloud, Compute Engine: Virtual Machines (VMs), https://cloud.google.com/products/compute.
13. Google Cloud, Google Kubernetes Engine (GKE), https://cloud.google.com/kubernetes-engine.
14. Google Cloud, Cloud Run - Serverless Container Platform.
15. Google Cloud, Cloud SQL: Relational Database Service, https://cloud.google.com/sql/.
16. HashiCorp, Terraform by HashiCorp.
17. Google, Google Workspace, https://workspace.google.com/sql.
18. S. Kanev, J. P. Darago, K. Hazelwood, et al., “Profiling a warehouse-scale computer,” in Proceedings of the 42nd Annual International Symposium on Computer Architecture, ser. ISCA ’15, New York, NY, USA: Association for Computing Machinery, Jun. 13, 2015, pp. 158–169.
19. Google, Organizing information - How Google Search Works, https://www.google.com/intl/en/search/howsearchworks/how-search-works/organizing-information/.
20. P. Nayak, Understanding searches better than ever before, 2019.
21. S. Brin and L. Page, “The anatomy of a large-scale hypertextual web search engine,” Computer Networks and ISDN Systems, vol. 30, no. 1-7, pp. 107–117, 1998.
22. A. Lottarini, A. Ramirez, J. Coburn, et al., “Vbench: Benchmarking video transcoding in the cloud,” in Proceedings of the 23th International Conference on Architectural Support for Programming Languages and Operating Systems, ser. ASPLOS ’18, New York, NY, USA: Association for Computing Machinery, Mar. 19, 2018, pp. 797–809.
23. T. D. Chandra, R. Griesemer, and J. Redstone, “Paxos made live: An engineering perspective,” in Proceedings of the twenty-sixth annual ACM Symposium on Principles of Distributed Computing, ser. PODC ’07, New York, NY, USA: Association for Computing Machinery, Aug. 12, 2007, pp. 398–407.
24. A. Vaswani, N. Shazeer, N. Parmar, et al., “Attention is all you need,” vol. 30, I. Guyon, U. V. Luxburg, S. Bengio, et al., Eds., 2017.
25. G. Team, R. Anil, S. Borgeaud, et al., “Gemini: A family of highly capable multimodal models,” arXiv preprint arXiv:2312.11805, 2023.
26. T. B. Brown, B. Mann, N. Ryder, et al., Language models are few-shot learners, 2020. arXiv: 2005.14165 [cs.CL].
27. OpenAI, J. Achiam, S. Adler, et al., “GPT-4 technical report,” 2024. arXiv: 2303.08774 [cs.CL].
28. H. Touvron, T. Lavril, G. Izacard, et al., “Llama: Open and efficient foundation language models,” 2023. arXiv: 2302.13971 [cs.CL].
29. Anthropic, Introducing the next generation of Claude, News: https://www.anthropic.com/news/claude-3-family, Mar. 2024.
30. U. Savagaonkar, N. Porter, N. Taha, B. Serebrin, and N. Mueller, “Titan in depth: Security in plaintext,” Google Cloud Identity and Security Blog, 2017.
31. Google Cloud, Shielded VM Overview, Google Cloud Security Documentation: https://cloud.google.com/docs/security/boot-integrity.
32. Google Cloud, Titanium underpins Google’s workload-optimized infrastructure, Google Cloud Blog: https://cloud.google.com/blog/products/compute/titanium-underpins-googles-workload-optimized-infrastructure.
33. Google Cloud, Google Cloud Titanium, https://cloud.google.com/titanium.
34. Google Cloud, Announcing PSP security protocol is now open source, Google Cloud Blog: https://cloud.google.com/blog/products/identity-security/announcing-psp-security-protocol-is-now-open-source.
35. Google Cloud, About Hyperdisk block storage, Compute Engine Documentation: https://cloud.google.com/compute/docs/disks/hyperdisks.
36. M. Dalton, D. Schultz, J. Adriaens, et al., “Andromeda: Performance, isolation, and velocity at scale in cloud network virtualization,” in 15th USENIX Symposium on Networked Systems Design and Implementation (NSDI 18), 2018, pp. 373–387.
37. Google Cloud, VM live migration process, Compute Engine Documentation: https://cloud.google.com/compute/docs/instances/live-migration-process.
38. Google Cloud, Introduction to object tables, BigQuery Documentation: https://cloud.google.com/bigquery/docs/object-table-introduction.
39. D. Hildebrand and D. Serenyi, Colossus under the hood: A peek into Google’s scalable storage system, https://cloud.google.com/blog/products/storage-data-transfer/a-peek-behind-colossus-googles-file-system?e=48754805, 2021.
40. Google Cloud, Inside Capacitor, BigQuery’s next-generation columnar storage format, Google Cloud Blog: https://cloud.google.com/blog/products/bigquery/inside-capacitor-bigquerys-next-generation-columnar-storage-format.
41. Google Cloud, Introduction to BigQuery autoscaling, BigQuery Documentation: https://cloud.google.com/bigquery/docs/slots-autoscaling-intro.
42. Google Cloud, In-memory query execution in Google BigQuery, Google Cloud Blog: https://cloud.google.com/blog/products/bigquery/in-memory-query-execution-in-google-bigquery.
43. V. Edara, Z. Zhao, K. Agrawal, and I. Gupta, “Network-compute co-design for distributed deep learning,” in Proceedings of the VLDB Endowment (PVLDB), vol. 14, 2021, pp. 3083–3091.
44. J. Levandoski, G. Casto, M. Deng, et al., “Biglake: BigQuery’s evolution toward a multi-cloud lakehouse,” in Companion of the 2024 International Conference on Management of Data, ser. SIGMOD/PODS ’24, New York, NY, USA: Association for Computing Machinery, Jun. 9, 2024, pp. 334–346.
45. T. Akidau, R. Bradshaw, C. Chambers, et al., “The dataflow model: A practical approach to balancing correctness, latency, and cost in massive-scale, unbounded, out-of-order data processing,” Proc. VLDB Endow., vol. 8, no. 12, pp. 1792–1803, Aug. 2015, issn: 2150-8097.
46. C. Chambers, A. Raniwala, F. Perry, et al., “Flumejava: Easy, efficient data-parallel pipelines,” in Proceedings of the 31st ACM SIGPLAN Conference on Programming Language Design and Implementation, ser. PLDI ’10, Toronto, Ontario, Canada: Association for Computing Machinery, 2010, pp. 363–375.
47. Google Cloud, No shard left behind: Dynamic work rebalancing in Google Cloud Dataflow, Google Cloud Blog: https://cloud.google.com/blog/products/gcp/no-shard-left-behind-dynamic-work-rebalancing-in-google-cloud-dataflow.
48. J. R. Hamilton et al., “On designing and deploying internet-scale services.,” in LISA, vol. 18, 2007, pp. 1–18.
49. E. Brewer, “Lessons from giant-scale services,” IEEE Internet Computing, vol. 5, no. 4, pp. 46–55, 2001.
50. W. Vogels, “Eventually consistent: Building reliable distributed systems at a worldwide scale demands trade-offs between consistency and availability,” 6, vol. 6, New York, NY, USA: Association for Computing Machinery, Oct. 1, 2008, pp. 14–19.
51. B. Beyer, C. Jones, J. Petoff, and N. R. Murphy, Site Reliability Engineering: How Google runs production systems. ” O’Reilly Media.”, 2016.
52. P. Hunt, M. Konar, F. P. Junqueira, and B. Reed, “Zookeeper: Wait-free coordination for internet-scale systems,” in 2010 USENIX Annual Technical Conference (USENIX ATC 10), 2010.
53. etcd - Distributed reliable key-value store, https://etcd.io/.
54. J. Dean and L. A. Barroso, “The tail at scale,” 2, vol. 56, New York, NY, USA: Association for Computing Machinery, Feb. 1, 2013, pp. 74–80.
55. L. Barroso, M. Marty, D. Patterson, and P. Ranganathan, “Attack of the killer microseconds,” Commun. ACM, vol. 60, no. 4, pp. 48–54, Mar. 2017.

**Open Access** 이 챕터는 크리에이티브 커먼즈 저작자 표시 4.0 국제 라이선스(http://creativecommons.org/licenses/by/4.0/) 조건에 따라 라이선스가 부여되며, 원저작자와 출처에 대해 적절한 크레딧을 제공하고, 크리에이티브 커먼즈 라이선스 링크를 제공하며, 변경 사항이 있는 경우 이를 표시하는 한, 어떠한 매체나 형식으로든 사용, 공유, 각색, 배포 및 복제를 허용합니다.

이 챕터의 이미지나 기타 제3자 자료는 자료에 대한 크레딧 라인에 달리 명시되지 않는 한 챕터의 크리에이티브 커먼즈 라이선스에 포함됩니다. 자료가 챕터의 크리에이티브 커먼즈 라이선스에 포함되지 않고 귀하의 의도된 사용이 법적 규정에 의해 허용되지 않거나 허용된 사용을 초과하는 경우, 저작권 소유자로부터 직접 허가를 받아야 합니다.