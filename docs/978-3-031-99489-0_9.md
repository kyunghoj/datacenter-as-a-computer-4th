# 9장. 에너지와 지속 가능성 (Energy and Sustainability)

**9.1 WSC에서의 에너지의 중요성**

웨어하우스 규모 컴퓨터(WSC)는 단 하나의 목적을 가지고 있습니다. 바로 전기 형태의 입력 에너지를 퍼블릭 클라우드, 웹 검색, 비디오 스트리밍, 소셜 미디어, 개인화된 비서, 데이터 분석 등과 같은 유용한 서비스 형태의 출력으로 변환하는 것입니다. 처리 과정의 부작용으로 모든 에너지는 열로 바뀝니다. 따라서 WSC 설계자에게는 효율성을 높일 수 있는 두 가지 큰 기회가 있습니다. 하나는 처리 에너지의 양을 줄이는 것이고, 다른 하나는 냉각 에너지의 양을 줄이는 것입니다.

20년 전, 업계의 상황은 여전히 열악했습니다. 일반적인 실제 데이터 센터와 서버는 모두 비효율적이었는데, 이는 역사적으로 효율성이 안정성, 성능, 자본 지출(CapEx)에 밀려 소홀히 다루어졌기 때문입니다. 그 결과, 평균적인 데이터 센터는 에너지의 3분의 2(!) 이상을 낭비했습니다. 대부분의 서버 내부에서는 실제 칩에 도달하기도 전에 플러그 전력의 최소 3분의 1이 비효율적인 전력 변환으로 손실되었고, 건물 자체 시스템이 서버만큼이나 많은 전력을 소비했습니다.

이런 종류의 비효율성은 비용이 많이 들었습니다. 왜 용인되었을까요? 흥미롭게도 대부분의 경우 아무도 그것을 알지 못했습니다. 50년 동안 비효율이 지속된 데에는 세 가지 요인이 기여했습니다.

*   1960년 상용 컴퓨팅의 초기에는 메인프레임 컴퓨터가 다루기 까다롭고 와트당 가격이 매우 비쌌기 때문에, 최적의 냉각 상태를 유지하는 데 비용을 아끼지 않았습니다. 게다가 메인프레임의 전력 소비량은 적었습니다.
*   데이터 센터 운영자들은 직업적 성공의 열쇠가 "무중단(no outages)"이라는 것을 알고 있었기 때문에 개선을 모색할 유인이 없었습니다. 데이터 센터를 운영하는 검증된 방식에 변화를 주는 것은 위험을 의미했고, 위험은 나쁜 것으로 간주되었습니다. 그 결과, 데이터 센터에 호스팅되는 서버는 훨씬 더 견고해지고 와트당 가격이 훨씬 저렴해졌지만, 데이터 센터 자체는 거의 변하지 않았습니다.
*   아무도 컴퓨팅의 TCO(총 소유 비용)를 보지 못했습니다. 새 서버 청구서는 IT 부서로 갔지만, 전력 및 냉각 청구서는 시설 부서로 갔습니다. 따라서 IT 구매자들은 약간 더 비싸지만 효율적인 서버가 실제로는 더 저렴하다는 사실을 몰랐기 때문에 서버 효율성을 요구하지 않았습니다.

이러한 방치된 역사의 긍정적인 면은 20년 전에는 상당한 개선을 쉽게 얻을 수 있었다는 점입니다. 데이터 센터와 서버 설계에 모범 사례를 적용하는 것만으로도 큰 위험 없이 전반적인 효율성을 2배 개선할 수 있었습니다. 따라서 2005년부터 2~3년이라는 짧은 기간 동안 최신 PUE(전력 사용 효율)는 1.2로 급격히 개선되었고, 그 이후 점진적으로 1.1 수준까지 개선되었습니다.

오늘날 최신 WSC는 전력 및 냉각 시스템에서 최적의 효율성에 상당히 근접해 있으며, 이론적으로 최적 효율성의 10~15% 이내에서 작동합니다. 따라서 앞으로 에너지 효율성에서 더 큰 이득을 얻을 기회는 기계 또는 전력 변환 전문가보다는 컴퓨터 과학자와 엔지니어(예: 소프트웨어 최적화)로부터 나와야 할 것입니다.

이 장에서는 다음과 같은 몇 가지 주요 주제를 다룹니다.

*   **전력과 에너지는 운영 비용을 최소화하기 위해 잘 관리되어야 합니다.** 높은 전력 소비는 더 높은 프로비저닝 비용, 전기 사용 비용 및 환경적 영향으로 이어집니다.
*   **낮은 사용률(utilization)에서의 에너지 효율성 개선은 엄청난 기회입니다.** IT 부하에서는 낮은 사용률이 일반적이며, 낮은 사용률에서는 에너지 효율성이 떨어지는 경향이 있습니다.
*   **에너지 최적화는 스택의 모든 계층에 걸친 복잡한 조정이 필요한 복잡한 엔드-투-엔드(end-to-end) 문제입니다.** 스택의 한 계층에서 최적화된 결정이 다른 계층의 노력을 망칠 수 있습니다. 진정한 진전을 위해서는 에너지 효율성에 대한 엔드-투-엔드 관점이 필요합니다.
*   **하드웨어 전문화는 에너지 효율성을 개선하는 귀중한 도구입니다.** 범용 CPU에서 무료로 효율성이 개선되던 시대는 끝났습니다. 반면 ASIC 및 전문화된 워크로드 맞춤형 설계는 범용성을 낮추는 대신 더 나은 성능과 에너지 효율성을 제공합니다.
*   **서버 사용률을 개선하면 에너지 효율성과 비용 효율성이 모두 향상됩니다.** 그 모든 서버에 비용을 지불하고 있다면, 유용한 일을 하도록 하는 것이 좋습니다.

---

**9.2 데이터 센터 인프라의 에너지 효율성**

WSC 에너지 효율성의 가장 포괄적인 정의는 특정 워크로드를 실행하는 데 사용된 에너지를 측정하는 것입니다(예: 1페타바이트 데이터 정렬). 불행히도 두 회사가 동일한 워크로드를 실행하는 경우는 없으며, 3장에서 논의한 바와 같이 실제 애플리케이션 혼합은 항상 변경되므로 WSC를 이런 방식으로 벤치마킹하기는 어렵습니다. 따라서 이러한 벤치마크가 고려되기는 했지만[23], 널리 사용되지는 않았습니다. 그러나 아래 방정식과 같이 독립적으로 측정하고 최적화할 수 있는 세 가지 요소의 곱으로 에너지 효율성을 보는 것은 유용합니다.

$$
효율성 = \frac{\text{연산량}}{\text{총 에너지}} = \frac{1}{PUE}_{(a)} \cdot \frac{1}{SPUE}_{(b)} \cdot \frac{\text{연산량}}{\text{부품에 전달된 에너지}}_{(c)}
$$

이 방정식에서 첫 번째 항 (a)는 시설 효율성을, 두 번째 항 (b)는 서버 전력 변환 효율성을, 세 번째 항 (c)는 서버의 아키텍처 효율성을 측정합니다. 다음 섹션에서 이 요소들에 대해 설명합니다.

**9.2.1 PUE**

전력 사용 효율(PUE: Power Usage Effectiveness)은 데이터 센터 건물 인프라 자체의 품질을 반영하며[1], 총 건물 전력 대 IT 전력(컴퓨팅, 네트워킹 및 기타 IT 장비가 소비하는 전력)의 비율을 나타냅니다. IT 전력은 "임계 전력(critical power)"이라고도 합니다. 데이터 센터의 다양한 부분에 전력을 공급하는 라인에 전기 계량기를 추가하여 PUE를 쉽게 측정할 수 있습니다.

$$
PUE = \frac{\text{시설 전력}}{\text{IT 장비 전력}}
$$

역사적으로 평균 데이터 센터의 PUE는 부끄러울 정도로 좋지 않았습니다. 2006년 연구[2]에 따르면 데이터 센터의 85%가 PUE 3.0 이상인 것으로 추정되었습니다. 다시 말해, 건물의 기계 및 전기 시스템이 실제 컴퓨팅 부하의 두 배에 달하는 전력을 소비했습니다. PUE가 2.0 이하인 곳은 5%에 불과했습니다. 이후 100개 이상의 데이터 센터를 대상으로 한 EPA 조사에서는 평균 PUE가 1.91로 보고되었습니다[3]. 2012년 업타임 인스티튜트(Uptime Institute)가 다양한 지역과 규모를 포괄하는 1,100개 이상의 데이터 센터를 대상으로 실시한 조사에서는 평균 PUE 값이 1.8에서 1.89 사이로 보고되었습니다[4].

그림 9.1은 2012년 연구 결과의 분포를 보여줍니다. 대규모 시설이 가장 큰 개선을 보였으며, 소규모 데이터 센터(서버 500대 미만)의 약 절반은 여전히 PUE를 측정하지 않고 있었습니다.

2016년 LBNL 보고서는 하이퍼스케일 데이터 센터(웨어하우스 규모 컴퓨터)의 PUE는 1.13, 기존 데이터 센터는 1.6에서 2.35라고 언급했습니다[5]. 2022년 업타임 인스티튜트의 가장 최근 조사[6]에 따르면 평균 PUE는 2018년 이후 대체로 정체 상태입니다(그림 9.2).

이와 대조적으로 WSC 운영자들은 2005년 Google을 시작으로 설계의 PUE를 빠르게 개선했으며, 많은 운영자가 PUE를 보고하기 시작했습니다. 규모가 커지면 효율성의 중요성을 정당화하기 쉽습니다. 예를 들어, Google은 에너지 효율성 조치로 현재까지 수십억 달러를 절약했습니다. Google의 초기 PUE 보고서는 2008년 전 세계 평균 1.2를 보여주었고, 이후 수년에 걸쳐 1.09로 개선되었습니다(그림 9.3)[7]. 연간 PUE 값의 피크는 냉각 오버헤드가 더 높은 여름철에 해당합니다.

**9.2.2 PUE 지표의 문제점**

The Green Grid는 PUE 측정 및 보고 방법에 대한 상세 지침을 게시하지만[8], 게시된 많은 값이 항상 비교 가능한 것은 아니며 때로는 마케팅 문서에서 최상의 값을 보여주기 위해 PUE 값을 사용하기도 합니다. PUE 값을 왜곡할 수 있는 가장 큰 요인은 다음과 같습니다.

*   **모든 PUE 측정에 동일한 오버헤드가 포함되는 것은 아닙니다.** 예를 들어, 일부는 1차 변전소 변압기의 손실이나 PDU에서 랙으로 공급되는 전선의 손실을 포함할 수 있지만, 다른 일부는 그렇지 않을 수 있습니다. Google은 알려진 모든 소스를 포함하는 포괄적인 오버헤드 정의를 사용하여 전체 평균 PUE 1.09를 보고하고 있지만, 더 "낙관적인" 오버헤드 정의를 사용하면 PUE 1.06을 보고할 수도 있었습니다[7]. PUE가 유용한 지표가 되려면 데이터 센터 소유자와 운영자는 측정 및 보고 시 The Green Grid 지침[8]을 준수하고 결과 도출에 사용된 방법에 대해 투명해야 합니다.
*   **순간 PUE는 평균 PUE와 다릅니다.** 하루 또는 일년 동안 시설의 PUE는 상당히 달라질 수 있습니다. 예를 들어 추운 날에는 낮을 수 있지만 여름에는 상당히 높을 수 있습니다. 일반적으로 연간 평균이 비교에 더 유용합니다.
*   **일부 PUE는 실제 측정이 아닙니다.** 벤더들은 종종 최적의 작동 조건과 공칭 성능 값을 사용하여 계산된 "설계(design)" PUE를 게시하거나, 최적의 조건에서 짧은 부하 테스트 중에 측정된 값을 게시합니다. 일반적으로 세부 정보 없이 제공되는 PUE 값은 이 범주에 속합니다.
*   **일부 PUE 값은 오차 범위가 큽니다.** 이는 드문 수동 판독이나 거칠게 배치된 계량기에 기반하여 일부 PUE 항을 측정 대신 추정해야 하기 때문입니다. 예를 들어, 시설에 UPS 다운스트림의 임계 부하를 측정하는 단일 계량기만 있는 경우 PDU 및 저전압 배전 손실을 추정해야 합니다.

실제로 PUE 값은 실시간으로 측정되어야 합니다. 이는 일일 및 계절별 변화에 대한 더 나은 그림을 제공할 뿐만 아니라 운영자가 일상적인 운영 중 비정상적인 판독 값에 반응할 수 있게 해줍니다. 예를 들어, 누군가 주기적인 테스트 후 백업 펌프 세트를 켜 둔 상태로 방치했을 수 있습니다. 실시간 지표를 사용하면 운영팀은 예상 PUE 값과 실제 PUE 값을 비교하여 이러한 문제를 신속하게 수정할 수 있습니다.

PUE 지표는 부하가 감소함에 따라 일반적으로 PUE가 악화되기 때문에 항상 더 나은 에너지 성능을 나타내는 것은 아니라는 비판도 받습니다. 예를 들어 데이터 센터의 PUE가 5MW 부하에서 2.0이고 10MW 부하에서 1.5라고 가정해 봅시다. 주어진 워크로드를 5MW 부하로 실행할 수 있다면(예: 최신 서버 사용), PUE가 열등하더라도 에너지 효율이 더 높은 것이 분명합니다. 그러나 이 비판은 PUE가 이 장의 초반에 제시된 효율성 방정식의 세 가지 요소 중 하나일 뿐이라는 점을 지적하는 것일 뿐이며, 전반적으로 PUE 측정의 광범위한 채택은 지난 50년 동안 데이터 센터 효율성의 가장 큰 개선을 이끈 원동력이었다고 할 수 있습니다.

**9.2.3 에너지 비효율성의 분석**

5장의 데이터 센터 전력 시스템 섹션에서는 전력이 데이터 센터 플로어에 접근함에 따라 효율적으로 변환되는 과정을 설명합니다. 처음 두 단계의 변환은 들어오는 고전압 전력(110kV 이상)을 중간 전압 배전 레벨(일반적으로 50kV 미만)로 낮추고, 서버 플로어에 더 가까워지면 저전압(북미의 경우 일반적으로 480V)으로 낮춥니다. 두 단계 모두 매우 효율적이어야 하며, 각 단계의 손실은 일반적으로 0.5% 미만입니다.

건물 내부에서는 기존의 이중 변환 UPS가 가장 많은 전기 손실을 일으키며, 최적 부하에서 88-94% 효율로 작동하고 부분 부하 시(일반적인 경우)에는 훨씬 낮습니다. 고효율 UPS는 약 97%의 효율에 도달할 수 있으며, 랙 내 UPS 및 배터리는 이를 더욱 개선할 수 있습니다. PDU에서의 마지막 변환 단계는 추가로 0.5%의 손실을 차지하며, 저전압 전력(110 또는 220V)을 랙으로 공급하는 케이블에서 1~3%의 전력이 손실될 수 있습니다. (대규모 시설은 이중 마루 면적이 가로세로 100미터가 넘을 수 있으므로 전력 케이블이 꽤 길 수 있음을 상기하십시오.) 따라서 대부분의 최신 WSC 설계는 서버 열을 따라 전력을 전달하기 위해 버스 바(bus bar)를 사용하며, 버스 바와 랙을 연결하는 짧은 케이블만 사용합니다.

그림 9.4는 PUE가 1.5인 기존의 저효율 데이터 센터에서 에너지 손실의 일반적인 분포를 보여줍니다. 명확성을 위해 이 분석에서는 서버 팬이나 서버 보드의 전기 저항으로 인한 추가 손실은 생략했습니다.

데이터 센터 에너지 비효율성의 가장 큰 부분은 냉각 오버헤드에서 비롯되며, 칠러(chiller)가 가장 큰 주범입니다. 평균적인 기존 데이터 센터에서 냉각 손실은 전력 손실보다 약 3배 더 크므로 효율성 개선을 위한 가장 유망한 목표입니다. 모든 냉각 손실이 제거되면 PUE는 1.18로 떨어지지만, 무손실 UPS 시스템은 PUE를 1.35로만 낮춥니다. 일반적으로 시설의 PUE가 높을수록 전체 손실 중 냉각 시스템에서 발생하는 비율이 높습니다[9]. 직관적으로 전력 분배 시스템을 잘못 다루는 방법은 제한적이지만, 냉각을 잘못 다루는 방법은 훨씬 더 많습니다.

**(그림 9.4: 평균 저효율 데이터 센터의 에너지 손실)**
*   IT 부하의 백분율로 표시된 오버헤드 (Total ~50% overhead implied by PUE 1.5)
*   냉각 플랜트 (26%), 팬 코일 (6%), 전기 손실 (14%), 기타 오버헤드 (3%)

**9.2.4 데이터 센터 효율성 개선**

이전 장에서 논의했듯이 효율성을 고려한 신중한 설계는 PUE를 크게 개선할 수 있습니다[10], [11]. 주요 단계는 다음과 같습니다.

*   **신중한 공기 흐름 처리:** 서버에서 배출되는 뜨거운 공기를 차가운 공기와 격리하고, 냉각 코일로 가는 경로를 짧게 유지하여 차갑거나 뜨거운 공기를 장거리로 이동시키는 데 에너지를 거의 소비하지 않도록 합니다.
*   **온도 상승:** 냉기 통로(cold aisle)를 18–20°C가 아닌 27–30°C로 유지합니다. 온도가 높을수록 데이터 센터를 효율적으로 냉각하기가 훨씬 쉽습니다. 실제로 20°C의 흡입 온도를 필요로 하는 서버나 네트워크 장비는 거의 없으며, 이 범위의 통로 온도 상승이 더 많은 구성 요소 고장을 유발한다는 증거는 없습니다[12], [13], [14].
*   **프리 쿨링(Free cooling):** 대부분의 온화한 기후에서 프리 쿨링은 칠러 가동 시간을 대부분 제거하거나 칠러를 완전히 없앨 수 있습니다.
*   **더 나은 전력 시스템 아키텍처:** 5장에서 논의한 것처럼 고효율 장비를 선택하여 UPS 및 배전 손실을 크게 줄입니다.

2009년 4월, Google은 2005년에 구축된 컨테이너 기반 데이터 센터의 비디오 투어를 포함하여 데이터 센터 아키텍처에 대한 세부 정보를 처음으로 공개했습니다[15]. 2008년 이 데이터 센터는 1.24라는 최신 연간 PUE를 달성했지만, 기존 데이터 센터와 다른 점은 위에 나열된 처음 네 가지 원칙을 적용했다는 점뿐이었습니다. 오늘날 대규모 데이터 센터, 특히 클라우드 운영자의 데이터 센터는 일반적으로 1.2 미만의 PUE를 특징으로 합니다. 불리한 기후에서도 오늘날의 PUE는 2008년의 최신 PUE보다 낮습니다. 예를 들어 월 평균 기온이 25°C 아래로 거의 떨어지지 않는 싱가포르의 Google 데이터 센터는 여전히 연간 PUE 1.13을 달성합니다[16].

이 네 가지 단계는 구현하기 쉽지만, 더 정교한 접근 방식은 상당한 추가 효율성을 잠금 해제할 수 있습니다. 특히 유망한 초기 결과에도 불구하고 AI 제어 냉각은 아직 일반적이지 않습니다. 기계 학습(Machine Learning)은 데이터 센터의 냉각 인프라 운영을 제어하는 방법이 많기 때문에 냉각 최적화에 적합합니다. 냉각 오버헤드는 전체 시스템 부하, 작동 중인 칠러 수, 외부 풍속과 같은 많은 시스템 매개변수 및 환경 요인과 비선형 관계를 가집니다. 예를 들어 냉각탑이 10개 있고 40% 부하로 실행 중이라면, 10개 모두를 40% 속도로 실행해야 할까요, 아니면 4개를 100%로 실행하고 나머지는 꺼야 할까요? 이러한 변수와 전체 냉각 오버헤드 간의 관계를 직관적으로 파악하기는 어렵습니다. 게다가 WSC는 동적입니다. 워크로드가 변경되고 장비가 매일 반입되거나 반출됩니다. 데이터 센터 냉각 제어 루프를 운영하는 데 사용되는 센서 네트워크에서 정기적으로 수집되는 대량의 데이터는 기계 학습 시스템이 건물 및 워크로드별 최적화를 발견하여 추가적인 PUE 효율성을 찾을 수 있게 해줍니다. 그러한 시스템 중 하나는 Google 데이터 센터의 여름철 냉각 오버헤드를 40% 줄였습니다[17]. 이러한 결과가 시사하듯이 ML은 향후 작업을 위한 유망한 분야입니다.

**9.2.5 PUE를 넘어 SPUE로**

이 섹션의 시작 부분에 있는 에너지 효율성 공식을 상기해 보십시오.

$$
효율성 = \frac{\text{연산량}}{\text{총 에너지}} = \frac{1}{PUE}_{(a)} \cdot \frac{1}{SPUE}_{(b)} \cdot \frac{\text{연산량}}{\text{부품에 전달된 에너지}}_{(c)}
$$

지금까지 우리는 시설 오버헤드인 (a) 항에 대해 논의했습니다. 두 번째 항 (b)는 PUE와 유사한 지표인 서버 PUE(SPUE)를 사용하여 서버 또는 기타 IT 장비 내부의 오버헤드를 설명합니다. SPUE는 총 서버 입력 전력 대 유용한 전력의 비율로 구성되며, 여기서 유용한 전력은 CPU, DRAM, 가속기, NIC, I/O 카드, SSD 등과 같이 계산에 직접 관여하는 전자 부품이 소비하는 전력만 포함합니다. 서버의 전원 공급 장치(PSU), 전압 조정 모듈(VRM), 마더보드의 전원 트레이스 및 냉각 팬에서 상당한 양의 전력이 손실될 수 있습니다. 5장에서 논의한 바와 같이 서버 내부의 손실은 전체 업스트림 데이터 센터 전력 트레인의 손실을 초과할 수 있습니다.

SPUE 측정은 PUE처럼 아직 표준화되지 않았지만 정의하기는 꽤 간단합니다. 거의 모든 장비에는 두 가지 변환 단계가 포함됩니다. 첫 번째 단계는 입력 전압(일반적으로 110-220 VAC)을 로컬 DC 전류(일반적으로 12 또는 48/54V)로 변환하고, 두 번째 단계에서는 VRM(마더보드에 장착된 소형 DC-DC 변압기)이 이를 CPU나 DRAM에서 사용하는 훨씬 낮은 전압으로 변환합니다. (첫 번째 단계는 전원 공급 장치 내부에서 일반적으로 380 VDC로의 추가적인 내부 변환을 필요로 합니다.) 세기 전환기에는 1.6~1.8의 SPUE 비율이 흔했습니다. 많은 서버 전원 공급 장치의 효율이 80% 미만이었고, 많은 마더보드가 비슷하게 비효율적인 VRM을 사용하여 전기 변환 손실로 입력 전력의 25% 이상을 잃었습니다. 대조적으로 오늘날 상용 AC 입력 전원 공급 장치는 94%의 효율을 달성하고 VRM은 96%의 효율을 달성합니다(5장 참조). 따라서 최신 SPUE는 1.11 이하입니다. 예를 들어 Google은 일반적인 12V DC 전압 대신 48 VDC 전압 랙 배전 시스템[18], [19]을 사용하여 에너지 손실을 30% 이상 더 줄입니다.

그림 9.5는 2024년경 일반적인 Google 서버의 SPUE 오버헤드를 보여줍니다. 데이터 센터와 달리 여기서는 전기 손실이 냉각을 지배합니다. 서버 팬 전력은 5%에 불과하지만 전력 공급 중 19%가 손실됩니다. 관련된 전류가 높기 때문에 이러한 손실은 최적화하기 더 어렵습니다. 예를 들어 CPU 바로 옆에 배치된 전압 조정기(VR)는 보드의 입력 전압(이 서버의 경우 54V)을 CPU 공급 전압(0.9V)으로 변환하여 500A를 초과하는 전류를 발생시킵니다. 일부 CPU는 1.8V의 외부 공급 전압을 실제 내부 전압(CPU 주파수에 따라 가변적일 수 있음)으로 낮추기 위해 칩 내장 VRM을 가지고 있으므로, 전력 변환 손실의 일부는 칩 내에서 발생할 수 있으며 SPUE에 포함되어야 합니다.

지난 10년 동안 CPU 공급 전압은 감소하여 연산당 줄(Joules per operation)로 측정되는 에너지 효율성이 크게 향상되었습니다. 불행히도 출력 전압이 낮을수록 고효율 전압 조정기를 설계하기가 더 어려워지기 때문에 VR 손실은 증가했습니다. 또한 좁은 전원 트레이스를 통해 높은 저전압 전류가 흐르면서 인쇄 회로 기판(PCB) 자체에서 상당한 전력 손실이 발생할 수 있습니다.

PUE와 SPUE의 곱은 WSC의 엔드-투-엔드 전기 기계적 효율성, 즉 진정한(또는 총) PUE(TPUE)에 대한 정확한 평가를 구성합니다. 2005년경 일반적인 데이터 센터의 일반적인 TPUE는 3.2 이상이었습니다. 즉, 생산적인 1와트당 최소 2.2W가 추가로 소비되었습니다. 대조적으로 평균 PUE가 1.11이고 평균 SPUE가 1.23인 현대적인 시설은 1.35의 TPUE를 달성합니다. 신기술과 결합된 냉각 및 전력 시스템 설계에 대한 세심한 주의는 오버헤드 전력 소비를 10분의 1 수준으로 줄였습니다.

---

**9.3 컴퓨팅의 에너지 효율성**

지금까지 우리는 전기 기계적 용어인 효율성 방정식의 (a)와 (b) 항에 대해 논의했으며, 전자 부품에 전달된 전기가 얼마나 효율적으로 유용한 작업으로 변환되는지를 측정하는 서버의 아키텍처 효율성인 (c) 항은 거의 무시했습니다. 최첨단 시설에서 전기 기계 구성 요소는 개선 가능성이 제한적입니다. Google의 TPUE 약 1.2-1.3은 전기 기계적 오버헤드가 없더라도 총 에너지 효율성이 20-25%만 향상된다는 것을 의미합니다. 대조적으로 컴퓨팅의 에너지 효율성은 지난 반세기 동안 약 1.5년마다 두 배로 증가했습니다[20]. CMOS 스케일링 문제로 인해 지난 10년 동안 이러한 속도가 크게 감소했지만[21], 여전히 전기 기계적 효율성 개선을 앞지르고 있습니다. 이 장의 나머지 부분에서는 컴퓨팅의 에너지 및 전력 효율성에 초점을 맞춥니다.

**9.3.1 에너지 효율성 측정**

이상적으로 우리는 데이터베이스 쿼리나 Google 검색과 같은 특정 결과를 생성하는 데 소비된 에너지를 측정하고 싶어 합니다. 많은 산업 벤치마크가 이 수준에서 에너지 효율성을 측정하려고 합니다. 고성능 컴퓨팅(HPC)에서 Green 500[22] 벤치마크는 LINPACK을 사용하여 세계 최고 슈퍼컴퓨터의 에너지 효율성 순위를 매깁니다. 유사하게 Joulesort[23]는 아웃 오브 코어(out-of-core) 정렬을 수행하는 전체 시스템 에너지를 측정합니다. SPECpower[24]는 서버급 시스템에 초점을 맞추고 엔터프라이즈 Java 플랫폼에서 일반적인 비즈니스 애플리케이션을 실행하는 시스템의 성능 대 전력 비율을 계산합니다.

머신 러닝의 경우, MLCommons는 추론 및 학습을 위한 ML 성능 벤치마크 세트를 정의합니다[25]. 이러한 벤치마크는 학계와 산업계의 광범위한 지원을 받아 다양한 ML 워크로드 전반에 걸쳐 비교할 수 있는 명확한 지표와 일관된 방법론을 제공합니다. 이 기반 위에 구축된 MLPerf Power 벤치마크는 MLPerf의 성능 측정값을 벤치마크 실행을 위한 에너지 측정값(또는 추정치)과 비교합니다. 비교 가능성을 위해 전력 측정은 측정 지속 시간, 샘플링 빈도 및 정확도와 같은 엄격한 기준을 따라야 합니다. 학습 워크로드의 경우 에너지 효율성 점수는 MLPerf Training 벤치마크를 기반으로 하며 Samples/J로 보고됩니다. 추론의 경우 점수는 MLPerf Inference를 기반으로 하며 결과는 1/J로 보고됩니다.

ML과 같이 상대적으로 새로운 분야에서는 연간 효율성 개선이 일반 컴퓨팅과 같은 성숙한 분야보다 수십 배 더 높습니다. MLPerf Power 저자들은 주로 모델 개선에 힘입어 3년 동안 벤치마크가 에너지 효율성을 100배 이상 개선했다고 관찰합니다[26]. 하드웨어 측면에서 GPU 및 TPU의 아키텍처 개선은 세대마다 상당한 효율성 이점을 제공했으며, 이는 가까운 미래에 빠른 진전이 계속될 것임을 시사합니다.

**9.3.2 에너지 효율성 개선: 에너지 비례성 (Energy Proportionality)**

**9.3.2.1 전체 서버군(Fleet) 사용률 통계**
그림 9.6은 2013년과 2024년 두 Google 클러스터의 평균 CPU 사용률을 보여주며, 각 클러스터에는 20,000대 이상의 서버가 있습니다. 왼쪽 클러스터는 여러 유형의 워크로드를 혼합한 일반적인 Google 클러스터를 나타냅니다. 이러한 WSC는 온라인 서비스가 부하의 일일 변동을 겪기 때문에 평균 사용률이 낮은 경향이 있습니다. 오른쪽 클러스터는 대규모 연속 배치(batch) 워크로드가 실행되는 Google의 가장 많이 사용되는 클러스터 중 하나를 나타냅니다. 이 클래스의 워크로드는 효율적으로 스케줄링되어 높은 평균 사용률에 도달할 수 있습니다.

수년에 걸쳐 사용률을 개선하기 위한 지속적인 노력은 성과를 거두었습니다. 2013년 클러스터는 대부분의 시간을 10-50% CPU 사용률 범위에서 보냈지만, 2024년에는 40-60%로 증가했습니다.

2024년 Google 내부 워크로드를 실행하는 더 큰 클러스터 샘플 전체에서 우리는 평균 CPU 사용률이 50%인 정규 분포와 더 유사한 유사한 분포를 봅니다(그림 9.7). 그림에 나타난 클러스터는 전체 서버군의 11%를 차지하며, 사용률은 3개월 동안 측정되었습니다. 따라서 그림 9.6은 상당히 다른 사용률을 가진 두 개의 개별 클러스터를 보여주었지만, 그림 9.7은 전체 서버군 평균에 대한 좋은 대리 지표입니다.

평균 사용률 50%는 얼마나 좋은 것일까요? 달성 가능한 최대 사용률은 여러 요인에 의해 제한됩니다.

*   부하가 사용자 활동에 해당하는 일일 패턴을 보이는 경우, 일일 최고점 대 최저점 비율이 달성 가능한 사용률을 제한합니다. 예를 들어 일일 최저점이 일일 최고점의 60%이고 사용량이 최고점과 최저점 사이에서 고르게 떨어진다면(또는 떨어진다면), 최고점에서 100%로 실행한다고 가정할 때 최대 사용률은 80%가 됩니다.
*   서비스에는 종종 지연 시간 목표가 있으며, 요청 대기열 및 코어 또는 메모리 포화로 인해 사용률이 높을수록 지연 시간이 증가합니다. 지연 시간 요구 사항이 엄격할수록 지연 시간이 너무 길어지는 CPU 사용률 지점은 낮아집니다. 잘 최적화된 서비스는 70-90% 사용률에서 실행될 수 있으므로 좋은 경험 법칙은 80%를 한계로 가정합니다.
*   국지적 중단을 처리하기 위해 서비스는 $N + M$ 프로비저닝으로 실행됩니다. 최소 $N + 1$ (즉, $M = 1$, 하나의 서비스 인스턴스가 다운되어도 전체 과부하가 발생하지 않음)입니다. 10개의 서비스 인스턴스로 $N + 1$로 프로비저닝된 서비스의 경우 중단이 드물다면 최대 사용률은 90%가 됩니다.

위의 가정을 사용하면 현실적으로 달성 가능한 최대 사용률은 $80\% \times 80\% \times 90\% = 58\%$로 떨어집니다. 배치 부하는 사용률을 더욱 개선할 수 있습니다. 예를 들어 배치 부하가 용량의 20%를 차지하고 밤에 8시간 동안 실행되는 경우 사용률은 추가로 $20\%/3 = 6.6\%$ 개선될 수 있습니다. 따라서 대규모 소비자 서비스의 경우 평균 월간 사용률 65-70%는 상한선에 가깝습니다. 따라서 Google의 내부 서비스 평균이 50%인 경우 사용률은 아마도 1.2배 더 향상될 수 있지만 그 이상은 아닙니다.

대조적으로 일반적인 IT 부하는 훨씬 낮은 사용률로 실행됩니다. 그림 9.8은 고객 워크로드를 포함하는 GCE 영역 샘플의 사용률을 보여줍니다. 이러한 워크로드는 평균 33.5%의 훨씬 낮은 사용률을 보입니다. 이 수치가 낮아 보이지만 드문 일은 아닙니다. 다른 연구(엔터프라이즈 데이터 센터 사용률, 알리바바, AWS, Azure)에서도 6%-25% 범위의 유사하게 낮은 사용률을 보고합니다[28–30].

아무도 돈 낭비를 좋아하지 않는데 엔터프라이즈 사용률이 왜 그렇게 낮을까요? 첫째, 대부분의 엔터프라이즈 워크로드는 확장되지 않습니다. 사용자가 거의 없고 단일 VM에서 실행됩니다. 예를 들어 회사는 하루에 몇 번만 사용되는 급여 애플리케이션을 가지고 있을 수 있습니다. 둘째, 엔터프라이즈 애플리케이션은 종종 더 높은 가용성 요구 사항을 가지므로 급여 애플리케이션에는 사용률이 낮은 주 서버뿐만 아니라 재해 복구를 위해 완전히 사용되지 않는 백업 서버가 있을 수 있습니다. 마지막으로 사용률을 높이는 것은 인력 집약적이며, 소규모 애플리케이션의 경우 그 노력의 비용이 절약된 서버 비용보다 높을 수 있습니다.

그 결과, 엔터프라이즈 서버의 활동 프로필은 WSC 서버가 가장 비효율적인 부하 영역에서 대부분의 시간을 보낸다는 점에서 최신 서버의 에너지 효율성 프로필과 불일치하게 됩니다.

에너지 소비를 줄이는 한 가지 유혹적인 아이디어는 서버가 유휴 상태일 때 절전 상태로 전환하는 것입니다. 그러나 서버는 거의 완전히 유휴 상태가 아닙니다. 단지 낮은 사용률로 실행될 뿐입니다. Gmail과 같은 하이퍼스케일 서비스의 경우 이는 일일 사용 패턴에 의해 결정됩니다. 일일 최저점에서도 사람들은 여전히 Gmail을 사용합니다. 엔터프라이즈 워크로드는 완전히 유휴 상태일 가능성이 더 큽니다. 예를 들어 소규모 회사의 내부 전화번호부를 제공하는 애플리케이션은 업무 시간 외에는 요청을 받지 않을 것입니다. 그러나 진정한 유휴 시간의 긴 기간을 만들어내는 것은 어렵습니다. 밤에도 VM에는 가끔 실행되는 많은 시스템 프로세스가 포함되어 있으며 완전히 유휴 상태로 만들려면 수동 개입(예: 정기 종료 예약)이 필요합니다. Tickless 커널 프로젝트[31]는 유휴 상태를 생성하고 유지하는 것이 얼마나 어려운지에 대한 예를 제공합니다. 퍼블릭 클라우드 워크로드는 물리적 서버가 수십 또는 수백 개의 VM을 호스팅하기 때문에 이를 더욱 어렵게 만듭니다. 모두가 비교적 낮은 사용률이라도 밀리초마다 일부 계산이 발생하므로 서버는 절전 상태로 들어갈 수 없습니다.

개발자가 VM 기반 모델에서 PaaS(Platform as a service) 또는 FaaS(Functions as a service) 모델로 이동할 수 있다면 상황이 개선됩니다. Google Cloud Run, Cloud Functions 또는 AWS Lambda가 그 예입니다. 섹션 9.3.2.8에서는 소프트웨어 기반으로 사용률을 개선하려는 노력에 대해 설명합니다.

**9.3.2.2 사용률과 에너지 효율성**
분명히 동일한 애플리케이션 바이너리라도 서버 아키텍처에 따라 다른 양의 전력을 소비할 수 있으며, 마찬가지로 소프트웨어 성능 튜닝에 따라 애플리케이션이 서버 용량을 더 많이 또는 적게 소비할 수 있습니다. 또한 시스템 효율성은 사용률에 따라 달라질 수 있습니다. 낮은 사용률 수준에서 컴퓨팅 시스템은 최대 사용률에서 실행될 때보다 훨씬 덜 효율적인 경향이 있습니다.

그림 9.9는 2024년 11월 기준 다양한 사용률에서 Dell PowerEdge R7725 서버의 SPECpower 벤치마크 결과를 보여줍니다[27]. 막대는 ops/W 단위의 에너지 효율성을 나타내고 선은 전력 소비를 나타냅니다. 둘 다 다양한 사용률 수준에 대해 표시됩니다. 목표 부하가 감소함에 따라 시스템 전력이 성능보다 더 천천히 감소하기 때문에 서버의 효율성(성능 대 전력 비율)은 눈에 띄게 떨어집니다. 예를 들어 30% 부하에서 전력 소비는 50% 이상이므로 에너지 효율성은 피크 부하 때보다 1.6배 이상 나쁩니다. 게다가 시스템이 유휴 상태일 때 여전히 138W, 즉 피크 전력 소비의 16%를 소비하고 있습니다.

이 결과는 서버 하드웨어 및 펌웨어 설정이 벤치마크를 위해 신중하게 조정되었기 때문에 최상의 효율성을 보여줍니다. 예를 들어 시스템은 메모리 프리페칭(prefetching), 터보 모드 및 투기적 실행(speculative execution)을 비활성화할 수 있는데, 이는 모두 피크 성능을 증가시키지만 반드시 에너지 최적의 방식은 아닙니다. 실제 서버는 성능이나 지연 시간 영향 때문에 이러한 설정을 사용하지 못할 수 있습니다. 그 결과, 유휴 상태에 가까운 부하에서의 전력 소비는 16%보다 훨씬 높으며 종종 25-30%에 이릅니다.

**9.3.2.3 에너지 비례 컴퓨팅 (Energy Proportional Computing)**
서버 워크로드 프로필과 서버 에너지 효율성 동작 간의 불일치는 하드웨어 수준에서 해결되어야 합니다. 따라서 에너지 비례성을 컴퓨팅 구성 요소의 설계 목표로 추가해야 합니다[32]. 이상적인 에너지 비례 시스템은 유휴 상태일 때(특히 여전히 작업을 수행할 수 있는 활성 유휴 상태일 때) 전력을 거의 소비하지 않고 활동 수준이 증가함에 따라 점진적으로 더 많은 전력을 소비합니다. 이 이상적인 곡선을 추론하는 간단한 방법은 상수 인자 없이 활동과 전력 사용량 사이에 선형성을 가정하는 것입니다. 그러한 선형 관계는 활동 수준이 감소함에 따라 효율성이 감소하는 대신 활동 범위 전체에서 에너지 효율성을 균일하게 만들 것입니다.

그러나 에너지 절약을 위한 최적의 관계가 반드시 선형성은 아니라는 점에 유의하십시오. 그림 9.8에서 보듯이 서버는 높은 활동 수준에서 비교적 적은 시간을 보내기 때문에, 특히 최대 사용률에 접근할 때 높은 사용률에서 효율성을 줄이는 것은 괜찮을 수 있습니다. 그러나 그렇게 하면 장비의 최대 전력 소비가 증가하여 시설 비용이 증가합니다.

그림 9.10은 세 가지 가상 시스템의 가능한 에너지 효율성을 보여줍니다. 45% 유휴 전력을 가진 낮은 비례성 서버(빨간색), 10% 유휴 전력을 가진 더 에너지 비례적인 서버(녹색), 10% 유휴 전력을 가진 가상의 하위 선형(sublinear) 에너지 비례 서버(파란색)입니다. 실선은 피크 전력으로 정규화된 전력을 나타내고 점선은 피크 사용률에서의 전력 효율성 대비 효율성 백분율을 나타냅니다.

피크 사용률에서의 효율성은 세 서버 모두 동일하지만, 서버가 30-50% 사용률에서 대부분의 시간을 보낸다면 에너지 비례 서버의 실제 효율성은 훨씬 더 좋습니다.

WSC에서 에너지 비례성의 잠재적 이득은 Fan 등[33]에 의해 수천 대 기계의 활동 수준 트레이스를 사용하여 더 에너지 비례적인 서버를 사용하는 것으로 얻는 에너지 절감을 시뮬레이션한 전력 프로비저닝 연구에서 평가되었습니다. 두 서버, 즉 피크의 10% 유휴 소비를 가진 효율적인 서버(그림 9.10의 녹색 곡선과 유사)와 유휴 시 50% 전력을 소비하는 비효율적인 서버(해당 빨간색 곡선과 같은)를 가정했습니다. 그들의 모델은 비교된 두 서버의 피크 에너지 효율성이 동일했기 때문에 증가된 에너지 비례성만으로 에너지 사용량이 반으로 줄어들 것이라고 제안합니다.

원래의 에너지 비례성 요구[32]에서 얻은 이 통찰력은 업계가 에너지 비례성을 우선시하도록 자극했습니다. 오늘날 스케일 아웃 서버는 피크 전력의 20-25%에서 유휴 상태가 되고 거기에서 적어도 부분적으로 비례하여 확장되는 것이 일반적입니다. 낮은 사용률에서의 에너지 효율성은 여전히 완벽하지 않지만(그림 9.9에서 보듯이), 60% 사용률에서는 피크 효율성의 75%만큼 효율적입니다.

**9.3.2.4 에너지 비례성 분석**
CPU는 역사적으로 에너지 사용과 관련하여 나쁜 평판을 가지고 있지만, 열악한 에너지 비례성의 유일한 주범은 아닙니다. 지난 10년 동안 CPU 설계자들은 다른 하위 시스템에 대한 대응보다 에너지 효율성에 더 많은 관심을 기울였습니다. 피처 크기 축소(Dennard scaling)로 인한 에너지 효율성 개선이 끝났음에도 불구하고, 멀티코어 아키텍처로의 전환(단일 코어의 더 높은 클럭 주파수와 더 큰 수준의 투기적 실행을 계속 추진하는 것과 대조적으로)은 CPU 효율성을 계속 개선하는 데 도움이 되었습니다. FinFET, 통합 전압 조정기, 절전 상태에서의 더 세분화된 클럭 게이팅, RAPL[34]과 같은 API를 통한 주파수 관리 추가와 같은 기술에서 추가 개선이 이루어졌습니다.

메모리 시스템이 전체 에너지 사용량에 기여하는 상대적 기여도는 지난 5년 동안 CPU 에너지 사용량과 비교하여 감소했으며, 이는 지난 10년 동안 더 높은 DRAM 에너지 프로필 추세를 역전시킨 것입니다. 최신 DDR5 DRAM은 더 효율적이며, DRAM 칩 전압 수준은 1.8V(2008년 DDR2)에서 1.1V(2022년 DDR5)로 떨어졌습니다. 동시에 새로운 CPU는 더 공격적인 비닝(binning) 프로세스와 온도 제어 "터보" 모드를 통해 열 설계 전력(thermal envelope)에 더 가깝게 실행할 수 있게 됨에 따라 더 많은 에너지를 사용하며, 오늘날의 시스템은 DRAM 기술 스케일링이 CPU보다 뒤처짐("메모리 벽")에 따라 GB당 CPU 성능 비율이 더 높습니다.

그림 9.11은 낮은 지연 시간과 피크 성능에 최적화된 2024년형 2소켓 AMD 서버의 전력 사용량을 보여줍니다. 피크 전력 소비의 16%에서 유휴 상태였던 그림 9.9의 서버와 달리, 이 서버는 유휴 상태(완전히 비어 있는 서버)에서 피크 전력의 30%, 매우 낮은 사용률(거의 유휴 상태이지만 완전히는 아님)에서 36%를 소비합니다. SPECpower와 이렇게 극명한 차이가 나는 이유는 무엇일까요?

두 서버는 하드웨어가 아니라 하위 수준 설정이 다릅니다. SPECpower 벤치마크는 처리량(throughput) 벤치마크이므로 시스템 구성은 절전 상태에 대해 가장 공격적인 설정을 사용하며, 이러한 상태에서 재개할 때 수백 마이크로초의 지연이 발생합니다. 또한 SPECpower 구성은 에너지 효율성을 높이기 위해 캐시 프리페칭 및 CPU 터보 모드와 같은 기능을 제한하여 피크 성능을 처리량과 교환합니다. 이에 비해 실제 사용 사례는 완전히 비어 있을 때 긴 깨우기(wake-up) 지연 시간을 허용할 수 있지만(추가 5% 절약), 정상 작동 중에는 그렇지 않습니다.

그림 9.11에서 CPU에 귀속된 유휴 전력의 절반 이상은 "언코어(uncore)" 전력, 즉 실제 CPU 코어 외부의 요소가 소비하는 전력입니다. 코어 자체는 유휴 상태이므로 전력을 비교적 적게 소비하기 때문입니다. PCIe 및 DRAM 버스는 오늘날에도 유휴 모드가 제한적입니다. 즉, 전원을 다시 켜는 데 상당한 지연 시간이 필요한 전체 하위 시스템의 전원을 끄는 "완전 유휴(full idle)" 모드만 지원합니다. 따라서 성능에 민감한 워크로드에서는 일반적으로 비활성화됩니다. 이러한 시스템은 낮은 클럭 속도와 같은 "활성 유휴(active idle)" 모델을 지원하지 않습니다. (서버 외부 네트워킹을 포함했다면, 즉 서버가 연결된 네트워크 포트가 소비하는 전력을 할당했다면 유휴 전력 상황은 더 나빠 보일 것입니다.)

따라서 시스템 수준에서의 완전한 에너지 비례성은 CPU 최적화만으로는 달성할 수 없으며 대신 모든 구성 요소에 걸쳐 추가 개선이 필요합니다. 불행히도 비교적 긴 전선을 사용하는 시스템에서 전압이나 주파수를 매우 빠르게 높이거나 낮추는 것은 어려우며, 더 나은 접근 방식은 활성 채널의 수를 변경하는 것입니다. 예를 들어 PCIe 6.0은 링크의 레인(lane) 하위 집합을 동적으로 전원을 끄면서 나머지는 완전히 활성 상태로 유지할 수 있는 새로운 L0p 전력 상태를 도입합니다. 대역폭과 전력 모두 활성 레인 수에 비례하여 변하므로 에너지 비례성으로 가는 길을 제공합니다.

**9.3.2.5 에너지 비례성 개선**
성능 지표로서 에너지 비례성에 대한 관심이 높아지면서 서버급 플랫폼에서 눈에 띄는 개선이 이루어졌습니다. WSC용 서버의 에너지 비례성에 대한 의미 있는 지표는 30%와 100% 사용률에서의 에너지 효율성 비율입니다. 완벽하게 비례적인 시스템은 100%일 때만큼 30%에서도 효율적일 것입니다. 초판(2009년 초)에서 상위 10개 SPECpower 결과에 대한 그 비율은 약 0.45였는데, 이는 WSC에서 사용될 때 해당 서버가 피크 효율성의 절반 미만을 보였음을 의미합니다. 2018년 6월 현재 그 수치는 거의 2배 향상되어 0.80에 도달했습니다. 그러나 2018년 이후 효율성 개선은 대체로 정체되었습니다.

그림 9.12는 spec.org의 데이터를 기반으로 2007년과 2022년 사이 인텔 레퍼런스 플랫폼의 비례성 증가를 보여줍니다. 아직 완벽하게 비례적이지는 않지만 최신 시스템은 이전 시스템보다 훨씬 더 에너지 비례적입니다.

프로세서 에너지 비례성은 개선되었지만 대용량 스토리지의 에너지 비례성을 개선하기는 더 어렵습니다. 디스크 드라이브는 디스크를 일정한 속도로 회전시키는 데 대부분의 전력을 사용하며 디스크 드라이브의 전력 소비는 지난 20년 동안 거의 변하지 않았습니다. 그러나 디스크 드라이브는 스토리지 효율성을 크게 높였습니다. 약 10W를 사용하는 드라이브는 2005년에 80GB를 저장했지만 2024년에는 32TB를 저장하여 해당 기간 동안 바이트당 에너지를 400배 줄였습니다.

기계 부품이 없는 SSD는 더 에너지 비례적입니다. 일반적인 4TB SSD는 유휴 상태에서 5W, 최대 읽기/쓰기 부하에서 최대 15W를 소비합니다. 디스크에 비해 저장된 TB당 에너지는 더 높지만 액세스당 에너지는 몇 차수(orders of magnitude) 더 낮습니다.

LAN 네트워킹은 스위치 칩과 광 트랜시버 모두 전체 전력의 높은 비율로 유휴 상태를 유지하기 때문에 약간만 에너지 비례적입니다. 400Gbps 포트를 갖춘 2024년 시대 스위치는 스위칭을 위해 포트당 약 10W를 소비하고 광 트랜시버를 위해 포트당 10-15W를 추가로 소비합니다. 그러나 스위치(및 포트) 대역폭이 전력 소비보다 빠르게 증가하기 때문에 세대마다 에너지 효율성(pJ/bit 단위)이 향상됩니다.

마지막으로 에너지 비례적 동작은 전자 부품뿐만 아니라 전력 분배 및 냉각 인프라를 포함한 전체 WSC 시스템의 목표입니다.

**9.3.2.6 저전력 모드**
앞서 논의했듯이 긴 유휴 간격은 다양한 종류의 절전 모드를 사용하여 더 높은 에너지 비례성을 달성할 수 있게 해줍니다. 우리는 이러한 저전력 모드를 비활성(inactive)이라고 부르는데, 이는 해당 모드에 있는 동안 장치를 사용할 수 없으며 일반적으로 부하가 다시 적용될 때 상당한 지연 시간과 에너지 페널티가 발생하기 때문입니다. 비활성 저전력 모드는 원래 모바일 및 임베디드 장치를 위해 개발되었으며 해당 도메인에서 매우 성공적입니다. 그러나 이러한 기술의 대부분은 비활성-활성 지연 시간 및 에너지 페널티를 너무 자주 지불해야 하는 WSC 시스템에는 잘 맞지 않습니다. 이 도메인에서 성공할 수 있는 몇 가지 기술은 CPU 저전력 정지 상태(예: ACPI C1E 상태)의 경우처럼 웨이크업 지연 시간이 매우 짧습니다.

불행히도 이들은 에너지 절감 정도가 가장 작은 저전력 모드인 경향이 있습니다. 더 큰 에너지 절감은 스핀 다운된 디스크 드라이브와 같은 비활성 저전력 모드에서 가능합니다. 대부분의 CPU는 PCIe 또는 DRAM 채널과 같은 "언코어" 기능의 전원을 꺼서 전력 소비를 상당히 줄일 수 있습니다. 그러나 이러한 상태에서 깨어나는 데는 0.1ms 정도가 걸리며, 이는 일부 애플리케이션에 너무 많은 지연 시간(즉, 성능 지터)을 유발할 수 있습니다.

활성(active) 저전력 모드는 비활성 상태를 요구하지 않으면서 성능 비용을 지불하고 에너지를 절약합니다. CPU 전압-주파수 스케일링(DVFS)은 더 느린 속도이기는 하지만 명령을 실행할 수 있기 때문에 활성 저전력 모드의 예입니다. 비활성 모드와 달리 활성 모드는 고성능 모드로 전환하는 데 따른 지연 시간 및 에너지 페널티가 상당할 때도 유용합니다. 활성 모드는 작동 중이기 때문에 시스템은 특정 부하 임계값 미만으로 유지되는 한 저에너지 상태를 유지할 수 있습니다. 낮은 활동 기간이 완전한 유휴 기간보다 더 일반적이고 길기 때문에 활성 에너지 절약 모드 간 전환의 오버헤드는 더 효과적으로 상각됩니다.

매우 낮은 전력의 비활성 모드와 고주파 전환은 에너지 비례성을 달성하는 방법으로 제안되었습니다[35], [36]. 제안된 시스템인 PowerNap과 IdleCap은 하위 구성 요소가 완전 유휴 상태 외에는 유용한 저전력 모드가 없다고 가정하고, 성능에 미치는 영향을 제한하면서 낮은 사용률에서 전력을 줄이기 위해 모든 하위 구성 요소에서 활성-유휴 전환을 변조합니다. 이러한 접근 방식의 약속은 매우 짧은 활성-유휴 및 유휴-활성 전환 시간을 갖춘 초저전력 유휴 모드의 시스템 전체 가용성에 달려 있습니다. 이는 프로세서에서는 도달 가능한 기능처럼 보이지만 다른 시스템 구성 요소에서는 달성하기 더 어렵습니다. 실제로 Meisner 등[37]은 온라인 데이터 집약적 워크로드(예: 웹 검색)의 동작을 분석하고 기존의 저전력 모드는 에너지 비례성과 낮은 지연 시간을 모두 산출하기에 불충분하다는 결론을 내렸습니다.

**9.3.2.7 사례 연구: Turbo on Demand**

우리는 더 에너지 효율적인 WSC 시스템을 가능하게 하려면 하드웨어 구성 요소가 에너지 비례성에서 상당한 개선을 거쳐야 한다고 주장했습니다. 그러나 더 지능적인 전력 관리 및 스케줄링 소프트웨어 인프라도 중요한 역할을 합니다. 일부 구성 요소 유형의 경우 완벽한 에너지 비례 동작을 달성하는 것이 실현 가능한 목표가 아닐 수 있습니다. 설계자는 기존 하드웨어의 전력 관리 기능을 지능적으로 사용하고, 오버헤드가 낮은 비활성 또는 활성 저전력 모드를 사용하며, 하드웨어 시스템의 에너지 비례성을 향상하기 위해 전력 친화적인 작업 스케줄링을 구현하는 소프트웨어 전략을 구현해야 합니다. 예를 들어 비활성 저전력 모드의 활성화 페널티를 충분히 작게 만들 수 있다면 PowerNap[35]과 같은 기술을 사용하여 비활성 저전력 모드만 지원하는 구성 요소로 에너지 비례 동작을 달성할 수 있습니다.

이 소프트웨어 계층은 캡슐화(encapsulation)와 성능 견고성(performance robustness)이라는 두 가지 주요 과제를 극복해야 합니다. 에너지 인식 메커니즘은 애플리케이션 개발자에게 추가적인 인프라 복잡성을 노출하는 것을 최소화하기 위해 하위 수준 모듈에 캡슐화되어야 합니다. 결국 WSC 애플리케이션 개발자는 이미 전례 없는 규모와 플랫폼 수준의 복잡성을 다루고 있습니다. 또한 대규모 시스템에서 최종 사용자 작업의 완료는 적절한 수준에서 수행되는 수많은 시스템에 따라 달라지는 경향이 있습니다. 개별 서버가 전력 관리 메커니즘으로 인해 과도한 응답 시간 변동성을 보이기 시작하면 서비스 수준 영향 가능성이 상당히 높으며 서비스에 추가 기계 자원이 필요하게 되어 순 개선이 미미해질 수 있습니다.

터보 부스트(동적으로 클럭 속도 조정)는 전력과 성능을 트레이드 오프하기 위한 새로운 차원(CPU 활동)을 추가합니다. 터보 부스트의 동작은 활성 코어 수와 워크로드의 계산 강도에 따라 크게 달라집니다. 예를 들어 인텔 스카이레이크 서버 CPU에서는 CPU 코어 주파수가 85%까지 변할 수 있습니다[38]. 이 현상은 AVX-512와 같은 더 넓은 벡터 명령어가 높은 전력 소비로 인해 코어에 사용할 수 있는 열 예산을 줄여 CPU 코어 주파수를 크게 떨어뜨릴 때도 나타날 수 있습니다. 한편으로 이러한 기술은 특정 워크로드에 대해 더 높은 피크 성능을 가능하게 하지만, 다른 한편으로는 WSC 전반에 걸쳐 성능 변동성을 증가시킵니다. 하드웨어에서 이루어지는 동적 주파수 스케일링 결정은 성능 견고성을 달성하는 데 있어 새로운 과제 세트를 제시하며, 소프트웨어 설계자는 하드웨어의 이러한 효과를 인식하고 결과적인 성능 변화를 처리해야 합니다.

사실 터보 부스트는 성능과 CPU 사용률 사이에 상당한 불일치를 만듭니다. 낮은 CPU 사용률에서 CPU는 더 높은 주파수로 부스트할 수 있는 더 많은 여유 공간(headroom)을 갖게 되는데, 이는 종종 불필요한 성능입니다. 반대로 높은 부하에서는 처리량 요구 사항이 정점에 있을 때 사용 가능한 부스트가 훨씬 적습니다. 이러한 동작은 노트북 및 휴대폰과 같은 최종 사용자 멀티코어 시스템에서는 타당합니다. 단일 코어 애플리케이션이 실행될 때 해당 코어의 주파수를 높이면 사용자 경험이 향상됩니다. 그러나 WSC에서는 대부분의 주기가 가장 큰 애플리케이션에서 소비되고 이러한 애플리케이션은 모두 수평적으로 확장되어 모든 코어에서 실행되므로 이러한 동작은 덜 유용합니다.

엔드-투-엔드 지표와 서비스 수준 목표(SLO) 타겟을 통합하면 효율성을 높이면서 성능 변동성 문제를 줄여 이 딜레마를 극복하는 데 도움이 됩니다. 핵심 통찰력은 사용률이 낮은 기간 동안 (더 높은 지연 시간) SLO 타겟과 현재 달성된 지연 시간 사이에 지연 시간 여유(slack)가 존재한다는 것입니다. 이 여유는 애플리케이션이 필요 이상으로 빠르게 실행되고 있음을 의미하므로 SLO를 유지하면서 더 낮은 클럭 주파수에서 실행될 수 있어 전력 절감 기회를 나타냅니다.

Lo 등[39]은 하드웨어 전력 작동 메커니즘(Intel RAPL[40])과 소프트웨어 제어 정책을 결합한 Pegasus 시스템을 설명합니다. 이 시스템은 엔드-투-엔드 지연 시간 지표를 사용하여 부하 변동에 대응하여 CPU 전력을 조정할 시기를 결정합니다. 애플리케이션 수준 지표와 세분화된 하드웨어 작동 메커니즘을 결합함으로써 시스템은 WSC 애플리케이션의 지연 시간 SLO를 존중하면서 전체 서버 전력을 더 에너지 비례적으로 만듭니다. 또한 부하 테스트는 일반적으로 CPU 주파수 상한이 모든 코어 활성 부스트 주파수로 제한되는 높은 사용률에서 수행됩니다. 따라서 주파수를 모든 코어 활성 주파수로 제한하는 것은 안전합니다. 성능과 지연 시간이 부하 테스트 중보다 나빠지지 않을 것이기 때문입니다.

Google에서 Pegasus는 모든 워크로드를 포괄하는 Turbo on Demand(ToD)로 발전했습니다. ToD는 지연 시간 SLO가 있는 워크로드뿐만 아니라 모든 워크로드를 포함합니다. 성능 요구 사항과 CPU에서 사용 가능한 성능을 일치시키도록 터보 주파수 상한을 튜닝함으로써 ToD는 플랫폼의 정격 용량에 영향을 주지 않고 효율성을 최대 30%까지 높입니다. 그림 9.13은 2014년 Turbo on Demand 출시 전후 시스템의 에너지 비례성 개선을 보여줍니다.

**9.3.2.8 소프트웨어로 엔터프라이즈 워크로드 사용률 개선**
에너지 비례성 및 기타 하드웨어 노력도 도움이 될 수 있지만, 엔터프라이즈(및 퍼블릭 클라우드)에서 저사용률의 가장 큰 동인은 각 워크로드가 자체 VM에서 실행된다고 가정하는 기본 운영 모델입니다. 단일 코어 VM의 용량조차 여전히 꽤 높기 때문에 트래픽 양이 적은 애플리케이션의 경우 결과적으로 CPU 사용률이 매우 낮습니다.

첫 번째 수준의 최적화는 VM 기반 모델을 유지하면서 자원을 초과 가입(oversubscribing)하여 사용률을 개선하려고 시도합니다. 구체적으로 사용률이 낮은 VM에 전체 하드웨어 코어를 할당하는 대신 부분 코어를 할당하여 물리적 서버에 더 많은 VM을 패킹하고 사용률을 개선합니다. 예를 들어 AWS T3 인스턴스는 기준 수준의 CPU 성능을 제공하면서 CPU 사용량을 버스트(burst)할 수 있는 버스트 가능한 범용 인스턴스입니다[41]. GCP에서 E VM은 vCPU 간에 물리적 코어를 시분할하는 공유 코어(shared-core)[42]입니다. GCP는 또한 단독 테넌트(sole-tenancy) 서버에서 고객 정의 오버서브스크립션을 허용하여[43] 고객이 오버서브스크립션과 성능 간의 적절한 균형을 선택할 수 있도록 합니다.

다음 수준의 최적화는 컨테이너 기반 모델(4.3.2절 참조)로 이동하여 VM의 오버헤드를 여러 애플리케이션 간에 공유함으로써 사용률을 개선합니다. 컨테이너화는 애플리케이션을 재구성하고 재패키징해야 하지만 종종 애플리케이션 코드를 거의 변경할 필요가 없습니다. 특히 소규모 애플리케이션의 경우 OS 오버헤드가 전체 리소스 사용량의 상당 부분을 차지할 수 있으므로 절감 효과가 클 수 있습니다. 특히 애플리케이션당 메모리 요구 사항이 적기 때문에 서버에 더 많은 애플리케이션을 패킹할 수 있습니다. 메모리 용량은 종종 CPU 용량보다 먼저 오버서브스크립션을 제한하기 때문입니다.

컨테이너화는 또한 관리 비용을 줄여줍니다. OS 관리 및 컨테이너 인프라 관리가 서비스(예: Google Kubernetes Engine, GKE)로 제공되기 때문입니다. 컨테이너 추상화는 Cloud Run[44]과 같은 더 간단한 운영 모델을 허용하여 대부분의 관리 작업을 제거하고 컨테이너를 서비스로 실행하기만 하면 되므로 사용자가 Kubernetes 관리(사실 Cloud Run은 적절한 Kubernetes에서 실행되지도 않음)에 노출되지 않습니다. 또한 이러한 서비스는 요청이 수신되지 않은 정의된 기간 후에 마지막 컨테이너 인스턴스가 종료되어 유휴 상태일 때 애플리케이션이 라이브 리소스를 0개 사용하도록 하는 제로 스케일링(scale-to-zero)을 포함한 자동 확장을 제공합니다. 반대로 다음 요청이 들어오면 Cloud Run은 자동으로 애플리케이션 컨테이너를 다시 시작합니다. 하루에 몇 번만 요청을 받는 엔터프라이즈 애플리케이션(예: 급여 서비스 예시)의 경우 제로 스케일링은 비용을 크게 줄이고 에너지 소비를 거의 0으로 떨어뜨릴 수 있습니다.

**9.3.2.9 간섭과 시끄러운 이웃 (Noisy neighbors)**
클러스터 스케줄러는 다양한 모양의 작업(예: 다른 크기의 VM)을 빈 패킹(bin-packing)하여 물리적 리소스를 초과 가입할 수 있도록 하여 최소한의 기계에서 최대 수의 작업을 실행하는 것을 목표로 합니다. 이는 에너지 효율성 측면에서 순이익일 뿐만 아니라 주어진 워크로드를 처리하는 데 더 적은 서버가 필요하므로 경제적 이득이기도 합니다.

그러나 서버 사용률이 높아짐에 따라 공유 리소스 경합으로 인한 성능 저하가 더 큰 문제가 됩니다. 예를 들어 DRAM 대역폭을 완전히 포화시키는 두 개의 워크로드가 동일한 서버에 배치되면 두 워크로드 모두 격리된 상태에서 실행될 때보다 성능이 크게 저하됩니다. 워크로드를 고려하지 않는 스케줄링(workload agnostic scheduling)의 경우 CPU 코어 수가 많을수록 이 시나리오가 발생할 가능성이 커집니다.

간섭의 효과에 대응하기 위해 서비스 소유자는 리소스 경합에 직면하더라도 작업이 충분한 컴퓨팅 용량을 갖도록 민감한 워크로드의 리소스 할당을 늘리는 경향이 있습니다. 이 추가 패딩은 서버 사용률을 낮추어 에너지 효율성에 부정적인 영향을 미칩니다. 경합 인식 스케줄링은 이러한 함정을 피하고 엄격한 애플리케이션 수준 성능 요구 사항을 유지하면서 사용률을 더욱 높입니다[45], [46], [47]. 특정 메커니즘은 각 시스템마다 다르지만 모두 과거 성능 지표를 사용하여 더 나은 스케줄링 및 리소스 할당 결정을 내립니다. 이러한 성능 인식 시스템은 리소스 공유 기회를 크게 늘리고 기계 사용률을 높이며 궁극적으로 열악한 에너지 비례성을 피할 수 있는 에너지 효율적인 WSC로 이어질 수 있습니다.

높은 사용률은 리소스 사용률이 일시적으로 급증하는 작업인 "시끄러운 이웃(noisy neighbors)"을 처리하기도 더 어렵게 만듭니다. 부하가 적은 시스템에서는 이러한 급증이 유휴 용량에 의해 흡수되어 해당 시스템에서 실행 중인 다른 작업이 영향을 받지 않을 수 있습니다. 부하가 높은 시스템에는 그러한 여유가 없으므로 강력한 성능 격리(시끄러운 작업에 사용할 수 있는 리소스 엄격 제한) 또는 리소스를 확보하기 위한 매우 빠른 작업 마이그레이션, 또는 둘의 조합이 필요합니다.

**9.3.2.10 AI 전력 변동**
오늘날의 ML 워크로드는 수만 개의 가속기 칩과 호스트, 스토리지 및 네트워킹 시스템 전반에 걸친 동기화된 계산을 필요로 합니다. 이러한 워크로드는 종종 전체 데이터 센터 클러스터 하나, 심지어는 여러 개를 차지합니다. 모든 워커 노드가 매우 동기화된 방식으로 동작하여 동시에 멈추거나 피크에 도달하는 몇 개의 대규모 ML 워크로드가 전체 클러스터의 전력 사용량을 지배하기 때문에 전력 소비는 유휴 상태와 피크 사용률 수준 사이에서 훨씬 가파르게 상승하고 하락합니다. 많은 동기화된 이벤트가 큰 변동을 일으킵니다. 워크로드가 시작되거나 끝날 때, 또는 학습 단계 내에서 계산 집약적 단계와 네트워킹 집약적 단계가 교대로 진행되는 동안 발생합니다.

그림 9.14는 전용 ML 클러스터에서 실행되는 배치 동기식 ML 워크로드를 보여주며, 15MW의 전력 변동이 관찰됩니다. 전통적인 부하 프로필과 비교할 때 램프 속도는 거의 즉각적일 수 있고, 몇 초마다 반복될 수 있으며, 몇 주 또는 몇 달 동안 지속될 수 있습니다.

이러한 종류의 변동은 다음과 같은 위험을 초래합니다.

*   정류기, 변압기, 발전기, 케이블 및 버스웨이를 포함한 랙 및 데이터 센터 장비의 신뢰성 감소.
*   칩, 마더보드 및 기타 서버 구성 요소의 신뢰성 감소.
*   전력 사용 프로필에 대한 유틸리티(전력 회사)의 기대와 불일치하는 경우를 포함한 업스트림 유틸리티의 손상, 중단 또는 스로틀링(throttling).
*   큰 전력 변동으로 인한 무정전 전원 공급 장치(UPS) 시스템의 의도치 않고 빈번한 트리거링으로 UPS 시스템의 수명 단축.

하드웨어 수준에서 빈번한 전력 변동으로 인한 열 변동은 뒤틀림(warpage), 열 인터페이스 재료 특성의 저하, 반도체 재료의 전기 마이그레이션 등을 포함한 다양한 형태의 스트레스를 유발합니다. 실제로 급격한 열 사이클링은 스트레스가 많은 조건에서의 수명을 기반으로 구성 요소 또는 시스템 수명을 예측하는 것을 목표로 하는 가속 수명 테스트(ALT)의 핵심 기술 중 하나입니다.

이 문제를 줄이려면 워크로드 전력 프로필을 사전에 형성(shape)하여 전력 변동을 줄여야 합니다. 프로파일 기반 최적화는 TPU 컴파일러가 전력 변동과 연결된 워크로드 서명(예: 글로벌 동기화 지점)을 모니터링하기 위해 바이너리를 계측하는 것으로 시작합니다. 그런 다음 컴파일러는 주요 TPU 컴퓨팅 블록의 활동 균형을 동적으로 조정하여 시간 경과에 따른 사용률을 부드럽게 만드는 것을 목표로 합니다. 이러한 재조정은 성능 오버헤드를 거의 발생시키지 않으면서 전력 및 열 변동을 줄입니다. (미래에는 전력 수준의 급격한 변화 대신 점진적인 변화를 가능하게 하기 위해 워크로드 시작 및 종료 단계에도 이 접근 방식을 적용할 수 있습니다.)

그림 9.15는 최적화 전후의 시스템 총 전력 소비와 단일 칩의 핫스팟 온도를 보여줍니다[48]. 이 실제 워크로드에서 전력 변동은 거의 50% 감소했습니다. 온도 변동은 약 20°C에서 약 10°C로 떨어졌습니다(온도 그래프는 더 긴 시간 간격에 걸친 온도를 보여줌). 적절한 튜닝을 통해 이러한 이점은 평균 전력 및 총 성능에 1% 미만의 영향을 미칩니다.

**9.4 전문화를 통한 에너지 효율성 개선**

지금까지 우리는 각각 CPU, DRAM, 네트워킹, 디스크를 갖추고 모든 계산이 범용 CPU에 의해 처리되는 서버들의 집합인 전통적인 WSC에 대해 논의했습니다. 그러나 6장의 논의를 다시 요약하자면, 데나드 스케일링(Dennard scaling)은 근본적인 소자 한계로 인해 끝났고 무어의 법칙은 저물어가고 있습니다. 앞으로 범용 CPU는 에너지 효율성을 더 개선하려고 할 때 벅찬 과제에 직면하게 됩니다. 이 문제는 피크 컴퓨팅 부하에서 에너지 효율성을 개선하는 것에 관한 것이므로 에너지 비례성과는 별개의 문제입니다.

피크 부하 시 CPU 효율성은 여전히 시간이 지남에 따라 (느리게) 개선되지만, 컴퓨팅 수요는 꾸준한 속도로 증가하고 있습니다. 현재 이 수요는 인공 지능과 기계 학습에 의해 주도되고 있으며, 이는 대규모 모델 크기에 상응하는 대규모 컴퓨팅을 필요로 하고 학습 중에 대량의 데이터를 소비합니다. 범용 CPU는 AI에 필요한 연산을 수행할 수 있지만 이러한 종류의 워크로드를 실행하는 데 최적화되어 있지 않습니다.

전문화된 가속기는 특정 클래스의 워크로드를 잘 실행하도록 설계되었습니다. CPU에 비해 상당한 성능 이점은 상당한 효율성 이점을 가져옵니다. 예를 들어 텐서 처리 장치(TPU)는 계산 및 데이터 액세스 모두의 에너지 효율성을 크게 향상시킵니다. 계산은 더 낮은 정밀도(예: 32비트 대신 8비트 부동 소수점)이므로 더 효율적이 됩니다. TPU의 시스톨릭 어레이(systolic array)는 데이터를 한 번 가져온 다음 여러 번 재사용할 수 있어 상당한 양의 전력을 소비하는 대형 SRAM 어레이에 대한 액세스 속도를 줄입니다. (놀랍게도 곱셈-덧셈 연산의 입력을 가져오는 것은 실제 계산보다 한 자릿수 더 많은 에너지를 소비합니다.)

또한 최신 슈퍼스칼라 비순차(out-of-order) CPU와 비교할 때 TPU의 제어 로직은 상대적으로 간단하여 훨씬 더 에너지 효율적입니다. 기계 학습 애플리케이션의 병렬 처리는 추출하기 쉽기 때문에 TPU는 CPU에서 발견되는 복잡하고 에너지를 많이 소모하는 제어 하드웨어가 필요하지 않습니다. TPU에 대한 이러한 설계 결정과 다른 설계 결정은 에너지 효율성에서 엄청난 개선을 가져왔습니다.

그림 9.16은 원래 TPU가 당시의 최신 서버 CPU(Intel Haswell, 2015)에 비해 추론 작업에서 얼마나 더 에너지 효율적인지를 보여줍니다. 시스템 수준(가속기 + 지원 CPU)에서 벤치마크 전반의 가중 평균을 비교할 때 GPU는 CPU보다 2배 더 좋은 성능을 보였고, TPU는 34배 더 좋은 성능을 보였습니다. 칩만의 와트당 성능을 비교하면 GPU는 CPU보다 2.9배, TPU는 83배 더 뛰어났습니다. GM과 WM은 기하 평균과 가중 평균입니다. 이 그림은 또한 비교 GPU와 동일한 공정 기술 및 GDDR5로 확장된 가상의 TPU 다이인 TPU'의 성능을 보여줍니다. 이 경우 TPU'의 상대적 총 성능/와트/다이는 CPU 대비 31배-86배, GPU 대비 25배-41배로 증가합니다.

그 이후로 TPU와 GPU 성능은 개선된 아키텍처 기능, 더 나은 컴파일러 및 개선된 칩 제조를 기반으로 세대당 2-4배 향상되었습니다. 그 결과 지난 10년 동안 칩당 ML 성능은 100배 이상 향상되었습니다!

그럼에도 불구하고 모든 워크로드가 특수 하드웨어에서 실행될 수 있는 것은 아닙니다. 워크로드 자체의 특성상 가속화하기 어려울 수 있습니다. 범용 CPU는 복잡하고 분기가 많으며 불규칙한 코드를 위한 가속기로 볼 수 있습니다. 또는 더 빈번하게는 사용 사례가 특수 하드웨어에 대한 고정된 초기 투자를 정당화할 만큼 크지 않을 수 있습니다. 따라서 가속기의 에너지 효율성을 개선하는 것과 함께 범용 서버를 포함한 전체 데이터 센터의 전반적인 에너지 효율성을 개선하는 것은 여전히 중요합니다.

**9.5 데이터 센터 전력 프로비저닝**

에너지 효율성 최적화는 전기 비용을 줄여줍니다. 또한 건설 비용도 줄여줍니다. 예를 들어 프리 쿨링으로 칠러의 필요성이 제거되면 칠러를 구매하고 설치할 필요가 없으며, 이를 백업할 발전기나 UPS에 비용을 지불할 필요도 없습니다. 이러한 건설 비용 절감은 효율성 개선으로 인한 전체 절감 효과를 두 배로 늘릴 수 있습니다.

시설의 프로비저닝된 전력을 완전히 사용하는 것도 똑같이 중요합니다. 시설이 피크 전력 용량의 50%로 운영된다면 사용된 와트당 유효 프로비저닝 비용은 두 배가 됩니다. 데이터 센터의 전력 예산을 완전히 사용하려는 이 인센티브는 최대 용량을 초과하여 중단을 일으킬 수 있는 위험에 의해 상쇄됩니다.

**9.5.1 전력 좌초 (Power Stranding)**
1MW 시설에 서버를 몇 대나 설치할 수 있을까요? 이 간단한 질문은 생각보다 답하기 어렵습니다. 첫째, 서버 사양은 일반적으로 최대 전력 소비에 대해 매우 보수적인 값을 제공합니다. Dell 및 HP와 같은 일부 공급업체는 더 나은 추정치를 제공하기 위해 온라인 전력 계산기[49], [50]를 제공하지만, 주요 애플리케이션의 실제 전력 소비를 수동으로 측정해야 할 수도 있습니다.

둘째, 실제 전력 소비는 부하에 따라 크게 달라지며(에너지 비례성 덕분에), 서버 그룹의 피크 전력 소비를 예측하기 어려울 수 있습니다. 특정 서버가 일시적으로 100% 사용률로 실행될 수 있지만 서버 그룹의 최대 사용률은 아마도 100%가 아닐 것입니다. 실제 배포에서는 정확한 전력 등급에 주의를 기울이더라도 활용도가 낮은 시설이 되기 쉽습니다. 예를 들어 시설은 일반적으로 미래의 성장을 수용해야 하지만 그러한 성장을 위해 공간을 비워두면 사용률이 감소하여 단위 비용이 증가합니다. 다양한 형태의 단편화(fragmentation)도 완전한 사용을 방해할 수 있습니다. 저밀도 장비가 랙 공간을 다 써버렸거나, 네트워크 포트가 부족하거나, 멀티탭 플러그가 부족하거나, 단순히 숫자가 균등하게 나뉘지 않아서 다른 서버를 삽입할 수 없을 수 있습니다. 예를 들어 2.5kW 회로는 520W 서버 4개만 지원하므로(420W 좌초), 해당 회로의 사용률은 83%로 제한됩니다. 시간이 지남에 따라 장비가 시설 내외로 이동하므로 100% 사용률을 계획하는 것은 어려우며 대부분의 조직은 그렇게 하지 않습니다.

더 잘하려면 대규모 서버 그룹의 동시 전력 사용량 간의 상관관계를 이해해야 합니다. 서버 그룹이 클수록, 애플리케이션 다양성이 높을수록 동시 고활동 기간이 발생할 가능성이 작아집니다. 일반적인 엔터프라이즈 데이터 센터에서는 이 데이터를 사용할 수 없거나 상대적으로 적은 수의 서버가 강력한 통계적 보장을 제공하지 않으므로 이러한 데이터 센터는 초과 할당(oversubscription)을 거의 사용하지 않습니다. WSC는 두 가지 제한을 모두 제거할 수 있습니다.

**9.5.2 전력 초과 할당(Oversubscription): 개념**

따라서 높은 시설 사용률을 얻는 것은 보기보다 어렵습니다. 프로비저닝할 전력량을 결정하기 위해 데이터 센터 장비의 전력 소비를 추정해야 하지만 이러한 추정치는 종종 너무 보수적이어서 용량 미달 사용으로 이어집니다. 데이터 센터는 일상적으로 낮은 사용률로 실행되므로 이는 실제로 심각한 문제입니다[51].

이에 대한 대응으로 우리는 보수적인 계산이 지원하는 것보다 더 적은 전력을 프로비저닝하거나 더 많은 서버를 구축할 수 있습니다. 두 경우 모두 사용 가능한 전력량을 초과할 위험, 즉 시설 전력을 초과 할당할 위험을 감수합니다[52]. 전력 초과 할당을 성공적으로 구현하면 과부하 상황의 위험을 최소화하면서 데이터 센터 전력 예산의 전체 사용률을 높일 수 있습니다.

Fan 등[33]은 6개월 동안 Google에서 다양한 워크로드를 실행하는 최대 5,000대 서버 클러스터의 전력 사용 동작을 분석하여 시설 전력 초과 할당의 잠재적 기회를 연구했습니다. 그들의 주요 결과 중 하나는 그림 9.17에 요약되어 있으며, 80대 서버(Rack), 800대 서버(PDU), 5,000대 서버(Cluster) 그룹에 대한 시간 경과에 따른 전력 사용량의 누적 분포를 보여줍니다.

전력은 해당 그룹의 피크 총 전력으로 정규화됩니다. 초과 할당 이점은 전력 도메인 크기에 따라 증가합니다. 100,000대 서버 풀은 100대 서버 풀보다 (평균 대비) 더 낮은 스파이크를 봅니다. 예를 들어 그림은 랙 유닛이 피크 전력의 65% 미만을 사용하는 데 시간의 약 80%를 보냈지만 6개월 관찰 기간 동안 어느 시점에는 피크 전력의 93%에 도달했음을 보여줍니다. 전력 프로비저닝의 경우 이는 랙 수준에서 사용 가능한 전력의 7%만이 좌초되었기 때문에 초과 할당 기회가 낮음을 나타냅니다. 그러나 더 큰 기계 그룹의 경우 상황이 바뀝니다. 특히 전체 클러스터는 총 피크 전력의 72% 이상으로 실행된 적이 없습니다. 따라서 모든 기계의 피크 전력 소비 합계에 해당하는 전력 용량을 클러스터에 할당했다면 해당 전력의 28%가 좌초되었을 것입니다. 이는 해당 전력 용량 내에서 $1/(1 - 0.28) = 1.39$배 더 많은 기계를 호스팅할 수 있었음을 의미합니다.

이 연구는 또한 시설 수준에서 피크 전력 소비를 줄이기 위해 더 에너지 비례적인 기계의 잠재력을 평가했습니다. 유휴 전력을 피크의 50%에서 10%로 낮추면 클러스터 피크 전력 사용량을 30% 이상 더 줄일 수 있으며 호스팅 용량을 40% 늘릴 수 있음을 시사합니다. 클러스터 내에서 다양한 워크로드를 혼합하면 기계 간에 동기화된 전력 피크의 가능성을 줄여 전력 초과 할당 기회를 늘립니다.

일단 초과 할당이 적용되면 데이터 센터 용량을 초과하는 워크로드 스파이크에 대한 안전 메커니즘이 필요합니다. 우선순위가 낮은 작업을 중지하는 것은 데이터 센터 부하를 즉시 낮추는 매력적인 방법입니다. Borg와 같은 일반적인 클러스터 스케줄링 시스템은 수천 대의 기계로 구성된 여러 클러스터에서 수천 개의 서로 다른 애플리케이션의 수십만 개의 작업을 관리하고 실행합니다. 클러스터는 두 가지 기본 애플리케이션 계층(3장의 워크로드 클래스 논의 상기)으로 구성된 이질적인 워크로드를 실행합니다.

*   **프로덕션 계층:** 사용자에게 보이는 중단을 유발하므로 거의 다운되어서는 안 되며 높은 가용성 목표를 가진 것으로 간주되는 프로덕션 서비스입니다. 예로는 고객 VM, 데이터베이스, Gmail 등이 있습니다.
*   **비프로덕션 계층:** 단기 중단에 훨씬 덜 민감하며 일반적으로 가용성 요구 사항이 더 느슨한 작업입니다. 예로는 테스트 실행, 배치 작업, ML 학습 작업 및 칩 시뮬레이션이 있습니다.

비프로덕션 계층은 이러한 워크로드의 약한 가용성 요구 사항을 활용하여 초과 할당 비율(OSR)을 공격적으로 높일 수 있습니다. 프로덕션 워크로드가 소비하는 전력이 전기적 한계를 초과하지 않는 한 높은 초과 할당은 허용됩니다. 총 부하가 초크 포인트(choke point)의 전기적 한계에 접근하면 전력 제한(power capping) 소프트웨어가 비프로덕션 워크로드를 일시 중지하거나 중단하여 시설 부하를 줄입니다.

예를 들어 랙 수준에서 초과 할당이 적용되는 경우처럼 이 메커니즘이 자주 트리거되어야 할 정도로 공격적으로 프로비저닝해서는 안 됩니다.

이 분야에 관심이 있는 연구자를 돕기 위해 Google은 전력 트레이스[53]를 공개했습니다. 트레이스는 10개 클러스터 및 57개 전력 도메인(PDU)에 걸쳐 1개월 동안의 총 및 프로덕션 워크로드 전력 데이터를 다룹니다.

**9.5.3 초과 할당 변형**

초과 할당 기술은 초과 할당되는 리소스와 초과 할당이 발생하는 세분성이라는 두 가지 차원에서 다릅니다. 지금까지 우리는 주로 장기간(시간적 세분성)에 걸쳐 클러스터(공간적 세분성)에서 서버 전력(리소스) 초과 할당에 초점을 맞추었습니다. 물론 초과 할당은 다른 리소스와 다른 세분성에도 적용되어 추가 절감 기회를 얻을 수 있습니다. 각각의 새로운 조합은 실제 사용량이 프로비저닝된 용량을 초과하는 드문 시나리오를 처리하기 위한 완화 전략이 필요합니다.

리소스 차원에서 가장 두드러진 적용은 전력 초과 할당이지만 냉각 용량 및 백업 발전과 같은 다른 리소스도 초과 할당할 수 있습니다. 인프라 초과 할당은 워크로드의 다양한 가용성 요구 사항을 인식하여 개별 사용률과 전체 TCO를 최대화하도록 인프라 조각의 크기를 조정하는 경우 가장 효과적입니다. 예를 들어 총 전력의 20%가 최대 8시간까지 연기할 수 있는 배치 작업에 소비된다면 안전한 초과 할당을 더욱 강화할 수 있는 여러 옵션이 있습니다. 버스 바 또는 PDU의 실제 전력 소비가 안전 한계를 초과하는 경우 이러한 워크로드를 몇 초 동안 일시 중단하거나, 무중단 프로덕션 작업에 전력을 공급하기 위해 백업 발전기가 필요한 유틸리티 중단 중에 몇 분 동안 일시 중단할 수 있습니다. 일 년 중 가장 더운 날에 사용률이 정말 높다면 배치 부하 중 일부를 하루 중 나중으로 연기하면 냉각 시스템이 온도를 안전하게 유지할 수 있습니다.

지금까지 논의된 모든 접근 방식이 정적으로 안전한 초과 할당 값을 결정하더라도 초과 할당이 반드시 정적일 필요는 없습니다. 예를 들어 겨울철에 유지 관리 일정을 가속화하기 위해 냉각을 더 공격적으로 초과 할당할 수 있습니다. 마찬가지로 초과 할당은 워크로드에 의존적입니다. 모든 클러스터가 동일한 워크로드를 실행하는 것은 아니며 클러스터 내의 다른 전력 도메인은 다른 피킹 동작을 가질 수 있습니다. 또한 이러한 값은 워크로드가 진화함에 따라 시간이 지남에 따라 변경될 수 있습니다. 시간적 및 공간적 인식은 임시 초과 할당으로 결합될 수 있으며, 여기서 워크로드 재배치로 생성된 추가 여유 공간은 일반적으로 클러스터의 초과 할당 제한을 위반하는 유지 관리를 수행하는 데 사용될 수 있습니다.

이중화된 설계에서 모든 전력 도메인에는 두 개의 공급 장치가 있습니다. 고전압 유틸리티 공급을 저전압 버스바 공급으로 낮추는 변압기와 유틸리티 공급이 실패할 경우 전력을 제공할 수 있는 발전기입니다. 가변 초과 할당의 한 형태는 적어도 하나의 유틸리티 공급을 사용할 수 있을 때(거의 항상 그렇습니다) 초과 할당 계수를 높이는 것인데, 전력 도메인은 일반적으로 변압기 용량이 아니라 발전기 용량에 의해 제한되기 때문입니다.

언뜻 보기에 이 상황은 일어날 것 같지 않습니다. 잘 설계된 시설에서 짝을 이루는 변압기와 발전기의 용량이 일치해야 하지 않을까요? 일반적으로 변압기는 크기를 키우는 것이 더 저렴하기 때문에 정격 설계 용량이 정확히 일치하지 않습니다. 더 중요한 것은 변압기에는 즉각적이고 엄격한 상한 용량 제한이 없다는 것입니다. 2MW 변압기가 2.2MW 부하에서 실행되면 더 뜨거워지고(수명이 짧아짐) 실패하지는 않습니다. 대조적으로 2MW 발전기는 2.2MW 부하에 직면하면 몇 초 내에 오프라인으로 전환됩니다. 따라서 유틸리티 전력으로 실행할 때는 정격 전력 제한을 초과하는 짧은 일탈을 허용할 수 있지만 백업 발전기로 실행할 때는 그렇지 않습니다.

초과 할당은 훨씬 더 큰 도메인, 예를 들어 캠퍼스 수준에서도 적용될 수 있습니다. 여기서 서로 다른 클러스터의 총체적 동작은 훨씬 더 통계적으로 안정적인 동작을 제공할 수 있습니다. 예를 들어 4개 건물에 걸쳐 120MW의 프로비저닝된 데이터 센터 용량이 있는 캠퍼스는 전체 부하를 처리할 수 있는 유틸리티 공급이 필요하지 않을 수 있습니다. 어떤 건물이 용량의 100%로 실행될 가능성이 매우 낮고, 4개 건물이 동시에 100%로 실행될 가능성은 더욱 낮기 때문입니다.

**9.5.4 사례 연구: Google의 전력 초과 할당**

이 사례 연구는 많은 데이터 센터가 25% 초과 할당 비율을 달성하는 Google의 전력 초과 할당[54]을 설명합니다. 두 가지 주요 기술이 높은 초과 할당을 가능하게 합니다. 첫째, 더 큰 전력 도메인 크기(도메인당 수십 MW)는 증가된 초과 할당을 위한 더 많은 통계적 다중화 및 공유를 허용합니다. 둘째, 워크로드 가용성 인식은 각 서버에서 작동하는 세분화되고 확장 가능한 전력 제한 액추에이터와 결합하여 일탈 발생 시 반응적인 전력 제어를 가능하게 합니다.

우리의 사례 연구는 약 15kV에서 작동하고 수십 MW의 장비에 걸쳐 전력 공유(및 초과 할당 잠재력)를 생성하는 중간 전압 전력 평면(MVPP)을 논의합니다. (5장의 그림 5.7에서 더 자세히 설명합니다.)

MVPP 아키텍처에서 발전기 팜(generator farm)은 전체 용량을 제한합니다. 따라서 전력 제한 인프라는 발전기를 인식하여 유틸리티 전력이 실패할 때 초과 할당을 줄입니다. 또한 발전기 고장을 처리할 수 있습니다. 발전기 전력으로 작동 중이고 백업 발전기가 고장 나면 최대 허용 전력이 그에 상응하는 양만큼 줄어듭니다. 전력 제한 컨트롤러는 도메인의 모든 서버에 있는 노드 컨트롤러에 알립니다. 노드 컨트롤러는 전력을 줄이기 위해 비프로덕션 작업 계층부터 시작하여 작업을 일시 중단하거나 종료하여 반응합니다. 전력 제한은 신속하게 반응해야 합니다. 엔진의 관성을 통해 발전기는 멈추기 전 몇 초 동안만 소량의 과도한 부하를 "견딜(ride through)" 수 있습니다.

전력 제한에는 현재 전력 소비에 대한 정확한 측정이 필요합니다. 그림 9.18은 Google 데이터 센터[54]에서 사용되는 전력 제한 서비스의 높은 수준의 소프트웨어 아키텍처를 보여줍니다. 매초, 미터 감시자(meter watcher) 모듈은 유틸리티 공급 및 발전기 팜에 위치한 여러 고속 응답 전력계를 지속적으로 폴링합니다. 이러한 측정값은 판독 값을 집계하는 전력 알림자(power notifier) 모듈로 공급됩니다. 전력 제한 임계값을 초과할 때마다 알림자는 기계 관리자(machine manager) 모듈에 연락하여 전력 평면의 개별 노드 수준 스케줄러에 RPC를 보냅니다. 이들은 차례로 SIGSTOP 신호를 사용하여 우선순위가 낮은 작업을 일시 중단합니다. 각 노드 스케줄러는 전력이 임계값 이상으로 유지되는 한 낮은 우선순위 작업이 실행되는 것을 방지합니다. 전력이 충분히 떨어지면 노드 스케줄러는 SIGCONT 신호를 발행하여 작업이 재개되도록 합니다.

가상의 상황에서도 OSR 함수로서 비프로덕션 계층 비가용성에 미치는 영향을 특성화하기 위해 시간 도메인 몬테카를로 시뮬레이션을 사용하여 실제 클러스터의 과거 전력 사용률 시계열을 사용하여 다양한 OSR 값에서 단일 클러스터 동작을 시뮬레이션합니다. 시뮬레이션은 유지 관리 및 고장률, 유틸리티 전력 중단 빈도 및 기간에 대한 보수적인 가정을 사용합니다. 수세기에 걸친 시뮬레이션 시간 동안 시뮬레이션은 단일 유틸리티 중단/공급 유지 관리, 이중 유틸리티 중단, 발전기 고장이 있는 이중 유틸리티 중단이라는 세 가지 유형의 이벤트를 통합한 확률적 결과 시리즈를 생성합니다.

그림 9.19는 최악의 시나리오, 즉 유틸리티 전력을 사용할 수 없어 전력 제한이 더 낮은 발전기 제한을 시행해야 한다고 가정할 때 주어진 클러스터에서 전력 제한으로 인해 비프로덕션 워크로드를 실행할 수 없는 시간의 비율을 보여줍니다. 플롯은 발전기로 실행되는 동안(연간 최대 몇 시간) OSR 값의 함수로서 클러스터 전반에 걸친 비프로덕션 워크로드 비가용성 범위를 보여줍니다. 표시는 개별 클러스터에 해당하고 막대는 클러스터 분포의 1사분위수와 3사분위수를 나타냅니다.

대부분의 클러스터는 대부분의 OSR 비율에서 발전기 실행 시간의 몇 퍼센트 동안만 비프로덕션 워크로드에 영향을 미칩니다. 그러나 일부 아웃라이어 클러스터는 상당한 부하 축소를 볼 수 있습니다. OSR 25%에서 아웃라이어 클러스터는 발전기 시간의 50% 이상 동안 비프로덕션 워크로드를 제한할 수 있습니다. 대부분의 고전압 유틸리티 고장은 몇 분 동안만 지속되므로 이는 여전히, 특히 배치 작업의 경우 허용될 수 있습니다.

**9.5.5 간헐적 에너지 공급**

중단 가능한 대규모 워크로드는 최적화를 위한 추가 기회를 창출합니다. 특히 전력망에 추가 피크 공급은 없지만 대부분의 시간 동안 공급이 가능한 지역에서 실행될 수 있습니다.

이는 그리드가 높은 사용률을 갖도록 구축된 것이 아니라 피크 사용량을 처리하도록 구축되었기 때문에 드문 경우가 아닙니다. 다시 말해, 전력망은 일년 중 수요가 가장 높은 날(예: 에어컨 수요가 가장 높은 가장 더운 여름날)의 부하를 처리할 것으로 예상되기 때문에 비용보다 가용성을 우선시합니다. 그러한 피크는 기상 이변으로 인해 평균적으로 1년에 한 번 미만 발생할 수 있습니다. 그 결과, 연중 대부분은 해당 피크보다 훨씬 낮은 수요 수준을 보이며 설치된 용량에 상당한 여유 공간을 남겨 둡니다. 그 결과 대부분의 그리드에서 연간 평균 사용률은 30%에서 60% 사이입니다.

따라서 피크 수요 기간 동안 중단 가능한 대규모 부하는 피크 기간에 축소될 수 있기 때문에 그리드를 안정화하는 데 도움이 될 수 있습니다. 또한 그리드의 고정 비용이 더 큰 소비량에 비례 배분되므로 에너지 비용을 줄입니다.

ML 학습 실행은 간헐적 에너지 공급에 이상적인 워크로드입니다. 규모가 크고(단일 위치에서 수십 또는 수백 MW), 빨리 중지할 수 있으며(1분 이내), 저장된 스냅샷에서 똑같이 빨리 다시 시작할 수 있습니다. 비싼 ML 가속기를 유휴 상태로 만들기 때문에 중단이 바람직하지는 않지만, 그러한 중단의 총 기간이 작다면(예: 연간 0.5% 또는 1%) 견딜 수 있습니다.

2025년 미국 그리드에 대한 연구[55]는 적당한 양의 간헐성이 AI 워크로드의 예상 수요를 크게 초과하는 부하 증가를 가능하게 할 것이라고 제안했습니다. 구체적으로 76GW의 새로운 부하(미국 총 피크 수요의 10%에 해당)가 평균 연간 부하 축소율 0.25%로 통합될 수 있습니다.

**9.5.6 기타 에너지 최적화**

여러 연구[56], [57], [58]는 시설 성능을 최적화하거나 에너지 비용을 줄이기 위해 시설의 백업 시스템(예: UPS 배터리)에 저장된 에너지를 사용하는 것을 제안합니다. 저장된 에너지는 시설의 부하 프로필을 평탄화(유틸리티 전력이 가장 비쌀 때 덜 사용), 풍력 발전 시설의 공급 변동성 완화, 또는 초과 할당된 시설의 짧은 수요 피크 관리(부하를 제한하는 대신 저장된 에너지를 사용하거나 제한을 시행할 수 있는 시간을 연장)에 사용될 수 있습니다.

우리가 아는 한, 아직 프로덕션 시스템에서 이러한 전력 관리 시스템이 사용된 적은 없습니다. 제어 복잡성 외에도 배터리의 추가 비용이 상당할 것입니다. 기존 UPS 용량을 전력 관리에 재사용할 수는 없습니다. 그렇게 하면 실제 중단 시 시설이 더 취약해질 수 있기 때문입니다. UPS SLO가 시설이 배터리로 $N$분 동안 실행될 수 있어야 한다고 요구하는 경우, 그 용량은 일부 시간이 아니라 항상 사용 가능해야 합니다. 일부는 확장된 UPS가 비용 효율적일 것이라고 주장했지만[58], 실제 배포에서의 경제적 타당성은 더 복잡했습니다. 전력 마이크로그리드(5장에서 논의됨)는 이러한 최적화를 더 관련성 있게 만들 수 있습니다.

WSC의 에너지, 피크 전력 및 온도 관리는 많은 연구의 대상이 되기도 했습니다. Chase 등[59], G. Chen 등[60], Y. Chen 등[61]은 에너지 절감 및 애플리케이션 성능을 고려하여 데이터 센터의 리소스를 자동으로 프로비저닝하는 계획을 고려합니다. Femal과 Freeh[62], [63]는 데이터 센터 전력 초과 할당 문제에 구체적으로 초점을 맞추고 피크 전력 소비를 줄이는 메커니즘으로 동적 전압-주파수 스케일링을 설명합니다. 온도 관리는 Heath 등[64]과 Moore 등[65]이 제안한 시스템의 주제입니다. Pedram[66]은 리소스 프로비저닝에 대한 소개를 제공하고 데이터 센터의 관리 문제를 다루기 위한 주요 기술을 요약합니다. DVFS를 통해 지연 시간 분포를 재구성하여 안전하게 전력을 절약하기 위해 애플리케이션 수준 지식을 통합하는 것은 Lo 등[39], Kasture 등[67], Hsu 등[68]에 의해 연구되었습니다.

Raghavendra 등[69]은 서버당 평균 전력 소비; 서버, 인클로저 및 그룹 수준에서의 전력 제한; 워크로드를 통합하고 사용하지 않는 기계를 꺼서 기계 모음 전체의 평균 소비 전력을 줄이는 가상 머신 컨트롤러(VMC) 사용을 고려하는 5단계 조정 전력 관리 계획을 연구했습니다. 이러한 집중적인 전력 관리는 사소하지 않은 제어 문제를 제기합니다. 예를 들어 일부 서버가 전력 제한으로 인해 예기치 않게 느려지면 애플리케이션이 불안정해질 수 있습니다. 구현 측면에서 차단기가 트립되는 것을 방지하기 위해 전력 제한 결정은 밀리초 내에 구현되어야 할 수도 있습니다.

Wu 등[70]은 당시 Meta에서 생산 중이던 동적 전력 제한 시스템인 Dynamo를 연구했습니다. Dynamo는 전체 데이터 센터에서 조정된 전력 결정을 내려 전력을 안전하게 초과 할당하고 전력 사용률을 개선합니다. 기계 전력을 제한하기 위한 노드 수준 시행 메커니즘으로 Intel RAPL을 사용하여 시스템은 워크로드를 인식하여 우선순위가 높은 지연 시간 민감 워크로드는 최후의 수단으로만 스로틀링되도록 합니다. Dynamo를 배포한 결과 저자들은 데이터 센터에서 동적 코어 주파수 부스팅의 사용 증가, 즉 충분한 전기적 및 열적 여유가 주어지면 더 높은 주파수에서 CPU 코어를 실행할 수 있는 Intel Turbo Boost[71]를 통해 전력 용량 사용률이 크게 증가했다고 언급합니다. 앞서 설명한 사례 연구 시스템과 마찬가지로 Dynamo는 애플리케이션 특정 지식과 세분화된 하드웨어 노브를 결합하여 애플리케이션 성능 경계를 존중하면서 WSC의 실현 가능한 컴퓨팅 기능을 개선합니다.

**9.6 데이터 센터의 환경적 지속 가능성**

지금까지 우리는 주로 데이터 센터의 전기 소비를 살펴보았습니다. 에너지 사용과 지속 가능성은 관련이 있지만, 환경적 지속 가능성은 에너지 외의 자원(예: 담수)과 데이터 센터의 직간접적인 온실 가스 배출을 포함하는 더 광범위한 주제입니다. 이러한 지속 가능성 문제를 해결하는 것은 자원이 점점 더 부족해지는 세상에서 인류의 환경 발자국을 줄이는 데 점점 더 중요한 영향을 미칩니다.

**9.6.1 배출: 스코프 1, 2, 3**

대기 중 온실 가스 농도는 산업 혁명 시작 이후 크게 증가했으며, CO2 농도는 1700년대 평균 280ppm에서 2024년 422ppm으로 51% 증가했습니다. 인간 활동은 농업, 삼림 벌채, 화석 연료 에너지 생성과 같은 활동을 통해 이러한 증가에 크게 기여했습니다[72].

환경적 지속 가능성은 많은 하이퍼스케일러의 우선순위였으며 온실 가스(GHG) 배출, 물 사용, 폐기물 처리 및 유해 물질과 같은 광범위한 영역을 포괄합니다.

GHG 배출은 세 가지 범주 또는 스코프(scope)로 나뉩니다.

*   **스코프 1 배출**은 회사 차량, 직원 출장, 사무실 난방 또는 백업 발전기에 의한 화석 연료 소비와 같이 회사가 운영의 일부로 직접 제어하는 직접 배출입니다.
*   **스코프 2 배출**은 회사가 유틸리티로부터 구매하는 에너지로 인해 발생하는 간접 배출입니다. 데이터 센터의 경우 스코프 2는 종종 GHG 배출의 주요 범주입니다.
*   **스코프 3 배출**은 회사의 가치 사슬에서 발생하는 간접 배출, 즉 회사가 구매하는 제품 및 서비스에 내재된 배출입니다. WSC의 경우 데이터 센터용 콘크리트 및 철강 또는 칩 및 기타 전자 부품을 생산하기 위해 배출되는 GHG가 그 예입니다.

WSC의 경우 스코프 1 배출은 미미합니다. 2023년 Google의 스코프 1 배출은 전체 배출량의 1%를 차지했습니다[73].

스코프 2 배출의 대부분은 유틸리티의 화석 연료 기반 전기 발전에서 나옵니다. 따라서 스코프 2 배출을 줄이는 것은 주로 무탄소 에너지(CFE) 비율을 높여 화석 연료 원천에서 생성되는 전기를 줄이는 것에서 비롯됩니다. 이를 달성하는 한 가지 방법은 유틸리티 또는 독립 전력 생산자로부터 무탄소 전기를 구매하는 것과 같은 시장 조치를 통하는 것입니다. 2017년부터 Google은 연간 총 에너지 소비량을 100% 재생 가능 에너지와 일치시켰습니다. (공식적인 스코프 2 발자국은 GHG 프로토콜이 현재 지역 외 재생 가능 에너지 구매를 계산하지 않기 때문에 여전히 0이 아닙니다.) 최근에는 그 목표가 모든 위치에서 24시간 내내 100% 무탄소 에너지를 달성하는 것으로 확대되었습니다. 2023년 현재 Google은 시간당 64% CFE에 도달했으며 10개 이상의 데이터 센터 위치에서 시간당 90% CFE를 달성했습니다[73].

대부분의 재생 가능 에너지 형태의 간헐성을 감안할 때(바람이 계속 불지 않고 밤에는 태양이 비치지 않음), 100% 재생 가능 에너지 발전을 보장하는 것은 어려운 일입니다. 이를 해결하는 한 가지 방법은 다음 섹션에서 설명하는 것처럼 재생 가능 에너지 가용성이 높을 것으로 예측되는 기간으로 시간 민감도가 낮은 워크로드의 실행을 옮기는 등 에너지 소비 패턴을 재생 가능 에너지의 가용성과 일치시키는 것입니다.

스코프 3 배출(때로는 "내재된(embedded) 또는 체화된(embodied) 배출"이라고 함)은 조직이 야기한 다른 모든 간접 배출을 나타냅니다(예: 서버 제조 또는 데이터 센터 건설 중). WSC에서 호스팅되는 IT 장비는 WSC 운영자의 스코프 3 배출의 대다수를 차지하며, 건물 자체에 내재된 배출이 그 뒤를 따릅니다. 이러한 배출은 공급업체에서 발생하므로 줄이기가 더 어렵습니다. WSC 운영자가 스코프 3 배출을 줄이기 위해 취할 수 있는 한 가지 조치는 공급업체가 운영을 탈탄소화하도록 장려하거나 요구하는 것입니다. 전자 장비의 경우 내재된 배출의 약 절반은 제조 공정 중 에너지 소비에서 비롯되므로 제조 국가에서 재생 가능 에너지를 늘리면 이러한 배출을 크게 줄일 수 있습니다.

스코프 2와 스코프 3 배출을 비교하는 것은 GHG 회계 규칙이 이를 다르게 처리하기 때문에 어렵습니다. 스코프 2 배출은 서버 수명 동안 발생하므로 서버가 1년 차에 총 에너지의 6분의 1을 소비하면 해당 에너지의 탄소만 해당 연도의 배출량에 계산됩니다. 대조적으로 서버에 내재된 모든 스코프 3 배출은 1년 차에 계산됩니다. 수명이 20-30년인 데이터 센터의 경우 모든 내재된 탄소가 1년 차 배출로 계산되기 때문에 이러한 왜곡이 더욱 두드러집니다. 이것은 기술적으로 정확하지만(건물은 실제로 그해에 완성되었고 모든 내재된 배출이 배출되었습니다), 스코프 2와 스코프 3 배출을 직접 비교하기 어렵게 만듭니다. 예를 들어 Google의 2023년 배출량에서 스코프 3이 스코프 2보다 3:1로 많았지만, 이 비율이 서버의 총 탄소 발자국이 내재된 배출에 의해 지배된다는 것을 의미하지는 않습니다. TPU의 실제 수명 주기 발자국 분석에 따르면 TPU가 평균 탄소 강도를 가진 그리드에서 실행될 때 스코프 2 배출이 총 배출량의 70%를 차지하는 것으로 나타났습니다[74].

WSC 운영자가 스코프 3 배출을 줄이는 데 취할 수 있는 직접적인 역할은 사용률 및 초과 할당을 늘리거나 서버의 운영 수명을 연장하여 배포되는 새로운 IT 장비의 양을 줄이는 것입니다. 따라서 이 장의 전반부에서 논의한 효율성 개선은 비용을 절감할 뿐만 아니라 스코프 2 및 3 배출도 줄입니다. 마찬가지로 재판매를 통해 구성 요소의 수명을 연장하면 스코프 3 배출이 감소합니다. 예를 들어 오래된 DIMM은 서버용으로 계속 사용하기에는 너무 느릴 수 있지만 구형 PC를 업그레이드하는 데는 여전히 매력적일 수 있습니다. 마찬가지로 폐기된 랙이나 네트워크 케이블에서 강철이나 구리를 재활용하면 배출이 줄어듭니다.

건물 배출의 경우 Google의 내부 분석에 따르면 콘크리트와 강철이 데이터 센터 GHG 배출의 가장 큰 탄소 기여자입니다. 건물 상부 구조에는 이 내재된 탄소의 대부분이 포함되어 있습니다. 시멘트는 일반적으로 콘크리트 혼합물의 7-15%만 형성하지만 콘크리트에 내재된 탄소의 최대 약 80%를 차지할 수 있습니다. 시멘트 생산은 생산 중 높은 온도가 필요하며(주로 화석 기반 연료로 달성), 원자재 추출 및 운송이 화석 연료에 의존하기 때문에 탄소 집약도가 높습니다. 또한 시멘트를 생산하는 화학 반응은 대기 중으로 이산화탄소를 방출합니다.

그러나 저탄소 시멘트 대안이 등장하기 시작했습니다. 최근 모든 주요 하이퍼스케일러는 탄소 배출에 대한 영향이 적은 비산회(fly ash) 및 슬래그(slag) 사용, 석회석 소성 점토 시멘트(LC3)와 같은 더 탄소 친화적인 재료, 콘크리트에 탄소 저장과 같은 장기적인 접근 방식을 포함하여 저탄소 콘크리트에 대한 더 많은 작업을 촉구했습니다[75].

마찬가지로 저탄소 강철이나 매스 팀버(CLT 또는 GluLam이라고도 함)와 같은 강철 대안은 WSC 데이터 센터의 탄소 배출을 줄일 수 있습니다. 이러한 공학 목재 제품은 뛰어난 강도와 내화성을 제공하며 상업 및 주거용 고층 건물의 강철과 콘크리트를 대체하기 시작했습니다[76]. 데이터 센터는 더 많은 강도를 요구하지만(바람 저항 및 훨씬 더 무거운 장비 부하 때문에), 매스 팀버는 데이터 센터에서도 강철과 콘크리트를 적어도 부분적으로 대체할 가능성이 높습니다[77]. OpenCompute 재단은 탄소 회계 및 원격 측정에 대한 지표를 포함하여 데이터 센터 지속 가능성에 대한 트랙도 가지고 있습니다.

많은 대기업, 특히 WSC를 운영하는 기업은 온실 가스 발자국과 배출을 크게 줄이겠다는 약속을 했습니다. 2017년부터 Google은 전기 소비의 100%를 재생 가능 에너지 발전과 일치시켰습니다[78]. 2030년까지 Google은 24시간 내내 무탄소 에너지로 완전히 운영하고 스코프 1, 스코프 2, 스코프 3 배출을 합쳐 2019년 기준 대비 50% 줄이는 것을 목표로 합니다[79]. 다른 대규모 하이퍼스케일러들도 유사한 약속과 진전을 이루었습니다. Microsoft는 2025년까지 스코프 1 및 스코프 2 배출 거의 0을 목표로 하고 있으며, 2030년까지 스코프 1, 2, 3 배출을 전체적으로 50% 줄이는 것을 목표로 합니다[80]. Meta는 재생 가능 에너지 인증서(REC) 구매를 포함하는 시장 기반 방법론을 사용하여 스코프 1 및 스코프 2에 대해 순 배출 제로를 달성했으며, 2030년까지 전체 가치 사슬 전반에 걸쳐 순 배출 제로를 목표로 합니다[81].

**9.6.2 탄소 인식 스케줄링 (Carbon-aware scheduling)**

위에서 설명한 야심 찬 탄소 목표에는 WSC 운영자의 새로운 접근 방식이 필요합니다. 매일 매시간 전기 소비를 완전히 탈탄소화(24/7)하려면 각 위치의 무탄소 에너지 수요와 공급을 정확하게 일치시켜야 합니다. 그러한 최적화 중 하나는 지역별 시간당 무탄소 에너지 가용성에 따라 서로 다른 데이터 센터 간에 컴퓨팅 작업을 이동하는 것입니다. 이러한 탄소 지능형 스케줄러는 에너지 혼합에 대한 하루 전 예측을 사용하여 전 세계로 컴퓨팅을 이동시키며 무탄소 전기가 더 많은 지역을 선호합니다[82]. 어떤 면에서 7장의 용어를 사용하면 이를 소프트웨어 정의 탄소 효율성(software-defined carbon efficiency)으로 볼 수 있습니다. 다른 소프트웨어 정의 접근 방식과 마찬가지로 적절한 정책은 3장에서 정의된 워크로드 SLO가 계속 충족되도록 합니다.

청정 에너지 가용성에 맞춰 위치 간에 컴퓨팅 작업을 이동하는 것 외에도 태양광 및 풍력과 같은 무탄소 에너지원이 풍부할 때 더 많은 전기를 사용하도록 시간을 이동하여 컴퓨팅 작업을 수행할 수도 있습니다. 많은 배치 작업은 어느 정도 유연성이 있으며(예: "자정에 실행" 대신 "자정 이후에 실행하고 오전 9시까지 완료") 따라서 필요에 따라 시간 이동을 할 수 있습니다.

**9.6.3 물 (Water)**

데이터 센터는 전기 형태로 많은 양의 에너지를 소비하며, 사실상 모든 에너지는 폐열 에너지로 변환되어 시설에서 제거되어야 합니다. 물은 이 열 제거 과정의 필수적인 부분입니다. 열교환기 루프에서 열 전달 매체로 사용되는 것부터 기화(vaporization)를 통해 환경으로 열을 전달하는 방법으로 냉각탑에서 직접 증발되는 것(5장 참조)까지 다양합니다. 수랭식 냉각은 물 사용과 에너지 사용 사이의 상충 관계를 포함합니다. 수랭식 냉각(공랭식에 비해)은 데이터 센터의 에너지 사용과 관련 탄소 배출을 10% 줄일 수 있습니다[83].

일반적으로 데이터 센터 운영에는 상수도(municipal sources)의 담수가 사용됩니다. 담수는 가뭄으로 어려움을 겪는 지역에서 귀중한 자원이며, 신중한 물 관리가 중요한 고려 사항입니다. 어떤 경우에는 담수 이외의 수원, 예를 들어 수처리 공장의 재생수("중수")나 심지어 해수도 사용할 수 있습니다. Google 데이터 센터 캠퍼스의 25%는 이러한 수원을 사용합니다[83].

The Green Grid는 물 사용 효율성 지표(WUE: Water Usage Effectiveness)의 형태로 물 효율성을 측정하기 위한 산업 표준 지표를 제안했습니다. WUE는 데이터 센터가 연간 소비한 물의 양(리터)을 데이터 센터의 에너지 사용량(kWh)으로 나눈 값으로 정의됩니다[84].

$$
WUE = \frac{\text{물 사용량}(l)}{\text{에너지 사용량}(kWh)}
$$

WUE는 데이터 센터의 물 사용 효율성을 정량화하고 추적하는 데 좋은 시작입니다. 그러나 지표로서 여전히 개선의 여지가 있습니다.

*   현재 WUE 지표는 재생수 또는 비식수 사용을 담수 사용과 동일하게 가중치를 두므로 WSC의 물 사용이 상수도 공급에 미치는 영향을 정확하게 반영하지 않습니다.
*   마찬가지로, 그렇지 않으면 식수를 사용했을 다른 용도(예: 관개용)를 위해 배출된 WSC 폐수를 재사용하는 것을 고려하지 않습니다.
*   마지막으로, 화력 발전소의 냉각수와 같이 데이터 센터에 공급하는 발전소가 소비하는 물을 포함하지 않습니다. 이러한 "상류(upstream)" 물 소비는 현장 데이터 센터 소비만큼 높거나 더 높을 수 있습니다(그러나 데이터 센터가 태양광 및 풍력 발전에서 모든 전력을 공급받는 경우 거의 0이 될 것입니다).

이러한 이유로 공식 WUE 지표는 데이터 센터의 물 영향을 정확하게 나타내지 못하지만 업계의 많은 곳에서 WUE를 보고합니다. 업계 평균 WUE는 1.8L/kW-hr로 추정됩니다[5]. 대규모 WSC 운영자는 훨씬 낮은 WUE 측정값을 달성했습니다. Meta는 0.26[85], AWS는 0.25[86]의 WUE를 가집니다. Google은 WUE를 보고하지 않지만 모든 소스의 총 물 사용량을 보고합니다.

수랭식 데이터 센터는 많은 양의 물(하루 수백만 리터)을 소비하지만 다른 용도에 비하면 물 사용량은 적습니다. 예를 들어 Google의 2023년 전체 글로벌 물 소비량은 건조한 미국 남서부의 골프장 41개 수준에 불과하며, 전 세계적으로는 약 39,000개의 골프장이 있는 것으로 추정됩니다. 따라서 에너지 소비와 달리 데이터 센터 물 소비는 전 세계적으로 중요한 역할을 하지 않습니다. 그러나 데이터 센터가 지역 물 공급에 영향을 미칠 수 있는 지역적으로는 여전히 신중하게 관리해야 합니다.

많은 WSC 운영자는 워터 포지티브(water positive), 즉 소비하는 것보다 더 많은 물을 생산하겠다고 약속했습니다. Google은 2030년까지 데이터 센터와 사무실 전반에 걸쳐 물 소비량의 120%를 지역 수원에 보충한다는 목표로 워터 포지티브가 되겠다는 약속을 했습니다[87]. Meta와 AWS도 2030년까지 워터 포지티브가 되겠다는 유사한 목표를 가지고 있습니다[88], [86]. 일반적인 물 보충 프로젝트는 폐수 또는 우수를 처리하여 지역 대수층에 주입하는 확장된 폐수 처리 공장으로 구성됩니다.

**9.6.4 기타 지속 가능성 고려 사항**

온실 가스 배출과 물 사용량은 WSC가 환경에 미치는 쉽게 정량화할 수 있는 물리적 영향이지만, WSC 소유자와 운영자는 다른 요소도 고려해야 합니다. 데이터 센터는 진공 속에 존재하지 않습니다. 그것은 지역 사회의 일부이며 데이터 센터는 이웃으로서 지역 사회에 긍정적이고 부정적인 방식으로 영향을 미칠 수 있습니다. WSC는 건설 중인 데이터 센터 직원과 건설 노동자를 고용하여 경제적 기회를 제공할 수 있지만, 현지 인력이 이러한 기회를 실현할 수 있는 기술을 습득하도록 보장하는 것은 WSC에 달려 있습니다.

데이터 센터는 또한 폐기물, 그중 많은 부분이 전자 폐기물(e-waste)을 생성하므로 오염을 최소화하고 재사용 가능한 귀금속 및 기타 귀중한 자원을 회수하기 위해 재활용해야 합니다. 적절한 전자 폐기물 처리는 어렵고 강력한 환경 통제하에 이루어져야 합니다. 구형 장비에 대한 2차(즉, 재판매) 시장을 찾으면 유효 수명을 연장할 수 있는 경우가 많습니다.

WSC 운영자는 현장에서 발생하는 오염을 최소화하기 위해 주의를 기울여야 합니다. 예를 들어 백업 발전기에 사용되는 디젤 연료의 적절한 저장 및 봉쇄 절차를 보장하고 배출되는 냉각수를 처리하여 오염 물질을 제거해야 합니다. WSC는 또한 구매력을 통해 더 광범위한 변화를 주도하는 역할을 할 수 있습니다. 예를 들어 Google은 의무 사항이 아닌 관할권에서도 RoHS 준수(유해 물질 제한) 구성 요소를 요구합니다. RoHS는 다양한 유형의 전자 장비 제조에 사용할 수 있는 납, 수은, 카드뮴, PBB 및 기타 유해 물질과 같은 독성 물질의 양을 제한합니다.

**9.7 AI의 에너지 사용**

지금까지 우리는 WSC 에너지 효율성에 대해 전반적으로 이야기했지만, 이 섹션에서는 AI/ML 워크로드의 에너지 사용에 대해 논의할 것입니다. AI 워크로드의 중요성이 커짐에 따라 일부 선정적인 주장을 포함하여 기계 학습(ML) 워크로드의 에너지 집약도를 강조하는 학술 논문이 늘어나고 있습니다. 매년 수백 퍼센트씩 기하급수적으로 증가하는 워크로드는 실제로 우려의 원인이 되며 ML의 탄소 배출에 대한 논의를 높이는 데 가치가 있지만 실제 그림은 미묘합니다.

Google의 에너지 사용량은 검색 엔진과 이후 Google Cloud의 성공에 힘입어 10년 이상 매년 15-20%씩 증가해 왔습니다. 그 사용량 내에서 ML의 비율은 2019-2021년 동안 전체 에너지 사용량의 15% 미만을 나타내며 일정하게 유지되었습니다[89]. 추론은 ML을 사용하는 수많은 10억 사용자 서비스 덕분에 2021년 전체 ML 에너지 소비의 약 60%를 차지했습니다. 일찍이 2018년에 Google은 기존 CPU 사이클보다 더 많은 "ML 사이클"을 사용한다고 보고했습니다. 초당 연산 횟수가 높음에도 불구하고 CPU 사이클이 연간 에너지 소비의 대부분을 차지하는데, 이는 ML 연산이 4비트, 8비트 및 16비트 연산이 주를 이루는 반면 CPU는 일반적으로 64비트 데이터를 처리하기 때문입니다.

전체 AI 전력 소비를 추정하기 위해 GPU 출하량에 대한 공개 데이터를 사용할 수 있습니다. 구체적으로 NVIDIA는 2024년에 350만-500만 개의 데이터 센터 GPU를 출하할 것으로 추정되었으며, 피크의 60-70% 평균 전력 소비를 가정할 때 실제 전력 소비는 약 2-2.5GW로 해석됩니다. 다른 모든 ML 가속기(다른 모든 NVIDIA 모델, AMD와 같은 경쟁사의 GPU 및 TPU 포함)가 1-1.5GW를 추가한다고 하면 2024년에 3-4GW의 AI 성장을 나타냅니다. 데이터 센터가 소비하는 총 전력(9.8.1절 참조)과 비교할 때 이 추정치는 AI가 2024년 전체 데이터 센터 전력을 15-20% 증가시켰음을 시사합니다.

그러나 일부 연구에서는 단 몇 년 만에 전체 데이터 센터 에너지 소비를 3배 또는 4배로 늘릴 엄청난 미래 성장을 제안합니다(그림 9.20 [90]). 이러한 매우 높은 AI 에너지 추정치의 주된 이유는 기술은 일정하게 유지되지만 문제 크기가 기하급수적으로 증가하여 에너지도 기하급수적으로 증가한다고 가정하기 때문입니다. 실제로 기술은 소프트웨어와 하드웨어 모두에서 매우 빠르게 발전했습니다. 예를 들어 불과 4년 동안 트랜스포머 모델 학습 효율성은 83배 향상되었습니다[89]. 마찬가지로 2024년에 출시된 새로운 GPU는 이전 GPU에 비해 동일한 모델을 학습하는 데 필요한 에너지를 거의 4배 개선했습니다[91]. GPT-3.5 수준에서 수행하는 시스템의 추론 비용은 2022년 11월과 2024년 10월 사이에 280배 이상 떨어졌습니다[92].

소프트웨어, 알고리즘 및 하드웨어의 이러한 급격한 발전으로 AI의 에너지 효율성은 놀라운 속도로 개선되어 수요 증가의 상당 부분을 상쇄하고 있습니다. 또한 모델이 충분히 작아지면 휴대폰과 같은 최종 사용자 장치에서 실행할 수 있어 데이터 센터 에너지 사용량을 0으로 떨어뜨릴 수 있습니다. 따라서 AI 사용을 올바르게 예측할 수 있다고 해도 데이터 센터에서의 AI 에너지 소비를 정확하게 예측하기는 매우 어렵습니다.

동시에 제본스의 역설(Jevons' paradox)[93]은 효율성의 큰 개선이 수요를 크게 증가시켜 효율성 절감 효과를 상쇄할 수 있음을 시사합니다. 그러나 경제적 현실은 AI가 수익성이 있기 전까지는 AI 에너지 사용이 너무 오랫동안 기하급수적으로 증가하는 것을 방지하므로 제본스의 역설이 완전히 발휘될 수는 없습니다.

이 대략적인 계산을 고려해 보십시오. 1GW 데이터 센터를 건설하고 GPU로 채우는 데는 약 300억-400억 달러가 듭니다. 그 중 대부분은 GPU 비용입니다(500-750W GPU당 15,000달러 할인가 가정). 그 외에도 6년 동안 해당 GPU를 실행하려면 전력, 인력, 유지 관리 등에 100억-200억 달러가 더 소요되어 설치된 ML 용량의 GW당 총 6년 비용은 약 400억-500억 달러가 됩니다. 이 AI 용량을 소비하는 제품의 개발, 판매 및 마케팅 비용을 지불하기 위해 최소 50%의 총마진을 가정하면 설치된 AI 용량 GW당 6년 매출 1,000억 달러, 즉 연간 매출 160억 달러가 필요합니다.

이 수치를 원근감 있게 보면, 오늘날(2024년경) 전 세계적으로 연간 1,000억 달러 이상의 매출을 올리는 회사는 100개 미만이므로, "단지" 6GW의 ML 용량을 필요로 하는 가상의 AI 애플리케이션은 세계에서 가장 큰 회사 중 하나가 되겠지만 세계 전기의 0.1% 미만을 사용할 것입니다(세계의 설치된 발전 용량은 약 7500GW). 따라서 언젠가 AI가 세계 전기의 1%를 사용할 것이라고 생각할 수는 있지만, 이를 위해서는 AI 기반 애플리케이션이 세계 최대 기업에 필적하는 수익을 창출해야 하므로 빠른 시일 내에 일어나지는 않을 것임을 시사합니다. 세쿼이아 캐피탈의 데이비드 칸은 2023년과 2024년에 다른 가정을 사용했지만 유사한 수치에 도달하는 유사한 분석을 발표했습니다[94].

또한 이러한 비용의 규모는 대규모 AI 제공 업체가 AI 학습 및 추론의 효율성을 개선하는 데 지속적으로 집중하도록 보장할 것입니다. 이 분야의 상대적으로 미성숙한 상태를 감안할 때 차수 단위(order-of-magnitude)의 개선이 가능하므로 향후 몇 년 동안 AI 에너지 사용의 실제 범위를 예측하기 어렵습니다. 이 책의 다음 판에는 더 정확한 답이 있겠지만, 현재로서는 효율성 개선과 경제적 제약 모두가 AI 에너지 성장을 완화할 것이기 때문에 고급 예측이 실현되지 않을 것으로 예상합니다. 일부 업계 전문가들도 유사한 분석을 바탕으로 비슷한 결론에 도달합니다[95].

어떤 면에서 AI 에너지 사용에 대한 우려는 2000년경 초기 인터넷 붐 동안 인터넷 에너지 사용에 대해 표현된 우려와 유사합니다. 예를 들어 여러 논문은 인터넷이 1999년에 미국 전체 전기의 8-10%를 소비할 것으로 추정하고 이것이 곧 30%로 상승할 것으로 예측했지만, 이후 연구에서는 이러한 수치를 수정하여 훨씬 낮은 기준선과 훨씬 낮은 성장을 보여주었습니다[96]. 마찬가지로 비디오 스트리밍은 2030년까지 전 세계 전기의 최대 51%에 달하는 막대한 양의 에너지를 사용할 것으로 예상되었지만[97], 현재 추정치는 0.5%에 가까운 수치를 시사합니다(다음 섹션 참조).

에너지 소비가 우려보다 훨씬 적은 것으로 판명된 이유는 무엇일까요? 두 경우 모두 급속한 효율성 개선(즉, 처리, 저장 또는 전송된 바이트당 에너지의 대폭 감소)이 기하급수적으로 증가하는 인터넷 사용량을 대부분 보상했으며, 그 추세는 20년 동안 안정적으로 유지되었습니다. AI 에너지 사용에 대해서도 동일한 패턴이 반복될지 확신하기에는 너무 이르지만 평행선은 사실로 남아 있습니다.

AI의 발자국에는 AI 하드웨어를 사용하는 동안 소비되는 에너지(위에서 논의됨)뿐만 아니라 제조 중 소비되는 에너지도 포함됩니다. 5세대 TPU에 대한 심층 연구에 따르면 제조 에너지는 운영 에너지에 비해 상대적으로 작습니다[98]. 정확한 수치는 제조 및 데이터 센터 위치의 에너지 믹스에 따라 다르지만 해당 연구의 경험 법칙에 따르면 내재된 배출은 AI 시스템 평생 배출의 약 10%를 나타내고 운영 배출은 약 90%를 나타냅니다.

**9.8 인터넷의 에너지 사용**

WSC 데이터 센터는 인터넷 물리적 인프라의 중요한 구성 요소이며, 인터넷의 고도로 분산된 설계에서 규모를 가진 구조물의 드문 가시적 사례 중 하나입니다. 그 결과 그들은 무명에서 벗어나 논의의 요점이 되었으며, 특히 전력 수요가 그들을 제공하는 전력망과 비교하여 중요해지는 곳에서 더욱 그렇습니다.

**9.8.1 데이터 센터 에너지 사용**

데이터 센터 에너지 사용은 지난 10년 동안 상당히 바뀌었습니다. 전 세계적으로 2010년 데이터 센터가 소비한 총 에너지의 80% 이상은 WSC가 아닌 소규모 데이터 센터에 있었습니다[99], [100]. 불과 8년 후, 그 수요의 절반 이상이 WSC로 이동했고 소규모 데이터 센터에는 약 3분의 1의 사용량만 남았습니다. 같은 기간 동안 컴퓨팅은 훨씬 더 효율적이 되었습니다. 컴퓨팅 인스턴스는 550% 증가했지만 총 에너지 사용량은 6%만 증가했습니다. 이전 섹션을 읽은 독자는 그 이유를 알 것입니다. WSC PUE가 훨씬 더 좋고, 무어의 법칙이 계산당 에너지를 줄였으며, WSC 기반 클라우드 서비스가 훨씬 더 높은 사용률로 실행되기 때문입니다. 2018년 전 세계 총 데이터 센터 에너지 소비량은 205TWh, 즉 23.4GW의 평균 연간 전력 소비였습니다. 비교를 위해 Google의 2018년 전기 소비량은 10.1TWh로 전체의 약 5%였으며[101], Microsoft는 8TWh였습니다[102].

2024년 미국 데이터 센터 에너지 소비에 대한 연구에서는 2023년 176TWh, 즉 미국 전기 소비의 4.4%로 추정했습니다[90]. 비교를 위해 Google의 2023년 전기 소비량은 25TWh[73]로 전체의 약 14%였으며, Microsoft는 24TWh였습니다. 온프레미스 IT가 클라우드로 계속 마이그레이션됨에 따라 이 두 회사의 에너지 점유율은 이 기간 동안 10%에서 27%로 증가했습니다.

비교를 위해 2023년에 560GW의 무탄소 에너지(CFE)가 설치되었습니다. 이 수치는 데이터 센터 수요에 비해 크지만 CFE가 모든 새로운 데이터 센터에 전력을 공급할 수 있다는 것은 아닙니다. 첫째, 560GW의 60%가 중국에 집중되었습니다. 둘째, 이 수치는 평균 발전량이 아니라 피크 용량을 나타냅니다. 태양광 발전소의 경우 일반적인 용량 계수(capacity factor)는 15%에서 25% 사이이므로 560GW의 피크 용량은 약 90-140GW의 평균 발전 용량으로 해석됩니다. 이 발전 중 일부는 기존 석탄 또는 가스 발전소를 대체하여 그리드를 탈탄소화하지만 반드시 확장하는 것은 아닙니다. 또한 가구(히트 펌프, 전기 자동차) 및 산업의 전동화는 데이터 센터가 필요로 하는 것보다 훨씬 더 많은 부하 증가를 생성하므로 추가 발전이 다른 곳에서도 필요합니다. 그럼에도 불구하고 충분한 새로운 무탄소 에너지가 건설되고 있으며 하이퍼스케일러들은 지난 5년 동안 에너지 공급의 탄소 집약도를 크게 줄일 수 있었습니다.

국제 에너지 기구(IEA)에 따르면 전 세계적으로 데이터 센터 에너지 사용은 전 세계 전력 수요의 1-2% 수준으로 유지되었습니다[103]. 2020년 IEA는 데이터 센터 사용량을 223TWh로 추정하여 2018년 이후 9% 성장했습니다[104]. 2024년에는 2022년 소비량이 240-340TWh, 즉 전 세계 최종 전력 수요의 약 1-1.3%로 추정되었습니다[103].

**9.8.2 암호화폐 에너지 사용**

데이터 센터 에너지 사용에 대한 논의에서는 암호화폐 채굴을 위한 특수 클래스의 새로운 데이터 센터도 고려해야 합니다. 이러한 데이터 센터는 규모 면에서 WSC와 비슷할 수 있지만 전력, 냉각 및 하드웨어 서비스만 제공하고 특수 하드웨어만 호스팅하기 때문에 WSC가 일반적으로 제공하는 서비스는 제공하지 않습니다.

가장 주목할만한 비트코인을 포함한 여러 암호화폐는 "작업 증명(proof of work)" 접근 방식을 사용하여 거래를 검증하고 새로운 통화를 "채굴"합니다. "작업 증명"은 상당한 컴퓨팅 파워가 필요한 복잡한 암호화 퍼즐을 풀어 블록체인에 거래 블록을 추가합니다. 블록체인에 블록을 추가하는 대가로 채굴자는 새로운 암호화폐 코인 형태의 거래 수수료를 보상받습니다. 약 4년마다 새로운 비트코인 블록 검증에 대한 보상이 절반으로 줄어듭니다. 이는 비트코인 공급을 제어하기 위해 수행됩니다. 이것이 없다면 하드웨어 성능 개선으로 인해 공급이 계속 증가할 것입니다. 채굴자는 작업 증명을 수행하기 위해 특수 ASIC 또는 GPU를 사용합니다.

설계상 비트코인 채굴은 값비싼 계산을 포함하며, 이는 결과적으로 큰 에너지 발자국을 생성합니다. 미국 에너지 정보청(EIA)은 2023년 현재 비트코인 및 기타 디지털 통화 채굴이 미국 전기 사용량의 0.6-2.3%를 차지하는 것으로 추정합니다[105]. 산업 협회들이 법원에서의 에너지 소비 공개 노력에 맞서 싸워왔기 때문에 실제 데이터는 부족합니다.

케임브리지 비트코인 전기 소비 지수(CBECI [106])는 비트코인 및 이더리움 채굴 작업의 일일 및 연간 전력 수요를 추정합니다. 2024년 4월 현재 CBECI는 연간 소비량을 175TWh로 추정하며, 하한은 80TWh, 상한은 500TWh입니다. IEA는 비트코인 에너지 사용량을 2022년 110TWh, 2023년 130TWh로 추정했습니다[107]. 따라서 비트코인 에너지 소비에 대한 보수적인 추정치는 모든 퍼블릭 클라우드 데이터 센터를 합친 것과 비슷하며, 더 높은 추정치는 총 데이터 센터 수요보다 클 것입니다.

일부 암호화폐, 특히 이더리움은 "작업 증명" 대신 "지분 증명(proof of stake)"으로 알려진 프로세스를 사용합니다. 거래를 검증하기 위해 참가자는 블록체인의 기본 토큰 일부를 담보로 겁니다. 이러한 검증자는 거래가 성공적으로 완료되면 보상을 받고 그렇지 않으면(불법적인 거래를 수행하려는 시도를 나타냄) 벌금을 뭅니다. "지분 증명" 암호화폐는 훨씬 적은 에너지를 사용하며, 그 결과 CBECI는 이더리움의 총 에너지 사용량을 비트코인의 0.005%로 둡니다.

**9.8.3 엔드-투-엔드 인터넷 에너지 사용**

2020년 에너지 사용에 대한 2023년 IEA 보고서 분석(그림 9.21)은 사용자 장치와 글로벌 WAN 네트워크를 IT 관련 에너지의 주요 소비자로 보여줍니다[108]. 데이터 센터는 전체적으로 약 25%를 사용하며 WSC에는 8.5%가 귀속됩니다.

언뜻 보기에 이 결과는 놀랍습니다. 당연히 우리는 클라우드 컴퓨팅의 에너지 사용 대부분이 클라우드를 호스팅하는 데이터 센터에 있을 것으로 예상합니다. IEA 연구는 추정치 뒤에 숨겨진 상세 계산을 보여주지만 간단한 대략적 계산이 상대적 비율을 설명하는 데 도움이 됩니다.

*   2023년 Google의 평균 글로벌 전력 소비는 GCP와 검색 및 YouTube와 같은 소비자 서비스를 포함하여 약 3GW였습니다[73]. 이 인프라가 30억 명의 사용자에게 서비스를 제공한다고 단순하게 가정하면 사용자당 1W의 지속적인 전력 소비를 얻게 됩니다.
*   일반적인 케이블 또는 광대역 모뎀은 10W 이상을 소비합니다.
*   Wi-Fi 액세스 포인트는 속도에 따라 5-20W의 전력을 사용합니다.
*   휴대폰은 충전 오버헤드를 포함하여 약 1-3W의 전력을 사용합니다. 일반적인 무선 전화기 충전기는 0.5W의 대기 전력을 소비합니다[109].

다시 말해, 사용하지 않는 무선 전화기 충전기 두 개가 해당 사용자의 모든 Google 서비스만큼의 전기를 소비합니다! 이러한 추정치는 다른 연구와 일치합니다. 예를 들어 국제 전기 통신 연합(ITU)은 2022년 스마트폰의 에너지 사용량을 23TWh로 추정했는데, 이는 모든 클라우드 공급자가 소비한 85TWh의 약 4분의 1입니다[110]. 더 큰 최종 사용자 장치는 훨씬 더 많은 에너지를 필요로 합니다. PC 에너지 소비는 392TWh로 추정되며, 이는 휴대폰보다 한 자릿수 더 높고 클라우드를 호스팅하는 데이터 센터 소비량의 거의 5배입니다.

세계은행과 ITU의 대규모 연구는 IT 에너지 사용에 대해 "전 세계 배출량의 최소 1.7%가 ICT 부문에서 비롯된다"는 유사한 전반적인 결론에 도달했습니다[110]. ICT 기업이 전 세계 기업 재생 가능 에너지 구매의 60%를 차지하므로 IT의 배출 점유율은 전기 소비 점유율보다 작습니다. 이 연구의 데이터 센터, 네트워크 등에 걸친 IT 에너지 분할은 위의 IEA 보고서와 매우 유사합니다.

다른 두 연구는 시청한 비디오 시간당 에너지 소비를 계산하여 위의 수치와 일치하는 값에 도달했습니다. IEA는 비디오를 표시하는 장치에 따라 2019년 비디오 스트리밍의 엔드-투-엔드 전력 소비를 37-77W로 추정했습니다[111]. TV나 노트북에 표시될 때는 화면 에너지 소비가 소비를 지배하는 반면, 휴대폰에서는 네트워크 전송이 소비를 지배합니다. Wi-Fi 및 WAN 네트워크는 정보 코딩 효율성이 그 이후로 적어도 4배 증가했기 때문에 2019년 이후 에너지 효율성이 훨씬 높아졌으므로 네트워크 에너지 추정치는 오늘날 훨씬 더 작을 것입니다.

Carbon Trust의 2021년 연구[112]는 주로 계산에 가정용 Wi-Fi 라우터를 포함하고 평균 화면(71W)만큼 많은 에너지를 사용한다고 가정하기 때문에 대략 두 배 높은 수치에 도달합니다. 이러한 높은 추정치에도 불구하고 비디오 시간당 결과적인 탄소 영향은 매우 낮습니다. 이 연구는 유럽 평균 발자국을 비디오 스트리밍 시간당 55g CO2로 둡니다. 비교를 위해 팝콘 한 봉지를 전자레인지에 4분 동안 돌리는 데 따른 배출량은 약 16g CO2이고 평균적인 유럽 자동차는 주행 km당 220g CO2를 배출합니다.

이 두 연구 간의 불일치는 왜 부문별 에너지(예: 모든 네트워킹 장치가 연간 소비하는 에너지)를 추정하는 것이 사용자 활동별 에너지(예: 비디오 시간당 에너지)를 추정하는 것보다 쉬운지를 보여줍니다. 예를 들어 Wi-Fi 라우터의 전력 소비가 10W라는 것을 확실히 알고 있다고 가정해 봅시다. 이 라우터는 하루 종일 실행되어 하루 240Wh를 소비합니다. 사용자가 하루에 3시간 비디오를 시청하는 경우 라우터는 비디오 1시간의 에너지 소비에 얼마나 기여할까요? 0Wh, 10Wh 또는 80Wh? 세 가지 수치 모두 정당화될 수 있습니다. 0Wh는 비디오가 표시되지 않더라도 어쨌든 소비될 기본 부하(baseload)로 Wi-Fi 라우터 에너지를 정의하는 경우 정확합니다. 비디오 시청은 Wi-Fi 라우터의 일일 에너지 소비를 증가시키지 않습니다. 10Wh는 이 기본 부하 소비를 활동이 발생하는 동안 귀속시키는 경우 정확합니다. 80Wh는 Wi-Fi 라우터가 비디오를 표시하기 위해서만 존재한다고 가정하고 전체 일일 에너지 소비를 3시간의 비디오 시청에 귀속시키는 경우 정확합니다.

추가적인 주의 사항으로 모든 범주에서 에너지 소비를 정확하게 추정하는 데 상당한 방법론적 과제가 있습니다[113], [114], [115]. 예를 들어 전체 데이터 센터 에너지 소비 계산은 시간이 지남에 따라 판매된 서버(데이터 센터급 CPU) 수를 기반으로 합니다. 이러한 (상당히 정확한) 볼륨을 에너지 소비로 변환하려면 평균 사용률과 수명을 정확하게 추정해야 합니다. 따라서 우리는 그러한 연구의 정확도가 25%보다 좋지 않다고 추정합니다. 즉, 실제 수치는 1.25배 이상 차이가 날 수 있습니다. 그림 9.22는 2020년 소비에 대한 세 가지 연구가 세 가지 범주 간에 에너지 소비가 어떻게 나뉘는지에 대한 추정치에서 어떻게 상당히 다른지를 보여줍니다[116]. Andrae와 Edler(2015)[117]의 추정치 A는 그들의 최상의 경우(총 623 MtCO2e)를 사용합니다. Belkhir와 Elmeligi(2018)[118]의 추정치 B는 평균 경우인 1,207 MtCO2e(A의 두 배)를 기반으로 합니다. 추정치 C는 Malmodin과 Lunden(2018)[119]에 의한 것으로 총 690 MtCO2e를 기반으로 합니다. 추정치 중 일부는 비교 가능하도록 Freitag 등에 의해 조정되었습니다[116].

전 세계 IT 에너지 소비 추정치가 상당히 크게 다른 또 다른 이유는 "IT" 또는 "ICT"의 정의입니다. 대부분의 연구에는 IT의 핵심 정의, 즉 기업 데이터 센터 및 직원 장치, 네트워킹 장비, 프린터 등을 포함하는 기타 장비가 포함됩니다. 그러나 소비자 측면으로 확장할 때 가정은 매우 다양합니다. 예를 들어 위의 세 연구는 TV를 제외하는데, TV는 IT 장치가 아닌 엔터테인먼트 장치로 취급되기 때문입니다. TV 콘텐츠는 휴대폰에서 볼 수 있고 YouTube 콘텐츠는 TV에서 볼 수 있으며 게임은 모든 장치에서 할 수 있으므로 향후 연구에는 모든 가정용 기기가 포함될 것으로 예상합니다.

가정, 데이터 세트 및 방법론의 이러한 차이에도 불구하고 모든 연구는 일반적으로 총 클라이언트 측 탄소 발자국이 서버 측 발자국보다 적어도 크거나 더 클 가능성이 높다는 데 동의합니다(그림 9.23 [116]).

요약하면 인터넷 에너지 소비는 소비자 기기 및 가정의 기타 전자 제품이 지배하며 데이터 센터가 그 뒤를 잇습니다. 비트코인 채굴은 일반적으로 이러한 계산에 포함되지 않지만 에너지 소비는 데이터 센터의 에너지 소비와 비슷한 수준입니다.

**(그림 9.23: 2020년 전 세계 ICT 탄소 발자국 추정치)**

---

**참고문헌**

1.  The Green Grid, WP#49 - PUE: A Comprehensive Examination of the Metric.
2.  C. Malone and C. Belady, “Metrics to characterize data center IT equipment energy use,” in Proceedings of the Digital Power Forum, 2006.
3.  The Green Grid, Recommendations for Measuring and Reporting Overall Data Center Efficiency, 2010.
4.  Uptime Institute, 2014 Data Center Industry Survey, 2014.
5.  A. Shehabi, S. Smith, D. Sartor, et al., United States data center energy usage report, 2016.
6.  Uptime Institute, 2022 Data Center Industry Survey, 2022.
7.  Google, Efficiency: Google Data Centers.
8.  J. Haas, J. Froedge, J. Pflueger, and D. Azevedo, “Usage and public reporting guidelines for the Green Grid’s infrastructure metrics (PUE/DCiE),” 2009.
9.  C. Belady and C. Malone, “Preliminary assessment from Uptime Institute: IDC data center of the future US server power spend for 2005,” 2014.
10. D. Nelson, M. Ryan, S. DeVito, et al., “The role of modularity in data center design,” 2009.
11. S. Greenberg, E. Mills, B. Tschudi, P. Rumsey, and B. Myatt, “Best practices for data centers: Lessons learned from benchmarking 22 data centers,” 2006.
12. E. Pinheiro, W.-D. Weber, and L. A. Barroso, “Failure trends in a large disk drive population,” FAST ’07, 2007.
13. B. Schroeder, E. Pinheiro, and W.-D. Weber, “DRAM errors in the wild: A large-scale field study,” 2009.
14. N. El-Sayed, I. A. Stefanovici, G. Amvrosiadis, A. A. Hwang, and B. Schroeder, “Temperature management in data centers: Why some (might) like it hot,” SIGMETRICS ’12, 2012.
15. G. Cloud, Google container data center tour, 2009.
16. Google, Efficiency at Scale - Google Data Centers.
17. DeepMind, DeepMind AI reduces Google data centre cooling bill by 40%.
18. X. Li and S. Jiang, Google 48V rack adaptation and onboard power technology update, 2019.
19. Maxim Integrated, 48V Rack Power Architecture for Hyperscale Data Centers.
20. J. Koomey, S. Berard, M. Sanchez, and H. Wong, “Implications of historical trends in the electrical efficiency of computing,” 2011.
21. S. H. Fuller and L. I. Millett, “Computing performance: Game over or next level?” 2011.
22. TOP500.org, The Green500 List.
23. S. Rivoire, M. A. Shah, P. Ranganathan, C. Kozyrakis, and J. Meza, “Models and metrics to enable energyefficiency optimizations,” 2007.
24. Standard Performance Evaluation Corporation, SPECpower_ssj2008 Benchmark, 2008.
25. MLCommons, MLPerf Benchmarks.
26. A. Tschand et al., “MLPerf Power: Benchmarking the energy efficiency of machine learning systems from Microwatts to Megawatts for sustainable AI,” 2024.
27. Standard Performance Evaluation Corporation, SPECpower_ssj2008 Result ID 01464, 2024.
28. H. Liu, “A measurement study of server utilization in public clouds,” 2011.
29. B. Everman et al., “Improving the cost efficiency of large-scale cloud systems running hybrid workloads-a case study of Alibaba cluster traces,” 2021.
30. E. Cortez et al., “Resource Central: understanding and predicting workloads for improved resource management in large cloud platforms,” SOSP ’17, 2017.
31. S. Siddha, V. Pallipadi, and A. Ven, “Getting maximum mileage out of tickless,” 2007.
32. L. A. Barroso and U. Hölzle, “The case for energy-proportional computing,” 2007.
33. X. Fan, W.-D. Weber, and L. A. Barroso, “Power provisioning for a warehouse-sized computer,” ISCA ’07, 2007.
34. H. Zhang and H. Hoffmann, A quantitative evaluation of the RAPL power control system, 2014.
35. D. Meisner, B. T. Gold, and T. F. Wenisch, “PowerNap: Eliminating server idle power,” ASPLOS XIV, 2009.
36. A. Gandhi et al., “Power capping via forced idleness,” 2009.
37. D. Meisner et al., “Power management of online data-intensive services,” ISCA ’11, 2011.
38. Intel, Intel® Xeon® Platinum 8164 Processor.
39. D. Lo et al., “Towards energy proportionality for large-scale latency-critical workloads,” ISCA ’14, 2014.
40. IPU - Intel RAPL interface advisory, 2020.
41. Amazon Web Services, T3 Instances.
42. Google Cloud, Shared-core machine types.
43. Google Cloud, CPU overcommit for sole-tenant VMs.
44. Google Cloud, Cloud Run.
45. J. Mars et al., “Bubble-Up: Increasing utilization in modern warehouse scale computers via sensible co-locations,” MICRO-44, 2011.
46. D. Lo et al., “Heracles: Improving resource efficiency at scale,” ISCA ’15, 2015.
47. C. Delimitrou and C. Kozyrakis, “Quasar: Resource-efficient and QoS-aware cluster management,” ASPLOS ’14, 2014.
48. Google Cloud, Mitigating power and thermal fluctuations in ML infrastructure.
49. Dell, Enterprise Infrastructure Planning Tool (EIPT).
50. Hewlett Packard Enterprise, HPE Power Advisor.
51. LooseBolts, Chiller side chats – the capacity problem, 2009.
52. P. Ranganathan et al., "Ensemble-level power management for dense blade servers," 2006.
53. Google, Google Cluster Data - Power Data 2019, 2019.
54. V. Sakalkar et al., “Data center power oversubscription with a medium voltage power plane and priority-aware capping,” ASPLOS ’20, 2020.
55. T. H. Norris et al., Rethinking load growth: Assessing the potential for integration of large flexible loads in us power systems.
56. S. Govindan et al., “Leveraging stored energy for handling power emergencies in aggressively provisioned data centers,” ASPLOS XVII, 2012.
57. D. Wang et al., “Energy storage in data centers: What, where, and how much?” SIGMETRICS ’12, 2012.
58. V. Kontorinis et al., “Managing distributed UPS energy for effective power capping in data centers,” ISCA ’12, 2012.
59. J. S. Chase et al., “Managing energy and server resources in hosting centers,” SOSP ’01, 2001.
60. G. Chen et al., “Energy-aware server provisioning and load dispatching for connectionintensive internet services,” NSDI’08, 2008.
61. Y. Chen et al., “Managing server energy and operational costs in hosting centers,” SIGMETRICS ’05, 2005.
62. M. E. Femal and V. W. Freeh, “Safe overprovisioning: Using power limits to increase aggregate throughput,” 2004.
63. M. E. Femal and V. W. Freeh, “Boosting data center performance through non-uniform power allocation,” 2005.
64. T. Heath et al., “Mercury and Freon: Temperature emulation and management for server systems,” ASPLOS XII, 2006.
65. J. D. Moore et al., “Making scheduling ”cool”: Temperatureaware workload placement in data centers.,” 2005.
66. M. Pedram, “Energy-efficient data centers,” 2012.
67. H. Kasture et al., “Rubik: Fast analytical power management for latency-critical systems,” MICRO-48, 2015.
68. C.-H. Hsu et al., “Adrenaline: Pinpointing and reining in tail queries with quick voltage boosting,” HPCA, 2015.
69. R. Raghavendra et al., “No “power” struggles: Coordinated multi-level power management for the data center,” ASPLOS XIII, 2008.
70. Q. Wu et al., “Dynamo: Facebook’s data center-wide power management system,” ISCA ’16, 2016.
71. Intel, Intel®Core™Processors.
72. US EPA, Climate Change Indicators: Atmospheric Concentrations of Greenhouse Gases.
73. Google, Google 2024 Environmental Report, 2024.
74. Google Cloud, TPUs improved carbon efficiency of AI workloads by 3x.
75. Infrastructure Masons (iMasons), Greener concrete for digital infrastructure.
76. Google, Google’s first mass timber building takes root in silicon valley.
77. Net Zero data centers, Projects.
78. Google Sustainability, Our third decade of climate action.
79. Google, Google supports climate action at COP27, 2022.
80. B. Smith, Microsoft will be carbon negative by 2030, 2020.
81. Meta, Climate - Meta Sustainability.
82. A. Radovanovic et al., “Carbon-aware computing for data centers,” 2021.
83. U. Hölzle, Our commitment to climate-conscious data center cooling, 2022.
84. D. Azevedo et al., “Water usage effectiveness (WUE): A green grid datacentre sustainability metric,” 2011.
85. Meta, Data Centers - Meta Sustainability.
86. Amazon Press Center, AWS makes water positive commitment to return more water to communities than it uses by 2030, 2022.
87. Google Sustainability, Replenishing 120% of the water we consume by 2030.
88. Meta, Restoring more water than we consume by 2030, 2021.
89. D. Patterson et al., “The carbon footprint of machine learning training will plateau, then shrink,” 2022.
90. A. Shehabi et al., 2024 United States data center energy usage report, 2024.
91. Fortune, Nvidia’s monstrous new Blackwell chip is here to solve AI’s carbon footprint problem-not make it worse, 2024.
92. Stanford HAI, Artificial Intelligence Index Report 2025, 2025.
93. Wikipedia contributors, Jevons paradox.
94. Sequoia Capital, AI’s $600B question.
95. A. Lovins, Artificial Intelligence meets natural stupidity: Managing the risks, 2025.
96. J. Koomey, “Woldwide electricity use in data centers,” 2008.
97. A. S. G. Andrae and T. Edler, “On global electricity usage of communication technology: Trends to 2030,” 2015.
98. I. Schneider et al., Life-cycle emissions of ai hardware: A cradle-to-grave approach and generational trends, 2025.
99. E. Masanet et al., “Recalibrating global data center energy-use estimates,” 2020.
100. N. Lei and E. R. Masanet, “Global data center energy demand and strategies to conserve energy,” 2021.
101. Google Sustainability, Google Environmental Report 2019 - Data Centers, 2019.
102. Microsoft, Designing and Building Sustainable Data Centers.
103. IEA, Data Centres and Data Transmission Networks.
104. J. Malmodin et al., “ICT sector electricity consumption and greenhouse gas emissions-2020 outcome,” 2024.
105. EIA, Electricity demand from data centers could double by 2026, 2024.
106. Cambridge Centre for Alternative Finance, Cambridge Bitcoin Electricity Consumption Index (CBECI).
107. IEA, Analysis and forecast to 2026, 2024.
108. D. Castro et al., “The carbon footprint of artificial intelligence,” 2023.
109. D. Patterson et al., “Energy and emissions of machine learning on smartphones vs. the cloud,” 2024.
110. World Bank, Data Centers and Decarbonization: Unlocking Flexibility in Power Grids, 2023.
111. G. Kamiya, The carbon footprint of streaming video: Fact-checking the headlines, 2020.
112. A. Stephens et al., Carbon impact of video streaming, 2021.
113. J. Koomey and E. Masanet, “Does not compute: Avoiding pitfalls assessing the internet’s energy and carbon impacts,” 2021.
114. C. Bremer et al., Assessing energy and climate effects of digitalization, 2023.
115. C. Freitag et al., “The climate impact of ICT: A review of estimates, trends and regulations,” 2021.
116. C. Freitag et al., “The real climate and transformative impact of ICT: A critique of estimates, trends, and regulations,” 2021.
117. A. S. Andrae and T. Edler, “On global electricity usage of communication technology: Trends to 2030,” 2015.
118. L. Belkhir and A. Elmeligi, “Assessing ict global emissions footprint: Trends to 2040 & recommendations,” 2018.
119. J. Malmodin and D. Lundén, “The energy and carbon footprint of the global ict and e&m sectors 2010–2015,” 2018.