# 소프트웨어 정의 인프라 (Software-Defined Infrastructure)

지난 두 장에서 우리는 WSC(Warehouse-Scale Computer) 하드웨어 구성 요소의 설계를 설명하고, 무어의 법칙 둔화가 어떻게 효율적인 하드웨어 설계에 대한 집중을 이끌어냈는지 자세히 살펴보았습니다. 맞춤형 실리콘 가속기는 와트당 더 나은 성능을 제공하며, 이종(heterogeneous) 서버 플랫폼은 다양한 시스템 균형점과 워크로드 특성에 맞춰 최적화됩니다.

하지만 무어의 법칙 둔화에 대응할 수 있는 또 다른 방법이 있는데, 바로 우리가 보유한 하드웨어를 더 효율적으로 활용하는 것입니다. 특히 WSC의 수직 통합형 설계와 4장에서 논의한 분산 시스템 스택은 효율성 향상을 위해 하드웨어를 관리하고 추상화하는 소프트웨어의 렌즈를 통해 WSC 하드웨어를 바라볼 수 있게 해 줍니다. 우리는 이러한 접근 방식을 **소프트웨어 정의 인프라(software-defined infrastructure)**라고 부릅니다.

소프트웨어 정의 인프라는 지역적인(local) 의사 결정을 최적화하기 위해 전역적인(global) 뷰를 활용할 수 있는 소프트웨어 관리 및 제어 평면(control plane)을 구축함으로써, 하드웨어를 더 유연하게 만들고, 애플리케이션에 더 잘 맞추며, 관리하기 쉽게 만듭니다. 예를 들어, 소프트웨어 정의 네트워크는 개별 스위치가 라우팅 결정을 내리는 부담을 덜어주는데, 이는 전역적으로 결정하는 것이 더 낫기 때문입니다. 소프트웨어 정의 서버는 사용자가 하드웨어를 지정할 필요 없이 올바른 워크로드(즉, 해당 특정 하드웨어에서 가장 잘 수행되는 워크로드)를 라우팅하는 하드웨어 인식 스케줄러의 이점을 누립니다.

이어지는 섹션들에서는 소프트웨어 정의 인프라가 컴퓨팅, 스토리지, 네트워크 및 데이터 센터 인프라의 성능과 효율성을 어떻게 향상시키는지 탐구합니다.

## 7.1 소프트웨어 정의 서버 (Software-defined servers)

지난 장에서 우리는 지난 25년 동안의 WSC용 서버 하드웨어 설계의 진화에 대해 논의했습니다. 동시에, 이러한 하드웨어 설계가 상위 소프트웨어 계층에 제공되는 방식(예: 서버의 추상화) 또한 진화했습니다.

과거에는 무어의 법칙이 이전 세대에 비해 워낙 큰 향상을 제공했기 때문에 최신 기계가 모든 애플리케이션에 있어 최선의 선택이었습니다. 따라서 초기 WSC는 컴퓨팅 관리의 상위 계층에 비교적 동질적인 추상화를 제공하는 단일 "당대 최고의 기계(machine of the day)"를 보유했습니다. 그러나 무어의 법칙이 둔화되면서 애플리케이션의 특성이 하드웨어보다 성능에 더 큰 영향을 미칠 수 있게 되었습니다. 예를 들어, 새 서버가 10~15%만 개선된 경우, 메모리 대역폭 요구량이 높은 애플리케이션은 최신 시스템이 코어를 15% 더 제공하더라도 구형 플랫폼에서 더 효율적으로 실행될 수 있습니다. 따라서 애플리케이션 간의 성능 변동성이 현세대 서버 유형 간의 변동성보다 클 수 있기 때문에, WSC 운영자는 여러 다른 서버 유형을 동시에 구매하여 전체 서버 집합(fleet)의 이질성(heterogeneity)을 증가시킬 수 있습니다.

구형 서버들이 가격/성능 면에서 여전히 경쟁력이 있기 때문에 서버 수명은 연장되고, 이는 여러 세대의 하드웨어가 공존하게 되어 추가적인 이질성으로 이어집니다. 동시에 워크로드 또한 다양화되어 다양한 컴퓨팅 요구, 메모리 접근 패턴, 대기 시간(latency) 요구 사항 및 서비스 수준 목표(SLO)를 갖게 되었습니다. 또한 여러 CPU 아키텍처 외에도 WSC는 GPU나 TPU와 같은 무수히 많은 특수 가속기와 새로운 메모리 계층(비휘발성 메모리 등)을 도입하여 다양성을 더욱 증가시켰습니다. 마지막으로, 6.2.1절에서 논의한 바와 같이 서버는 코어, 메모리, SSD, 도메인별 가속기를 포함한 다양한 하드웨어 리소스로 동적으로 구성되는 분리형(disaggregated) 미니 분산 시스템으로 진화하고 있습니다.

특정(벤더가 정의한) 하드웨어 설계에 맞춰진 전통적이고 정적이며 획일적인(one-size-fits-all) 서버 추상화는 이러한 이질적인 세상에서 비효율적이며, 서로 다른 하드웨어 플랫폼의 특정 강점이나 다양한 애플리케이션의 고유한 요구 사항을 활용하지 못합니다.

**소프트웨어 정의 서버(SDS)**는 동적 최적화와 애플리케이션-하드웨어 간의 더 나은 일치를 위해 하드웨어와 소프트웨어 전반의 공동 설계(co-design)를 강조하는 대안적이고 적응 가능한 추상화를 제공합니다. 결과적으로 우리는 특정 애플리케이션 요구 사항에 최적화된 "SoftSKU"를 위해 시스템 구성(예: 하드웨어 노브)을 동적으로 조정하는 것을 지원할 수 있습니다. 하드웨어 리소스에 대한 더 세분화된 제어(예: 공유 리소스에 대한 QoS, 비균일 메모리 액세스)를 지원할 수 있으며, 정적인 하드웨어 휴리스틱에서 소프트웨어 프로그래밍 가능성(프리패칭과 같은 컴파일러 피드백 기반 최적화)으로 제어를 이동할 수 있습니다. 더 중요한 것은 하드웨어 이질성(다른 CPU 세대, 가속기, 메모리 계층)을 해결하기 위한 더 나은 클러스터 스케줄링 인터페이스를 공식화하여 워크로드를 올바른 하드웨어에 동적으로 매칭할 수 있다는 점입니다.

본질적으로 소프트웨어 정의 서버는 고전적인 하드웨어 확장의 종말에 대응하여 더 큰 시스템 지능과 적응성으로 나아가는 움직임을 나타냅니다. 소프트웨어가 하드웨어 리소스를 더 깊이 이해하고 제어할 수 있게 함으로써, 소프트웨어 정의 서버는 성능, 리소스 활용률, 총 소유 비용(TCO)에서 상당한 개선을 달성할 수 있으며, 근본적인 하드웨어 개선이 더 어려워진 상황에서도 대규모 컴퓨팅 인프라에서 지속적인 효율성 향상을 제공할 수 있습니다.

소프트웨어 정의 서버는 시스템 스택의 여러 수준에서 작동합니다. CPU 또는 마이크로아키텍처 수준에서 소프트웨어 정의 서버는 이전에는 정적이었던 하드웨어 기능의 세분화된 동적 튜닝을 가능하게 합니다. 예를 들어, 하드웨어 프리패처(prefetcher), CPU 코어 주파수 또는 전력 상태는 해당 코어에 할당된 애플리케이션의 런타임 동작 및 요구 사항에 따라 소프트웨어를 통해(종종 모델별 레지스터(MSR)를 통해) 조정될 수 있습니다. 좋은 예는 Google의 최근 Limoncello 연구[1]입니다. 이를 통해 구성은 일반적인 기본값을 넘어 명령어 혼합, 캐시 미스율 또는 메모리 지연 시간 민감도와 같은 특정 워크로드 특성에 맞게 최적화될 수 있으며, 이전에는 활용되지 않았던 상당한 성능 또는 효율성 이득을 잠금 해제할 수 있습니다. 서로 다른 CPU 세대에서 사용할 수 있는 특수 명령어 세트(예: SIMD, AVX)도 최적화를 위해 명시적으로 고려될 수 있습니다.

머신(machine) 수준에서 소프트웨어 정의 서버는 서버 노드 내의 공유 리소스 관리에 집중할 수 있으며, 이는 애플리케이션이 마지막 레벨 캐시(LLC) 및 메모리 대역폭과 같은 리소스를 두고 경쟁하는 멀티 테넌트 환경에서 특히 중요합니다. SDS는 서비스 품질(QoS) 메커니즘을 구현하여 시스템이 애플리케이션 우선순위, 클래스 또는 측정된 요구[2]에 따라 이러한 공유 리소스를 할당할 수 있게 합니다. 이는 간섭을 완화하고 할당 정책을 시행함으로써, 리소스 집약적인 배치(batch) 작업과 함께 배치될 때에도 우선순위가 높은 지연 시간 민감형 작업에 대해 보다 예측 가능한 성능을 보장합니다. 소프트웨어 정의 서버는 또한 전체적인 최적화를 달성하기 위해 서로 다른 리소스 유형 간의(종종 복잡한) 상호 작용(예: 캐시 할당을 제한하면 메모리 트래픽이 증가할 수 있음)을 관리할 수 있습니다.

개별 머신을 넘어 확장하면, 소프트웨어 정의 서버는 클러스터 수준의 리소스 관리 및 스케줄링을 처리할 수 있습니다. 서로 다른 하드웨어 플랫폼(예: 다른 CPU 세대 또는 아키텍처)이 고유한 성능 특성(예: 코어 수 대 주파수, 코어당 메모리 대역폭, NUMA 페널티)을 가지고 있음을 인식하여, 클러스터 스케줄러는 성능 데이터와 워크로드 특성을 사용하여 작업을 가장 효과적으로 실행되는 하드웨어 플랫폼으로 지능적으로 조정(steer)함으로써 플랫폼별로 워크로드를 스케줄링할 수 있습니다[3]. 이 매칭 프로세스는 전체 클러스터 처리량과 효율성을 극대화합니다.

상위 수준에서 소프트웨어 정의 서버는 2장에서 소개한 WSC 소프트웨어 스택을 확장하는 강력한 추상화 및 효율성 계층에 의존합니다(그림 7.1). 추상화 계층은 하드웨어 기능을 쿼리하고 구성을 적용하기 위한 일관된 인터페이스를 제공하여, 플랫폼별 구현 세부 정보를 상위 수준 소프트웨어로부터 숨깁니다. 하드웨어 측면에서는 특정 CPU 및 머신 수준 구성을 소프트웨어에 잘 정의된 추상화로 제시합니다. 소프트웨어 측면에서는 성능을 투명하게 최적화하면서 최종 사용자 애플리케이션에 대한 WSC 추상화를 유지합니다. 그 아래의 효율성 계층은 성능 데이터를 수집하는 모니터링 인프라, 워크로드-하드웨어 상호 작용을 이해하는 모델링 기능, 최적의 구성 및 스케줄링 힌트를 생성하는 정책 엔진(머신 러닝을 사용할 수 있음)을 통합합니다. 이러한 계층들이 함께 자동화된 데이터 기반 최적화를 가능하게 하여 WSC가 애플리케이션 요구를 충족하도록 하드웨어 동작을 동적으로 수정할 수 있게 합니다.

우리는 다양한 최적화를 포괄하기 위해 소프트웨어 정의 서버라는 용어를 사용합니다. 아래에서는 몇 가지 구체적인 예를 논의합니다. 먼저 워크로드별 동작을 사전에 고려하는(프로파일 기반 최적화 사용) 컴파일러 기반 소프트웨어 최적화 예제로 시작합니다. 그런 다음 TCMalloc이 TLB 미스와 메모리 풋프린트를 최적화하는 예를 중심으로 소프트웨어 라이브러리를 하드웨어 인식형으로 최적화한 방법을 논의합니다. 플랫폼 인식 스케줄링은 이기종 플랫폼 전반에서 워크로드를 최적화하며, 소프트웨어 관리형 계층화 메모리는 총 메모리 비용을 줄입니다.

**그림 7.1 소프트웨어 정의 서버: 추상화 및 효율성 계층**
*(그림 설명: App 1, App 2... App N 아래 WSC software가 있고, 그 아래 WSC efficiency layer가 있습니다. 효율성 계층은 Monitoring infrastructure, Performance modeling infrastructure, Policy generators를 포함하며 ML을 사용하여 효율성을 개선합니다. 그 아래 Software-defined servers abstraction layer가 있고, 이는 Cluster software, Node software and OS kernel과 상호작용하며 하드웨어를 추상화합니다.)*

### 7.1.1 사례 연구: 컴파일러 최적화

WSC의 수직 통합형 시스템 스택(앞서 4장에서 논의함)은 더 많은 하드웨어-소프트웨어 공동 설계를 가능하게 합니다. 특히 대부분의 WSC 제공업체가 자체 컴파일러를 구축한다는 점을 감안할 때, 하드웨어 인식 컴파일러 최적화를 위한 많은 옵션이 있습니다. 컴파일러는 특정 서버 아키텍처에 맞게 최적화된 코드를 생성합니다. 창고 규모 컴퓨팅(WSC) 워크로드의 다양성에도 불구하고 하드웨어와 소프트웨어의 공동 최적화 가능성을 열어주는 많은 공통 사용 패턴이 존재합니다. 아래에서 그중 하나의 예를 논의합니다.

Google에서는 프로덕션 바이너리에서 발견되는 방대한 양의 CPU 사이클에 대한 명령어 및 기본 블록(basic block)에 대한 상세 정보가 담긴 데이터베이스를 활용하여 많은 최적화를 안내합니다[4]. 이 데이터베이스는 X 유형의 명령어가 얼마나 자주 실행되는지, Y 유형 명령어의 몇 퍼센트가 Z 속성을 갖는지, 또는 가장 흔한 N-gram이 무엇인지와 같은 질문에 답하는 데 사용됩니다. 이를 통해 우리는 고전적인 마이크로아키텍처 최적화 기회를 식별할 수 있었습니다.

예를 들어, WSC 워크로드의 명령어 풋프린트(footprint)는 일반적인 L1 명령어 캐시 크기보다 100배 이상 큰 경향이 있으며 연간 20% 이상의 속도로 증가하고 있습니다. 결과적으로 이러한 워크로드는 일반적으로 SPEC CPU 벤치마크를 사용하여 평가되는 데스크톱급 애플리케이션에서 발견되는 최악의 시나리오보다 훨씬 높은 명령어 캐시 미스율을 겪습니다.

프로세서는 유용한 명령어를 스스로 공급받는 능력에 치명적으로 의존하기 때문에, 저조한 명령어 캐시(i-cache) 성능은 프론트엔드 정체(stall)로 인한 심각한 성능 손실로 이어질 수 있습니다. Intel Haswell CPU에서 실행되는 웹 검색 워크로드의 사이클 수준 분석 결과, 총 성능 잠재력의 14%가 주로 명령어 캐시 미스로 인한 "프론트엔드 대기 시간(Front-end latency)" 때문에 손실되는 것으로 나타났습니다[4]. 이 워크로드는 약 4 MiB의 핫(hot) 상태 명령어 작업 집합(working set)을 가지고 있는데, 이는 현재 서버 CPU에서 발견되는 L1 및 L2 명령어 캐시보다 훨씬 크지만, 공유 L3 캐시(보통 수십 MiB 크기)에는 넉넉히 들어갈 수 있는 크기입니다. 이에 영감을 받아 우리는 애플리케이션 성능을 크게 향상시키기 위해 애플리케이션 바이너리의 중요 실행 경로에 코드 프리패치(prefetch) 명령어를 자동으로 삽입할 수 있는 컴파일러 최적화를 조사하게 되었습니다.

피드백 기반 최적화(FDO)는 런타임 동작 정보를 사용하여 최적화를 안내하며, 일반적으로 10%에서 15%의 개선 효과를 가져옵니다. 그러나 데이터 센터 애플리케이션의 특성상 많은 사용자가 워크로드를 적절하게 나타내는 벤치마크를 유지 관리하는 것은 매우 힘든 일입니다.

AutoFDO[5]는 프로덕션 서버에서 수집한 하드웨어 성능 데이터를 활용하여 피드백 기반 최적화를 자동화합니다(그림 7.2). 이 프로세스는 가볍고 프로덕션 시스템에 미치는 영향을 최소화하기 위해 오프로드됩니다. 여기에는 성능 샘플의 정기적인 수집, 심볼화(symbolized), 포맷팅 및 버전 관리 저장소 저장이 포함됩니다.

프로필이 준비되면 컴파일러는 이를 중간 표현(IR)에 매핑할 수 있습니다. 이 과정은 바이너리 수준 프로필을 소스 수준 프로필로 변환한 다음, 이를 IR에 매핑할 수 있는 표준 컴파일러 형식으로 변환하는 것을 포함합니다. 다음으로 컴파일러는 엣지(edge) 및 노드 빈도 정보가 포함된 제어 흐름 그래프(control flow graph)를 생성할 수 있으며, 여기에는 컴파일러가 선택적 인라인(inlining)을 수행하는 데 사용할 수 있는 문맥 감도(context-sensitivity) 정보가 포함됩니다.

**그림 7.2 AutoFDO 엔드투엔드 시스템 다이어그램**
*(그림 설명: Release binary archive -> Ingestor -> Binary index & symbols -> Sample database <- Collector <- Machine (Perf_events daemon). Sample database & Source depot -> Compiler. Compiler -> Release binary archive.)*

AutoFDO 경험은 몇 가지 핵심 교훈을 강조했습니다. 컴파일러 변환이 오류를 일으키지 않도록 하려면 철저한 테스트가 필수적입니다. AutoFDO가 벤치마크에서 기존의 피드백 기반 최적화(FDO)보다 항상 성능이 뛰어난 것은 아니지만, 실제 성능은 부정확한 프로필을 사용하더라도 종종 비슷합니다. 또한 바이너리 내의 워크로드 다양성을 고려하여 다양한 사용 사례에 맞게 최적화할 수 있도록 여러 프로필을 허용하는 것이 중요합니다. 마지막으로 팀들이 바이너리에 AutoFDO를 매우 쉽게 채택할 수 있어야 혜택이 전체 서버 집합(fleet)에 도달할 수 있습니다.

### 7.1.2 사례 연구: 라이브러리 최적화

많은 소프트웨어 스택은 메모리 관리, RPC, 암호화 등과 같은 기본 구성 요소를 공유합니다. 때때로 "데이터 센터 세금(data center tax)"[6]이라고 불리는 이러한 구성 요소는 WSC 환경에서 처리 사이클의 최대 30%를 소비할 수 있어(8.1.2절), 핵심 라이브러리에 대한 하드웨어 인식 최적화의 강력한 근거를 제시합니다.

그러한 예 중 하나는 메모리 할당자에서 거대 페이지(hugepage) 적용 범위[7]를 최적화하는 것입니다. 캐시 및 TLB(Translation Lookaside Buffer) 미스는 WSC의 주요 성능 병목 현상입니다. WSC 사이클의 약 20%가 TLB 미스로 인해 정체됩니다. 거대 페이지는 수 메가바이트에서 수 기가바이트에 이르는 훨씬 더 큰 메모리 블록을 커버하는 TLB 항목입니다. 따라서 거대 페이지는 TLB 미스를 크게 줄일 수 있습니다. 그러나 페이지가 클수록 해당 페이지 내의 내부 단편화(internal fragmentation)로 인해 물리적 메모리가 사용되지 않을 위험이 높아집니다. 거대 페이지 적용 범위를 최적화함으로써 할당자는 TLB 미스를 줄이고 운영 체제와 협력하여 내부 단편화를 줄이도록 새 할당 배치를 제어할 수 있습니다.

TCMalloc[8], [9]은 대규모 분산 애플리케이션에서 자주 사용되는 메모리 할당자입니다. 그림 7.3은 TCMalloc의 메모리 구성을 보여줍니다. 객체는 크기별로 분리됩니다. 먼저 TCMalloc은 메모리를 페이지 크기에 정렬된 스팬(span)으로 분할합니다. 충분히 큰 할당은 할당된 객체만 포함하는 스팬으로 충족됩니다. 다른 스팬은 동일한 크기의 여러 작은 객체(크기 클래스)를 포함합니다. "소형(small)" 객체 크기 경계는 256 KiB입니다.

**그림 7.3 TCMalloc의 구성 요소로의 크기별 요청 흐름**
*(그림 설명: Unbacked hugepages -> HugeAllocator. Backed hugepages -> HugeCache. HugeCache -> HugeFiller & HugeRegion. Small requests (<1MB) -> HugeFiller. Medium requests (1 MB - 1 GiB) -> HugeRegion. Large requests (>=1 GiB) -> HugeAllocator.)*

이 "소형" 임계값 내에서 할당 요청은 100개의 크기 클래스 중 하나로 올림(round up)됩니다. TCMalloc은 일련의 캐시에 객체를 저장합니다.

목표는 거대 페이지의 활용을 극대화하는 것입니다. 휴리스틱을 통해 할당자는 자주 사용되는 거대 페이지에 객체를 빽빽하게 채우는 동시에, 운영 체제에 반환하기 위해 완전히 사용되지 않는 거대 페이지를 생성할 수 있습니다. HugeAllocator라고 하는 주요 구성 요소는 HugeCache라고 하는 완전히 비어 있는 거대 페이지 캐시를 통해 가상 메모리 및 운영 체제를 다룹니다. 또한 HugeFiller라고 하는 부분적으로 채워진 단일 거대 페이지 목록은 후속 소형 할당에 의해 조밀하게 채워집니다.

거대 페이지를 인식하는 메모리 할당자를 사용하면 WSC 애플리케이션에서 7.7%의 성능 향상과 2.4%의 RAM 사용량 감소를 가져왔습니다. 또한 이 할당자는 TLB 미스로 인한 정체를 6% 줄이고 단편화로 인한 메모리 낭비를 26% 줄입니다.

### 7.1.3 사례 연구: 플랫폼 인식 스케줄링

플랫폼 인식 스케줄링(Platform-aware scheduling)은 성능과 활용도를 높이기 위해 워크로드를 가장 잘 수행하는 특정 플랫폼에 스케줄링하는 또 다른 고전적인 소프트웨어 정의 서버 최적화입니다.

워크로드 성능은 기본 마이크로 아키텍처에 대한 민감도가 다르기 때문에 플랫폼마다 크게 다를 수 있습니다. 예를 들어 비디오 트랜스코딩과 같은 메모리 집약적인 워크로드는 코어당 메모리 대역폭이 높은 플랫폼에서 잘 작동합니다. 반면 웹 검색과 같이 멀티스레드화된 워크로드는 동시 멀티스레딩(SMT) 또는 많은 코어 수를 가진 플랫폼을 선호합니다. 단일 스레드 컴퓨팅 집약적 워크로드는 클럭 속도가 높은 플랫폼에서 가장 잘 수행됩니다.

그림 7.4는 측정 당시 전체 서버 집합(fleet)에서 가장 일반적인 5개 플랫폼에 걸친 특정 바이너리의 성능을 보여줍니다. 바이너리의 성능은 시간이 지남에 따라 일관되었으며 플랫폼 A에 대한 명확한 선호도를 보여주었고, 플랫폼 D는 이 바이너리를 실행하기에 최악의 선택이 될 것입니다. 이 그래프에서 100%는 각 플랫폼의 성능 등급에서 순수하게 예상되는 성능을 나타냅니다. 따라서 이 특정 애플리케이션은 상위 두 플랫폼에서는 예상보다 약 3% 느리게 실행되지만 플랫폼 D에서는 예상보다 10% 더 느리게 실행됩니다.

플랫폼 인식 스케줄링은 최적의 성능을 제공할 수 있는 플랫폼으로 워크로드를 유도합니다. 데이터 처리 파이프라인은 프로덕션 환경에서 실행 중인 워크로드의 프로필을 캡처합니다. 순위 알고리즘은 계층적 병합 클러스터링(hierarchical agglomerative clustering)과 같은 데이터 마이닝 기술을 사용하여 프로필을 분석하고 각 워크로드에 대한 선호 플랫폼 순위 목록을 생성합니다. 이러한 워크로드별 플랫폼 선호도는 클러스터 관리자에 업로드됩니다. 거기서 클러스터 관리자는 이용 가능한 가장 적합한 하드웨어 플랫폼에 워크로드를 스케줄링합니다.

모든 중요 워크로드에 대해 플랫폼 인식 스케줄링을 활성화하면 평균 성능이 7~10% 향상되었습니다. 흥미롭게도 이러한 접근 방식의 이점은 일반 컴퓨팅을 넘어 가속기 및 GPU 기반 플랫폼으로까지 확장되어 효율성과 활용도를 향상시킵니다. 실제로 가속기 및 GPU에 대해 이 접근 방식을 구현함으로써 일부 플랫폼의 활용도가 두 배로 증가했으며, 최종 사용자는 기본 하드웨어 차이의 복잡성으로부터 보호받아 원활한 경험을 유지할 수 있었습니다.

**그림 7.4 서로 다른 플랫폼에서의 애플리케이션 상대 성능**

### 7.1.4 사례 연구: 소프트웨어 정의 메모리

우리가 논의할 소프트웨어 정의 서버의 마지막 예는 메모리 관리에 관한 것입니다.

데이터 센터에서 하드웨어 플랫폼과 워크로드의 다양성이 증가함에 따라 모든 리소스가 완전히 활용되는 균형 잡힌 시스템을 유지하기가 어렵습니다. 컴퓨팅 용량 대비 메모리 대역폭 비율은 시간이 지남에 따라 감소해 왔으며, 머신 러닝(ML)과 같은 메모리 집약적 워크로드의 증가로 인해 악화되었습니다. 이러한 추세는 전체 데이터 센터 집합 전반에 걸쳐 불균형을 초래합니다. Google에서는 세 가지 접근 방식을 따라 소프트웨어 정의 메모리 최적화를 배포했습니다[10]:

*   **메모리 요구 사항 파라미터화**: 각 애플리케이션에 대한 특정 대역폭, 용량 및 대기 시간 요구 사항을 식별하여 메모리 리소스의 보다 효율적이고 목표 지향적인 할당을 보장합니다.
*   **다양한 메모리 기술 배포**: 각 애플리케이션의 고유한 요구 사항에 맞는 다양한 메모리 기술을 활용합니다. 예를 들어 고대역폭 애플리케이션은 HBM 또는 3D 적층 캐시의 이점을 누릴 수 있는 반면, 고용량 애플리케이션은 더 크지만 느린 DRAM 모듈을 사용할 수 있습니다. 하드웨어를 넘어 압축을 통해 메모리의 다양성을 생성할 수도 있습니다. 압축 메모리는 본질적으로 더 저렴하지만 대기 시간이 더 긴 메모리 계층의 추상화를 제공합니다.
*   **계층화된 메모리(tiered-memory) 아키텍처 개발**: 올바른 데이터를 올바른 메모리 기술로 유도하고, 애플리케이션 요구에 따른 할당을 자동화하여 계층화된 메모리 관리를 단순화합니다.

계층화된 메모리 소프트웨어는 세 개의 계층으로 구성됩니다. 그림 7.5는 처음 두 계층을 보여줍니다. 최하위 계층은 하드웨어를 추상화하고 여러 메모리 장치에 걸친 세분화된 물리적 주소 공간을 제공합니다. 중간 계층은 커널에 의해 수행되는 후보 감지 및 페이지 마이그레이션 메커니즘에서 페이지 관리 정책을 분리합니다. 우리의 과거 경험에 따르면 커널 메커니즘을 성공적으로 사용하려면 프로덕션 규모에서만 나타나는 미묘한 동작을 해결하고 특정 워크로드 측면에 최적화하기 위해 여러 번의 설계 반복이 필요합니다. 사용자 공간 정책 계층은 이러한 유연성과 민첩성을 허용합니다.

상위 계층(그림에는 표시되지 않음)은 클러스터 수준에서 작동합니다. Borg 스케줄러는 모든 머신에서 실행되는 Borglet 작업인 노드 에이전트와 협력하여 여러 머신에 걸친 작업 요청 대기열을 지속적으로 관리합니다. 각 머신의 부하 및 성능 지표를 모니터링하고 개별 서버에 작업을 디스패치합니다.

계층 간에 페이지를 마이그레이션하기 위해 액세스 패턴을 측정하여 거의 액세스되지 않는 "콜드(cold)" 페이지와 자주 액세스되는 "핫(hot)" 페이지를 식별합니다. 커널 데몬은 주기적으로 페이지 액세스 비트를 스캔하여 페이지 유휴 기간(idle age)을 결정합니다. 콜드 페이지를 하위 계층으로 강등(demote)시키는 것은 주로 기존 가상 메모리 패턴을 따릅니다. 핫 사용량은 시기적절한 감지를 위해 정밀한 하드웨어 샘플링을 사용하여 결정됩니다(그림 7.6).

**그림 7.5 계층화된 메모리 아키텍처**
*(그림 설명: 상단 Application과 ufard(hot page promotion, policies)가 User space에 위치. 커널 영역에는 page migration, cold page demotion, page access scan, precise PMU sampling perf. 하드웨어 영역에는 Tier 1 (NUMA nodes + DRAM)과 Tier 2 (NUMA nodes + Low-cost memory)가 있음.)*

우리의 고수준 지역성(locality) 모델은 프로덕션 트래픽을 처리할 때 작업(job)에서 수집된 전체 집합(fleet-wide) 프로파일링 데이터로부터 구축됩니다. 통계적 캐시 모델은 작업의 메모리 대역폭 소비를 측정하면서 다양한 캐시 양에 따른 작업 성능을 예측합니다. 주요 구성 요소는 미스율 곡선(MRC)으로, 작업이 다양한 캐시 크기에서 달성할 미스율을 매핑한 것입니다. 그림 7.6은 통계적 캐시 모델을 사용하여 생성된 두 개의 샘플 MRC를 보여줍니다. 작업 A와 작업 B는 캐시 크기에 따라 다양한 민감도를 보이는 별개의 워크로드입니다. 작업 B는 작업 집합이 더 작고 코어당 2 MiB를 넘어가면 MPKI(천 개 명령어당 미스) 감소가 제한적인 반면, 작업 A는 코어당 7 MiB까지 상당히 개선됩니다.

미스율 곡선을 다가오는 메모리 기술의 하드웨어 특성과 결합하여 클러스터 수준에서 시스템 균형을 개선하는 방법을 예측할 수 있습니다. 각 워크로드에 대한 마지막 레벨 캐시 MPKI 감소와 이에 상응하는 메모리 대역폭 수요 감소를 추정하는 것으로 시작합니다. 그런 다음 얼마나 많은 작업이 새로운 기술의 혜택을 받을 수 있는지 결정하고, 이전 섹션에서 논의한 플랫폼 인식 스케줄링을 활용하여 이러한 작업을 가장 적합한 하드웨어에 스케줄링합니다. 요약하면, 소프트웨어 정의 메모리는 메모리 기술의 조합을 사용하여 특정 사용 사례를 향상시키고 클러스터 수준에서 전체 시스템 균형을 향상시킬 수 있게 합니다.

**그림 7.6 첫 번째 메모리 계층에서의 시뮬레이션된 미스율 vs 실제 미스율**

## 7.2 소프트웨어 정의 가속기 (Software-defined accelerators)

소프트웨어 정의 인프라의 개념은 넓은 수준에서 가속기에도 적용될 수 있습니다. 한 예로 H2O-NAS(초대규모 하드웨어 최적화 신경망 아키텍처 검색)를 논의합니다[11].

6.3장에서 우리는 ML 모델이 어떻게 끊임없이 증가하는 계산 능력을 요구하는지 논의했습니다. 규모에 맞게 ML 하드웨어의 잠재력을 완전히 활용하기 위해 모델 효율성은 새로운 하드웨어 인프라를 구축하는 것만큼 중요해졌습니다. 신경망 아키텍처 검색(NAS)은 최고의 인간 설계 모델에 필적하는 ML 모델 아키텍처를 자동으로 설계하는 데 있어 상당한 가능성을 보여주었습니다. NAS 접근 방식에는 검색 전략(예: one-shot vs. multi-trial), 검색 알고리즘(예: 강화 학습, 그래디언트 기반 알고리즘, 진화 알고리즘), 검색 공간(하드웨어 전문화 및 가중치 공유), 검색 목표(보상 함수, 품질 및 성능 신호)의 네 가지 주요 차원이 있습니다.

H2O-NAS는 이러한 전통적인 NAS 접근 방식을 취하여 하드웨어를 인식하도록 확장합니다. 이는 전통적인 강화 학습 기반 검색 알고리즘을 가중치 공유에 최적화된 하드웨어 최적화 검색 공간으로 보강합니다. 예를 들어, (고정된 학습 예산이 주어졌을 때) 최고 품질의 모델이 TPU 팟(pod)에 맞기에는 약간 너무 클 수 있으며, 크기와 아키텍처를 조정하면 품질 손실을 최소화하면서 실제로 두 배 빠르게 학습되는 수정된 모델을 생성할 수 있습니다.

초대규모 하드웨어 및 데이터의 규모에 더 잘 최적화하기 위해 H2O-NAS는 대규모 병렬 단일 단계 강화 학습(RL) 검색 알고리즘을 사용하여 실시간 프로덕션 트래픽을 사용하여 모델 아키텍처를 검색하고 모델 가중치를 동시에 훈련합니다. 자세한 내용은 Li 등의 논문[11]에 나와 있지만, Google에 배포된 이 접근 방식은 비슷한 수준 또는 더 나은 모델 정확도와 품질을 유지하면서 규모에 따른 상당한 성능 및 에너지 효율성 향상을 입증했습니다.

## 7.3 소프트웨어 정의 네트워크 (Software-defined networks)

WAN이든 LAN이든 많은 요소를 가진 네트워크는 자동으로 관리(프로그래밍)되어야 합니다. 프로그래밍 가능한 네트워크에 대한 필요성은 OpenFlow[12], P4[13], 그리고 네트워크 제어 평면을 개별 스위치에서 논리적으로 중앙 집중화된 컨트롤러로 이동시키는 소프트웨어 정의 네트워킹(SDN)에 대한 많은 관심을 이끌어냈습니다[14], [15], [16].

SDN은 데이터, 제어 및 관리 평면을 분리하며, 후자의 두 가지는 소프트웨어로 구현됩니다. 소프트웨어 정의 네트워크는 범용 하드웨어 구성 요소를 활용하면서 제어 및 관리 요구 사항을 소프트웨어에서 처리합니다. SDN은 데이터 평면을 프로그래밍하기 위해 표준화된 프로토콜을 사용하여 소프트웨어를 통해 상용 실리콘(merchant silicon)으로 구축된 포워딩 장치에 대한 제어를 중앙 집중화합니다. 이러한 분리를 통해 네트워크를 개별 장치가 아닌 통합된 개체로 관리할 수 있습니다. 또한 독립적인 확장이 가능합니다. 예를 들어 제어 알고리즘을 수정하지 않고도 하드웨어를 업그레이드할 수 있습니다. 이러한 분리는 또한 제어 및 관리 평면이 기본 하드웨어를 최적화하기 위해 새로운 알고리즘을 더 잘 통합할 수 있게 했습니다. 소프트웨어 정의 네트워킹은 클러스터 내부 및 광역 네트워크 모두를 지원하며 세계에서 가장 큰 WSC 네트워크 중 일부를 구동합니다.

논리적으로 중앙 집중화된 서버에서 네트워크를 제어하면 많은 이점이 있습니다[17]. 특히 도달 가능성(reachability) 계산, 최단 경로, 최대 흐름(max-flow) 트래픽 배치와 같은 일반적인 네트워킹 알고리즘은 중앙에서 해결하기가 훨씬 더 간단해집니다. 각 개별 라우터가 동일한 문제를 해결해야 하는 네트워크에서는 제한된 가시성(직접 이웃만 보임), 일관성 없는 네트워크 상태(현재 네트워크 상태와 동기화되지 않은 라우터), 그리고 많은 독립적이고 동시적인 행위자(라우터)를 다루면서 일관된 상태에 도달하기가 더 어렵습니다. 네트워크 관리 작업 또한 단순해지는데, 전역 뷰를 사용하여 수천 개의 개별 스위치로 구성된 네트워크 도메인을 하나의 일관된 상태에서 다른 상태로 이동시키는 동시에, 진행 중인 상위 수준 관리 작업의 롤백이 필요할 수 있는 오류를 동시에 설명할 수 있기 때문입니다. P4[13]는 패킷 포워딩 데이터 평면의 프로그래밍을 허용하는 프로토콜 및 스위치 독립적인 고수준 언어를 제공하여 유연성을 더욱 높입니다.

게다가 서버는 스위치나 라우터에 내장된 CPU보다 프로그래밍하기 쉽고 더 강력한 하드웨어를 제공합니다. 제어 평면을 몇 대의 서버로 중앙 집중화하면 소프트웨어 업데이트도 더 쉬워집니다. SDN은 데이터 센터 네트워킹에 자연스럽게 부합하는데, WSC에서 실행되는 애플리케이션은 이미 중앙 엔티티인 클러스터 관리자에 의해 관리되고 있기 때문입니다. 따라서 중앙 SDN 컨트롤러를 사용하여 애플리케이션이 의존하는 모든 네트워크 요소를 구성하는 것은 자연스러운 일입니다. SDN은 논리적으로 중앙 집중화된 제어가 많은 라우팅 및 트래픽 엔지니어링 문제를 단순화하는 WAN 네트워크를 관리하는 데에도 똑같이 매력적입니다[14], [15].

SDN의 이론적 장점과 스탠포드의 초기 학술 연구에 영감을 받아 최초의 실제 SDN 구현은 Google에서 개발되었습니다. 최초의 프로덕션 SDN 네트워크인 B4[14], [15]는 Google 네트워크의 증가하는 비디오 트래픽 및 기타 대량 트래픽을 처리하고, 더 비싼 전체 기능(full-feature) B2 백본 대신 더 저렴한 B4 백본을 통해 이동할 수 있게 했습니다. 비디오 트래픽은 높은 규모와 낮은 가용성 요구 사항을 결합했기 때문에 SDN과 같은 초기 기술에 이상적인 사용 사례였습니다. 당시 YouTube의 전체 가용성은 99.99%보다 상당히 낮았으므로 (캐시되지 않은) 트래픽을 낮은 신뢰성으로 전송하는 것은 허용될 수 있었습니다. B4는 SDN 스택을 실행하는 서버에서 모든 주요 관리 및 제어 평면 기능을 수행하고 OpenFlow를 통해 네트워크의 이더넷 스위치를 프로그래밍했습니다.

동시에 SDN은 데이터 센터 네트워크도 인수했습니다[18]. 처음에는 중앙 집중식 컨트롤러가 작업의 일부만 처리했습니다. 2008년 시대의 Saturn 네트워크에서 중앙 집중식 컨트롤러는 구성을 수행하고 스위치가 전역 상태를 이해하도록 도왔지만, 스위치 기반 소프트웨어가 스위치의 실제 포워딩 테이블을 프로그래밍했습니다. 2012년 시대의 Jupiter 네트워크는 5단계 Clos 네트워크 토폴로지를 구현하고 OpenFlow를 사용하는 Onix SDN 컨트롤러[19]를 사용하여 패브릭 스위치에 라우팅 및 구성 정보를 푸시했습니다. 현재 Jupiter 세대는 OpenFlow를 P4[20]로 대체하여 추가 기능을 제공합니다.

P4[13]는 SDN이 포워딩 테이블 프로그래밍 이상의 것을 필요로 한다는 것을 인식하고 OpenFlow에서 진화했습니다. 시간이 지남에 따라 이더넷 스위치 칩은 순수 패킷 스위칭(즉, 들어오는 패킷을 나가는 포트로 전달)에서 정교한 패킷 처리로 발전했습니다. 예를 들어, 들어오는 패킷은 필터링(방화벽 기능), NAT(Network Address Translation)를 위해 재작성, 또는 GRE 터널로 캡슐화될 수 있습니다. P4를 사용하면 SDN 컨트롤러가 이러한 패킷 처리를 고수준의 하드웨어 독립적 언어로 지정할 수 있습니다. P4 컴파일러는 그 사양을 칩별 구현으로 변환하여 SDN 컨트롤러로부터 공급업체별 세부 정보를 숨깁니다.

SDN은 광학 계층과 라우팅 계층 모두에서 상용 네트워킹 장비로 구성된 네트워크에도 자리 잡았습니다. OpenConfig[21]는 공급업체에 구애받지 않는 표준 API를 통해 이러한 장비를 프로그래밍하고 관리할 수 있게 해 줍니다. SAI(Switch Abstraction Interface)[22]는 스위칭 ASIC, NPU 또는 소프트웨어 스위치와 같은 포워딩 요소를 제어하는 공급업체 독립적인 방법을 제공합니다. SONiC 스택[23]에는 클라우드 데이터 센터에서 완전히 기능하는 L3 장치에 필요한 네트워킹 소프트웨어 구성 요소가 포함되어 있습니다. 결과적으로 WSC 관리 및 제어 평면은 표준화되지 않았지만 표준화된 구성 요소 및 API를 활용할 수 있습니다.

다음 다섯 개의 섹션은 개별 패브릭에서 글로벌 WAN에 이르기까지 SDN 전략이 실제로 어떻게 실행되는지 보여줍니다.

### 7.3.1 Jupiter 토폴로지 및 트래픽 엔지니어링

데이터 센터 네트워크는 처리량과 효율성을 최적화하기 위해 토폴로지 및 트래픽 엔지니어링[20]을 사용합니다. 토폴로지 엔지니어링은 멀티 테넌트 및 건물 규모 패브릭이 관리 가능한 불확실성을 가진 예측 가능한 트래픽 패턴을 보인다는 사실을 활용합니다. 따라서 Clos 토폴로지에서 최악의 경우의 트래픽을 비차단(non-blocking) 전달하기 위해 프로비저닝할 필요가 없으므로, 동일한 용량을 제공하면서도 더 저렴한 솔루션을 허용합니다. 토폴로지 엔지니어링은 스파인(spine) 블록을 제거하고 트래픽 및 토폴로지 공동 엔지니어링을 통해 최적화된 직접 연결(direct-connect) 패브릭을 생성합니다. 이 접근 방식은 트래픽 불확실성을 수용하면서 더 짧고 효율적인 경로를 생성합니다. 또한 스파인 블록과 관련된 비용 및 전력 소비를 줄이고, 중간 스파인 블록을 새로 고칠 필요 없이 최신 블록 간의 고속 직접 링크를 허용하여 토폴로지를 장기 수요에 효과적으로 맞춥니다.

트래픽 엔지니어링(TE)은 실시간 수요에 따라 다양한 경로에 걸쳐 트래픽 전달을 동적으로 최적화하여 스트라이핑(striping), 실패 또는 관리 작업으로 인한 불균형을 보상합니다. 이상적으로는 트래픽이 블록 간에 직접 흐르겠지만, 실제로는 수요가 변하고 토폴로지와 완벽하게 일치하지 않습니다. 6장에서 논의된 Jupiter 네트워크에서 TE는 직접 경로와 1홉 간접 경로를 결합하여 성능과 견고성의 균형을 맞춥니다. 각 서버의 흐름 측정값은 블록 수준 트래픽 매트릭스로 집계되며, 각 항목은 블록 간에 전송된 바이트를 나타냅니다. 이 매트릭스는 지난 한 시간 동안 각 쌍에 대한 최대 전송 속도로 구성된 WCMP(Weighted Cost Multipathing) 최적화에 사용되는 예측 트래픽 매트릭스에 입력됩니다. 이 예측 매트릭스는 관찰된 트래픽에 큰 변화가 발생하거나 신선도를 위해 주기적으로 업데이트됩니다.

트래픽 엔지니어링과 토폴로지 엔지니어링은 서로 다른 시간 규모에서 작동합니다. 트래픽 엔지니어링은 토폴로지 및 트래픽 변화에 빠르게 적응하는 반면, 토폴로지 엔지니어링은 새로운 네트워크 구조를 구현하기 위한 느리고 계획된 프로세스입니다. 병렬 링크 전반의 잠재적인 부하 분산 문제를 해결하기 위해 호스트 기반 다중 경로 네트워크 부하 분산(Multipathed Network Load Balancing)은 RTT 수준의 혼잡을 기반으로 트래픽을 적응적으로 분산시킵니다.

### 7.3.2 네트워크 인식 스케줄링

네트워크 인식 스케줄링은 컴퓨팅 및 스토리지 작업을 배치하기 위한 사전 및 사후 메커니즘을 제공하여, Borg와 같은 중앙 집중식 스케줄러에 네트워크 트래픽 패턴 및 지속적인 핫스팟에 대한 통찰력을 제공합니다[24]. 종종 워크로드 변동이나 네트워크 장애로 인해 발생하는 이러한 핫스팟은 성능에 영향을 미칠 수 있습니다. 네트워크 인식 스케줄링은 컴퓨팅 및 스토리지 사용률뿐만 아니라 네트워크 대역폭도 고려하여 클러스터 내에서 작업을 사전에 빈 패킹(bin-packing)합니다. 또한 네트워크 인식 스케줄링 내의 사후 메커니즘은 네트워크 중단이나 트래픽 패턴 변경 시 요구량이 많은 작업을 지연 시간에 민감한 워크로드로부터 멀리 재배치할 수 있습니다. 이는 최적의 리소스 활용을 보장하고 네트워크 혼잡의 영향을 최소화합니다. 사전 및 사후 계획을 통해 네트워크 인식 스케줄링은 링크 활용을 극대화하기 위해 개별 흐름 관리에 중점을 둔 흐름별 혼잡 제어 메커니즘을 보완합니다. 이들은 함께 모든 사용자에게 가용하고 예측 가능한 네트워크 경험을 유지하기 위한 견고한 시스템을 형성합니다.

### 7.3.3 대역폭 집행자 (Bandwidth enforcer)

Google의 대역폭 집행자(BwE)[25]는 WAN 전체에서 실시간으로 대역폭 할당 및 집행을 최적화합니다. BwE는 분산 컴퓨팅 및 대규모 데이터 전송을 지원하는 데 중요합니다. 이는 경쟁 애플리케이션 간에 WAN 용량을 분배하고, 높은 전체 네트워크 활용도를 유지하면서 비즈니스 요구에 따라 우선순위를 지정하며, 대역폭 및 실패 조건에 대한 전역 뷰를 고려합니다. BwE는 네트워크 토폴로지 및 링크 활용도에 대한 전역 지식을 전역 집행자에서 각 호스트의 속도 집행자에 이르는 대역폭 집행자 계층 구조에 대한 입력으로 사용합니다. 트래픽이 네트워크에 들어오기 전 소스 호스트에서 트래픽 전송 속도를 능동적으로 제어합니다. 호스트와 스위치 모두의 원격 측정 데이터를 활용하여 트래픽 패턴을 이해하고 잠재적인 병목 현상을 식별하여 최적의 네트워크 성능을 보장합니다.

호스트 기반 흐름별 혼잡 제어 메커니즘은 왕복 시간(RTT) 기준으로 혼잡에 빠르게 반응하여 BwE를 보완합니다[26]. 빠른 혼잡 감지는 RTT 규모에서도 혼잡 발생 시 네트워크 손실 및 지연을 낮게 유지하는 반면, BwE는 더 넓은 시간 규모에서 애플리케이션 간의 격리를 보장하여 서로 간섭하는 것을 방지하고 예측 가능한 사용자 경험을 유지합니다.

### 7.3.4 B4 트래픽 엔지니어링

중앙 집중식 트래픽 엔지니어링 서비스인 B4 트래픽 엔지니어링(TE)[15]은 데이터 센터 간 WAN 전체의 네트워크 흐름 경로와 터널을 최적화합니다. 이 접근 방식은 기존의 분산 라우팅 방법에 비해 우수한 리소스 활용도를 제공합니다. 트래픽 엔지니어링은 변화하는 네트워크 조건에 대응하여 지속적으로 경로를 다시 계산하고 오버레이 역할을 하며, 기존 라우팅은 장애 발생 시 대체 수단으로 사용됩니다. 중앙 집중식 TE 서버는 실시간 네트워크 토폴로지, 링크 상태 업데이트 및 흐름 수요를 수신한 다음, 애플리케이션 우선순위/수요에 따라 용량 균형을 맞추기 위해 애플리케이션 흐름을 여러 경로로 분할하면서 100%에 가까운 활용도를 달성하기 위해 전역적으로 최적화된 경로 할당을 계산합니다. 가용성을 더욱 향상시키기 위해 호스트 기반 메커니즘(Protective ReRoute[27])은 엔드 호스트에서 흐름을 적응적으로 다시 라우팅합니다. 네트워크 장애로 인해 흐름이 블랙홀에 빠지면 경로 재라우팅은 몇 번의 왕복 시간 내에 대체 작동 경로로 빠르게 전환합니다. 이러한 빠른 경로 재설정은 짧은 시간 규모(다중 RTT)에서도 장애 발생 시 사용자 트래픽에 대한 네트워크 가용성을 유지하는 반면, TE는 더 긴 시간 규모에서 고품질 경로를 제공합니다.

Espresso[28]는 SDN을 Google의 글로벌 피어링 에지로 확장하며, 기존 인터넷 프로토콜로 인한 피어링 링크의 활용도 저하를 해결하기 위해 개발되었습니다. Espresso는 IP 주소를 기반으로 사용자를 매핑하는 정적 할당 대신 실시간 네트워크 성능을 기반으로 서비스 엔드포인트를 동적으로 선택합니다. 또한 Espresso는 트래픽 관리 로직을 중앙 집중화하여 개별 라우터에서 분산 시스템으로 이동시킵니다. 이 시스템은 WSC의 컴퓨팅 인프라를 애플리케이션 신호와 함께 활용하여 집계된 네트워크 데이터를 분석하고 최종 사용자의 경험을 기반으로 개별 흐름을 최적화합니다. 전반적으로 Espresso는 라우터 중심 프로토콜보다 성능이 뛰어나며 더 높은 가용성과 성능을 제공합니다.

### 7.3.5 DDoS 공격 완화

분산 서비스 거부(DDoS) 공격은 네트워크 계층(사이트의 인터넷 링크 용량을 소진시킴) 또는 애플리케이션 계층(애플리케이션의 프론트 또는 백엔드 용량을 과부하 시키도록 설계된 요청으로)에서 합성 네트워크 트래픽으로 서비스를 압도하여 서비스를 비활성화하려고 시도합니다.

Cloud Armor[29]는 전 세계적으로 DDoS 공격을 모니터링하고 탐지합니다. 이를 통해 네트워크 운영자는 필요할 때 네트워크 액세스 제어 목록(ACL)을 수동으로 푸시하여 특정 트래픽 패턴을 차단할 수 있으며, 들어오는 공격을 막기 위해 자동으로 ACL을 생성할 수 있습니다.

일부 "공격"은 일시적인 병목 현상을 일으키는 실제 트래픽 급증일 뿐입니다. 가상화된 네트워크의 핵심 목표는 일관된 가용성과 성능을 제공하여 한 가상 머신(VM)이 다른 가상 머신의 네트워크 경험에 부정적인 영향을 미치지 않도록 하는 것입니다. 그러나 한 VM이 혼잡을 유발하여 다른 VM의 성능에 영향을 미치는 "시끄러운 이웃(noisy neighbors)"은 비슷한 과제를 제기합니다. 호스트의 LAN 링크는 초과 가입(oversubscribed)되지 않을 수 있지만 업스트림 링크(건물 내부, 구역 간 또는 지역 외부)는 초과 가입될 수 있으므로, 갑자기 많은 트래픽을 보내거나 받는 사용자가 다른 사용자에게 영향을 미칠 수 있으며 억제되어야 합니다.

중앙 집중식 시스템은 격리를 복원하기 위해 지연된 응답 시간과 제한된 정보를 갖는 경우가 많은 반면, 순수 호스트 기반 시스템은 상태 분배로 인한 과도한 통신 오버헤드로 이어질 수 있습니다. 이러한 문제를 해결하기 위해 하이브리드 솔루션은 호스트 수준의 빠르고 반응적인 수신기 주도형 DoS 탐지 기능과 중앙 집중식 DoS 서버를 결합합니다. 서버는 호스트로부터 혼잡 신호를 수신하고 추가 원격 측정 데이터를 활용하여 집행 속도를 정확하게 계산하고 배포함으로써 대규모 네트워크 중단 클래스에 대한 빠른 완화를 보장합니다.

### 7.3.6 SDN의 다음 단계

SDN이 마련한 기반은 신흥 AI/ML 워크로드가 제기하는 고유한 과제를 해결하는 데 도움이 됩니다. 느슨하게 결합된 분산 애플리케이션과 달리 ML 학습 작업은 건강한 컴퓨팅 및 네트워킹 슈퍼컴퓨터 리소스를 동시에 요구합니다. 이러한 작업은 또한 전례 없는 양의 가속기와 네트워킹을 필요로 하여 평균 실패 간격(MTBF)이 훨씬 짧아집니다. 공유 클러스터에서 슈퍼컴퓨터 리소스에 대한 경쟁은 리소스의 동적 재구성 및 재조정을 필요로 합니다. TPU v4[30]부터 SDN은 광학 회로 스위칭을 사용하여 장애 발생 시 트래픽을 동적으로 다시 라우팅하고 작업 가용성을 높이는 등 고대역폭 칩 간 상호 연결(ICI)을 관리하는 데 중요한 역할을 했습니다. 앞으로 AI/ML 워크로드의 끊임없이 증가하는 요구를 지원하기 위해 가용성이 높고 확장 가능한 컴퓨팅-네트워킹 기판을 제공하려면 SDN의 지속적인 진화가 필수적입니다[31].

또한 최근 연구[32]에서는 SDN을 구현하는 표준 중앙 집중식 방법에 대한 그럴듯한 대안을 찾았습니다. 이 분산형 SDN(dSDN)에서는 모든 라우터가 운영자가 정의한 dSDN 컨트롤러를 실행합니다. 각 dSDN 컨트롤러는 간단한 플러딩 기반 전파 프로토콜을 통해 전역 네트워크 뷰를 구성한 다음 로컬에서 트래픽 엔지니어링 알고리즘을 실행하여 용량 인식 경로를 계산합니다. 간단한 합의 없는(consensus-free) 경로 선택을 위해 dSDN은 소스 라우팅(해당 라우터에서 시작되는 경로에 대해 라우터가 유일한 의사 결정자임)을 사용합니다.

dSDN 아키텍처는 데이터 평면 외부의 구성 요소 및 레거시 프로토콜에 대한 의존성을 제거합니다. 이러한 단순화에도 불구하고 dSDN은 복원력을 제공하는 전통적인 프로토콜의 운명 공유(fate-sharing)를 복원하면서 전통적인 중앙 집중식 SDN의 이점을 유지합니다. 라우터가 다운되면 제어 평면의 손상은 중앙 집중식 SDN과 달리 데이터 평면의 손상과 일치합니다. dSDN은 라우터 CPU(TE 실행을 위해)에 더 높은 계산 부하를 부과하고 추가 패킷 헤더 상태(소스 경로 전달을 위해)를 부과하지만, 둘 다 최신 라우터에서 쉽게 수용됩니다.

## 7.4 소프트웨어 정의 스토리지 (Software-defined storage)

Google은 다양한 데이터 센터 및 저장 장치 전반에 걸쳐 대체 가능성(fungibility)을 제공하는 소프트웨어 정의 스토리지를 통해 스토리지 효율성을 최적화합니다. 기존 스토리지 시스템은 종종 특정 워크로드 유형에 맞게 특별히 배포됩니다. 예를 들어 스토리지 시스템은 데이터베이스 워크로드를 고급 SSD 장치에 배치하여 성능을 우선시할 수 있는 반면, 아카이브 클라우드 서비스는 IOPS를 사용하지 않고 가장 큰 용량의 HDD 드라이브를 선택할 수 있습니다. 3장에서 논의된 광범위한 WSC 서비스 및 워크로드를 감안할 때 배포된 데이터 센터 설치 공간의 효율성을 극대화하려면 스토리지 리소스가 가능한 한 대체 가능해야 합니다.

Google에서는 통합된 글로벌 계층화 스토리지 시스템을 사용합니다. 이 시스템은 다양한 워크로드와 형태를 수용하도록 설계되었습니다. 최대 효율성과 상호 교환성을 달성하기 위해 블록, 데이터베이스, 객체, 키-값 및 파일과 같은 다양한 스토리지 서비스 유형이 모두 단일 모듈식 분산 스토리지 시스템(Colossus) 위에 구축됩니다. 이 아키텍처는 스토리지 리소스의 원활한 통합 및 최적화를 허용하여 효율적이고 전 세계적으로 확장 가능한 스토리지 솔루션을 제공합니다.

### 7.4.1 스토리지 워크로드 다양성

글로벌 규모의 스토리지 시스템은 장치 활용도를 최적화하면서 다양한 범위의 워크로드 유형을 수용해야 합니다. 스토리지 장치는 고정된 양의 저장 공간(바이트)과 해당 저장 공간에 대한 고정된 양의 액세스를 결합하여 초당 I/O 작업 수와 총 데이터 전송 대역폭을 모두 제한합니다.

각 워크로드에는 바이트 대 IOPS의 다른 비율이 필요합니다. 워크로드에 디스크 크기를 맞추는 간단한 방법은 콜드 워크로드에는 대형 HDD를 배포하고 핫 워크로드에는 소형 HDD(또는 SSD)를 배포하는 것입니다. 그럼에도 불구하고 워크로드가 사용 가능한 장치와 완벽하게 일치할 가능성은 낮으며 장치의 기능 중 적어도 하나는 활용도가 낮습니다. 또한 애플리케이션은 시간이 지남에 따라 변경되므로 오늘 가장 적합한 장치가 1년 후에도 여전히 올바른 선택일 가능성은 낮습니다.

예를 들어 아카이브 스토리지 전용으로 스토리지를 배포하는 경우 이 "콜드" 워크로드에 대해 바이트당 최저 비용을 얻기 위해 가능한 가장 큰 HDD를 선택할 것입니다. 이 시나리오에서는 바이트 효율성을 극대화하지만 아마도 IOPS의 상당 부분을 사용하지 않은 상태로 남겨둘 것입니다. 반대로 데이터베이스 전용으로 스토리지를 배포하는 경우 바이트당 비용이 훨씬 더 높은 SSD를 선택할 수 있습니다.

소프트웨어 정의 스토리지를 사용하면 이러한 워크로드를 공유 장치에 결합하고 전체 IOPS/TB 비율에 대해 전체 집합(fleet) 구성의 크기를 적절하게 조정할 수 있습니다. 개별 애플리케이션보다 대규모 풀의 용량을 최적화하는 것이 훨씬 쉽습니다. 예를 들어 낮은 IOPS 아카이브 워크로드를 위한 스토리지는 대륙 전체 또는 전 세계에 분산되어 IOPS 한계에 가깝지만 바이트가 비어 있는 장치를 채울 수 있습니다.

그림 7.7은 디스크 스토리지를 사용하는 Google 워크로드의 광범위한 I/O 요구 사항을 보여줍니다. 저장된 각 바이트에 대해 100% 활용도(즉, 최대 탐색 속도)로 실행되는 동안 들어갈 수 있는 이론적 HDD 크기를 계산합니다. 예를 들어 가장 콜드한 워크로드는 2024년 현재 사용 가능한 실제 가장 큰 디스크보다 10배 더 큰 300 TB를 초과하는 디스크를 사용할 수 있습니다. 따라서 개인 스토리지 집합에서 제공되는 경우 해당 워크로드는 사용 가능한 가장 큰 디스크조차도 사용 가능한 I/O 속도의 10% 미만으로 실행합니다. 반대로 가장 핫한 바이트는 훨씬 더 작은 디스크가 필요합니다. 그러나 Google의 고유한 워크로드는 디스크에 편안하게 맞습니다. 80번째 백분위수에서도 데이터는 오늘날 상업적으로 이용 가능한 것보다 더 큰 드라이브에 맞습니다.

**그림 7.7 이론적 디스크 크기 (바이트 대 IOPS)**

이러한 측면에서 Google의 스토리지 요구 사항은 사람들의 거의 액세스하지 않는 오래된 사진 및 비디오 저장에서 비롯되는 대규모 준 아카이브(semi-archival) 스토리지 수요가 없는 일반 기업의 요구 사항과 다릅니다. (그래프의 오른쪽 끝에서 디스크는 더 이상 필요한 IOPS를 유지할 수 없으며 데이터는 SSD에 저장되어야 하지만 그래프의 해당 부분은 생략했습니다.)

계획을 돕고 실제 비용을 정확하게 반영하기 위해 내부 청구 시스템은 IOPS 비용과 바이트 비용을 별도로 청구합니다[33]. 이 비용 모델을 통해 개발자가 경제적 균형을 달성하기 위해 바이트와 IOPS 간의 균형을 올바르게 맞추도록 장려할 수 있습니다.

다양한 워크로드 간의 I/O 공유를 지원하기 위해 스토리지 API는 워크로드 클래스 분리를 가능하게 합니다. 지연 시간에 민감한 워크로드는 별도의 스토리지 서비스 범주를 통해 지연 허용(latency-tolerant) 워크로드와 격리됩니다. 이 접근 방식은 Gmail 및 YouTube와 같은 서비스 지향 워크로드에 대해 제한된 지연 시간을 보장하는 동시에 데이터 분석 및 데이터 이동과 같은 지연 허용 작업을 수용합니다. 결과적으로 배치(batch) 분석 작업은 디스크에 "백그라운드에서" 액세스할 수 있는 반면 스토리지 시스템은 지연 시간 최적화 IOPS 비용을 지불하는 서비스를 우선시합니다.

### 7.4.2 투명한 SSD 캐싱

배포된 HDD 크기가 커짐에 따라 IOPS에 대한 수요가 배포된 바이트에서 HDD가 제공하는 IOPS를 넘어섰습니다. 현재 HDD 크기를 사용하여 집단적 IOPS 수요를 충족하려면 훨씬 더 많은 HDD가 필요하여 좌초된(stranded) 바이트가 발생합니다. 배포된 HDD와 IOPS 활용도 간의 최적의 균형을 달성하기 위해 SSD에 구현된 글로벌 공유 스토리지 캐시를 활용합니다. 통합 스토리지 API 뒤에 있는 캐시를 활용하면 기존 워크로드를 수정하지 않고도 시스템의 균형을 원활하게 맞출 수 있습니다. 이 스토리지 캐시를 통해 배포된 모든 HDD 바이트와 IOPS 용량을 효과적으로 활용할 수 있습니다.

### 7.4.3 컴퓨팅과 스토리지 간의 데이터 센터 공간 교환

데이터 센터는 컴퓨팅 및 스토리지에 대한 다양한 수요에 직면하여 그 비율에 영향을 미칩니다. 또한 워크로드는 IOPS 대 바이트 요구 사항이 다릅니다. 리소스 할당을 최적화하기 위해 위치 독립적 스토리지를 활용할 수 있습니다. 디스크 기반 스토리지의 상당 부분은 "콜드"하므로 특정 지역이나 대륙, 심지어 전 세계 어디에나 배치할 수 있습니다. 콜드 스토리지는 저장된 Tbyte당 대역폭이 거의 필요하지 않으므로 배치는 네트워크 대역폭에 의해 제한되지 않고 데이터 지역성에 대한 관할권 요구 사항에 의해서만 제한됩니다.

대체 가능한 스토리지를 통해 데이터 센터 전반의 수요와 용량 균형을 맞출 수 있습니다. 예를 들어 데이터 센터에 컴퓨팅이 차지하지 않는 여유 공간과 전력이 있는 경우 시간이 지남에 따라 해당 공간을 채우기 위해 유연한 양의 콜드 스토리지 용량을 할당할 수 있습니다. 또한 IOPS와 바이트 간에 불균형이 있는 경우 위치 독립적 스토리지의 콜드 부분을 해당 데이터 센터로 재배치하여 그렇지 않으면 좌초될 가용 바이트를 활용할 수 있습니다.

### 7.4.4 기타 소프트웨어 관리형 하드웨어 최적화

위에서 몇 가지 주목할만한 예를 논의했지만 스토리지를 위한 소프트웨어 관리형 하드웨어 최적화의 설계 공간은 상당히 큽니다. 예를 들어 SmartFTL(Flash Translation Layer) 최적화는 애플리케이션 제공 쓰기 힌트를 사용하여 미디어 배치를 관리하여 쓰기 증폭을 줄입니다[34]. 마찬가지로 하이브리드 SMR HDD 드라이브는 CMR 및 SMR(기존 및 싱글 자기 기록) 전반에 걸쳐 데이터가 관리되는 방식에 대한 소프트웨어 제어를 통합합니다[35].

## 7.5 소프트웨어 정의 데이터 센터 (Software-defined data center)

### 7.5.1 소프트웨어 정의 전력

전력 초과 가입(oversubscription)은 전원 공급 장치가 명목상 지원할 수 있는 것보다 더 많은 서버를 데이터 센터에 배포하여 데이터 센터 효율성을 높이고 비용을 절감합니다. 초과 가입된 데이터 센터의 모든 서버가 동시에 피크에 도달하면 차단기가 트립되거나 냉각 과부하, 발전기 과부하 또는 이들 모두가 발생합니다. 따라서 초과 가입된 데이터 센터는 임계 전력 소모가 데이터 센터의 물리적 한계에 접근하는 경우 부하의 일부를 떨어뜨리기 위한 전력 캡핑(power capping) 메커니즘이 필요합니다. (9.5절에서 초과 가입에 대해 더 자세히 논의할 것입니다.)

다행히 데이터 센터는 우선순위가 높은 서빙(serving) 작업과 우선순위가 낮은 배치(batch) 워크로드를 모두 실행합니다. 전력 캡핑 시스템은 후자를 조절하지만 전자를 조절하지 않으려고 노력하므로 일반적으로 우선순위가 높은 서빙 작업에 필요한 전력을 초과 가입하지 않습니다. 합리적인 워크로드 다양성(모든 부하가 동시에 피크에 도달하지 않음)과 상당한 배치 부하가 결합되면 초과 가입으로 가용 용량을 수십 퍼센트 늘릴 수 있습니다.

소프트웨어 정의 전력은 하드웨어 불가지론적 전력 캡핑 시스템[36]을 사용하여 워크로드에 대한 중단을 최소화하면서 안전한 전력 초과 가입을 허용합니다. 이 시스템은 전력 안전과 성능 최적화의 균형을 맞추는 두 개의 임계값, 무작위 조절 해제/승법 감소(randomized unthrottling/multiplicative decrease) 제어 정책을 구현합니다. 또한 이 시스템은 Linux 커널의 CPU 대역폭 제어 기능을 활용하여 작업 수준 서비스 품질(QoS) 인식 스로틀링을 활성화합니다. 이를 통해 시스템은 지연 시간에 민감한 작업에 대해 낮은 지연 시간을 유지하면서 전력 자원을 효율적으로 할당할 수 있습니다.

그림 7.8에 묘사된 소프트웨어 아키텍처에는 시스템의 주요 모듈이 포함되어 있습니다. 미터 감시자(meter watcher) 모듈은 초당 1회 속도로 미터에서 전력 판독 값을 폴링하는 역할을 합니다. 그런 다음 이러한 판독 값은 전력 알림자(power notifier) 모듈로 전달되고 나중에 참조할 수 있도록 전력 이력 데이터 저장소에 저장됩니다.

전력 알림자 모듈은 반응형 및 사전형 캡핑 로직을 모두 구현하는 중앙 제어 모듈 역할을 합니다. 전력 판독 값을 사용할 수 있는 경우 모듈은 반응형 캡핑 로직에 사용합니다. 판독 값을 사용할 수 없는 경우 사전형 캡핑 로직을 위해 위험 평가자(risk assessor) 모듈을 쿼리합니다. 위험 평가자는 전력 이력 데이터 저장소의 과거 전력 정보를 활용하여 차단기 트립 위험을 평가합니다. 따라서 시스템은 일부 전력 원격 측정 데이터를 사용할 수 없는 상황에서도 강력한 성능을 유지할 수 있습니다.

어느 로직이든 캡핑이 필요하다고 판단하면 전력 알림자 모듈은 적절한 캡핑 매개변수를 머신 관리자(machine manager) 모듈로 전달합니다. 그런 다음 머신 관리자는 원격 프로시저 호출(RPC) 요청을 개별 머신의 노드 컨트롤러로 보내 전력 소비를 동시에 줄입니다. 전력 토폴로지 데이터 저장소는 전력 전달 토폴로지에 대한 중요한 정보가 들어 있는 저장소입니다. 여기에는 보호된 전력 제한 및 특정 전력 도메인 내의 특정 머신과 같은 세부 정보가 포함됩니다. 이러한

**그림 7.8 전력 캡핑 아키텍처**
*(그림 설명: Power history data와 Meters가 Power readings를 Meter watcher에 보냄. Meter watcher는 Power readings를 Power notifier에 보냄. Power history data는 Risk assessor에 정보를 제공하고 Risk assessor는 Risk assessment를 Power notifier에 보냄. Power topology data는 Power notifier에 정보를 제공함. Power notifier는 Throttling decision을 Machine manager에 보냄. Machine manager는 Throttling RPCs를 Node controllers에 보냄.)*

**그림 7.9 시간에 따른 전력 스로틀링 응답**

전력 도메인은 규모가 다양할 수 있으며 일부는 몇 메가와트 정도로 작고 다른 일부는 수십 메가와트만큼 클 수 있습니다.

두 개의 캡핑 임계값(높음 및 낮음)은 전력 안전을 위한 응답성과 성능 영향을 최소화하기 위한 효율성 간의 균형을 맞춥니다. 부하가 높은 임계값을 초과하면 하드 스로틀링(hard throttling)이 시작되어 "희생(victim)" 작업의 CPU 할당을 거의 0으로 설정하여 효과적으로 중지합니다(그림 7.9). 실제 전력이 나중에 높은 임계값 아래로 떨어지면 소프트 스로틀링(soft throttling)이 이어받아 사용량을 높은 임계값 아래로 유지하려고 시도하면서 CPU 할당을 점진적으로 늘립니다. 이 소프트 스로틀링 영역은 간헐적인 하드 스로틀링으로 인해 발생할 수 있는 부하 진동을 방지합니다. 낮은 임계값 미만에서는 스로틀링이 없습니다. 낮은 임계값은 높은 임계값이 이전에 도달했을 때만 활성화되므로 전력이 잠시 낮은 임계값을 넘었지만 높은 임계값에 도달하지 않으면 스로틀링이 발생하지 않습니다. 부하가 일정 시간 동안 낮은 임계값 미만으로 유지되면 낮은 임계값 타이머가 만료되고 소프트 스로틀링이 비활성화됩니다.

소프트웨어 정의 전력에 대한 이러한 접근 방식은 여러 프로덕션 클러스터에서 대규모로 성공적으로 구현되어 9%에서 25% 사이의 전력 초과 가입 이득을 가져왔습니다.

### 7.5.2 소프트웨어 정의 플릿 (Software-defined fleet)

소프트웨어 정의 인프라는 용량 관리 자동화의 편리함을 제공합니다. 예를 들어 Autocap은 장기 계획, 다가오는 성장 요구 및 중복성 목표($N + 1$ 또는 $N + 2$)를 고려하여 프로덕션 서비스의 용량 관리를 자동화하는 포괄적인 내부 도구입니다. Autocap을 사용하면 클러스터 선택 및 작업 배치가 자동화됩니다.

반면 또 다른 내부 도구인 Autopilot[37]은 현재 CPU 사용률을 사용하여 실시간으로 작업을 확장하여 단기 조정을 수행합니다. 작업의 동시 태스크 수(수평적 확장)와 개별 태스크의 CPU/메모리 제한(수직적 확장)을 모두 조정할 수 있습니다.

두 서비스 모두 미세 조정된 휴리스틱과 결합하여 작업의 이전 실행에 대한 과거 데이터를 분석하는 머신 러닝 알고리즘에 의존합니다. 이러한 기능은 응답성과 효율성 간의 균형을 유지하여 프로덕션 서비스에 대한 최적의 용량 관리를 제공하는 데 도움이 됩니다.

## 7.6 자율 주행 시스템 (Self-driving systems)

머신 러닝은 컴퓨팅 수요를 주도하고 있으며 시스템은 ML 워크로드를 위해 재설계되고 있습니다. 그러나 머신 러닝은 시스템을 더 잘 설계하는 데에도 사용될 수 있으며, 구체적으로 소프트웨어 정의 인프라의 맥락에서 성능, 효율성 및 탄력성을 향상시킬 수 있습니다. 아래에서 몇 가지 대표적인 예를 논의합니다.

머신 러닝은 코드 패턴을 분석하고 잠재적인 가속 목표를 자동으로 정확히 찾아내며 최적의 하드웨어/소프트웨어 공동 설계 전략을 제안함으로써 대규모 코드베이스에 적합한 가속기 식별을 자동화할 수 있습니다. 이는 개발을 가속화하고 혁신적인 인터페이스와 생태계를 조성합니다.

마찬가지로 ML 기반 생성적 설계(generative design)를 사용하여 칩 및 PCB 레이아웃을 자동화하고, 이질성을 수용하면서 성능, 전력 효율성 및 신뢰성을 최적화할 수 있습니다[38], [39]. 이러한 자동화는 전통적인 경직되고 시간이 많이 소요되는 설계 프로세스의 한계를 극복하여 다양한 애플리케이션 전반에 걸친 빠른 혁신과 맞춤화를 가능하게 합니다. 미래에는 오늘날 100명이 1년 걸려 완성하는 칩 설계를 12명이 3개월 만에 더 나은 설계로 최적화하여 설계할 수 있을 것으로 생각됩니다.

ML은 노드 수준의 대부분의 제어 시스템에서도 사용될 수 있습니다. 예를 들어 ML 모델은 시스템 전체의 원격 측정 데이터를 분석하여 다양한 매개변수를 동적으로 조정하고 실시간 워크로드 특성을 기반으로 리소스 할당을 최적화할 수 있습니다. 이는 다양한 벤더, 플랫폼, 작업, 클러스터 및 애플리케이션 전반에 걸쳐 서비스 품질(QoS), 효율성 및 리소스 활용도 향상으로 이어질 수 있습니다.

ML은 대규모 분산 시스템에서도 사용될 수 있습니다. 예를 들어 ML 기반 접근 방식은 네트워크, 스토리지 및 클러스터와 같은 분리형 시스템 내의 복잡한 상호 작용을 모델링할 수 있습니다. 전력/냉각 분배를 최적화하고, 클러스터 전반에 걸쳐 작업을 지능적으로 스케줄링하고, 꼬리 지연 시간(tail latency)을 최소화함으로써 ML은 이러한 복잡한 환경에서 효율적인 확장, 내결함성 및 전반적인 성능 향상을 가능하게 할 수 있습니다.

이러한 예는 ML의 가능성을 보여주지만 우리는 여전히 시스템에 머신 러닝을 사용하는 초기 단계에 있습니다. ML은 미래의 WSC가 직면한 다양한 과제를 해결하는 데 없어서는 안 될 도구임이 입증되고 있으며, 앞으로 WSC 설계에서 훨씬 더 큰 부분을 차지하게 될 것입니다.

## 참고 문헌

1.  A. Jain, H. Lin, C. Villavieja, et al., “Limoncello: Prefetchers for scale,” in *Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 3*, ser. ASPLOS ’24, vol. 3, New York, NY, USA: Association for Computing Machinery, Apr. 27, 2024, pp. 577-590.
2.  D. Lo, L. Cheng, R. Govindaraju, P. Ranganathan, and C. Kozyrakis, “Heracles: Improving resource efficiency at scale,” in *2015 ACM/IEEE 42nd Annual International Symposium on Computer Architecture (ISCA)*, 2015, pp. 450-462.
3.  S. Dev, D. Lo, L. Cheng, and P. Ranganathan, “Autonomous warehouse-scale computers,” in *Proceedings of the 57th ACM/EDAC/IEEE Design Automation Conference*, ser. DAC ’20, IEEE Press, Nov. 18, 2020, pp. 1-6.
4.  G. Ayers, N. P. Nagendra, D. I. August, et al., ”AsmDB: Understanding and mitigating front-end stalls in warehouse-scale computers,” in *Proceedings of the 46th International Symposium on Computer Architecture*, ser. ISCA ’19, New York, NY, USA: Association for Computing Machinery, Jun. 22, 2019, pp. 462-473.
5.  D. Chen, D. X. Li, and T. Moseley, ”AutoFDO: Automatic feedback-directed optimization for warehousescale applications,” in *Proceedings of the 2016 International Symposium on Code Generation and Optimization*, ser. CGO ’16, New York, NY, USA: Association for Computing Machinery, Feb. 29, 2016, pp. 12-23.
6.  S. Kanev, J. P. Darago, K. Hazelwood, et al., ”Profiling a warehouse-scale computer,” in *Proceedings of the 42nd Annual International Symposium on Computer Architecture*, ser. ISCA ’15, New York, NY, USA: Association for Computing Machinery, Jun. 13, 2015, pp. 158-169.
7.  The Linux Kernel Archives, HugeTLB Pages, Kernel Documentation: https://www.kernel.org/doc/html/v4.18/admin-guide/mm/hugetlbpage.html.
8.  A. H. Hunter, C. Kennelly, P. Turner, et al., ”Beyond malloc efficiency to fleet efficiency: A hugepage-aware memory allocator,” in *15th USENIX Symposium on Operating Systems Design and Implementation (OSDI 21)*, 2021, pp. 257-273.
9.  Z. Zhou, V. Gogte, N. Vaish, et al., ”Characterizing a memory allocator at warehouse scale,” in *Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 3*, ser. ASPLOS ’24, vol. 3, New York, NY, USA: Association for Computing Machinery, Apr. 27, 2024, pp. 192-206.
10. A. Lagar-Cavilla, J. Ahn, S. Souhlal, et al., ”Software-defined far memory in warehouse-scale computers,” in *Proceedings of the 24th International Conference on Architectural Support for Programming Languages and Operating Systems*, ser. ASPLOS ’19, New York, NY, USA: Association for Computing Machinery, Apr. 4, 2019, pp. 317-330.
11. S. Li, G. Andersen, T. Chen, et al., ”Hyperscale hardware optimized neural architecture search,” in *Proceedings of the 28th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 3*, ser. ASPLOS 2023, New York, NY, USA: Association for Computing Machinery, Mar. 25, 2023, pp. 343-358.
12. Open Networking Foundation, *OpenFlow Standard (Archived)*, https://www.openflow.org/.
13. P4.org, P4 Language Consortium, https://p4.org/.
14. U. Hölzle, B4 and Google’s network, Presentation: https://www.segment-routing.net/images/hoelzle-tue-openflow.pdf.
15. S. Jain, A. Kumar, S. Mandal, et al., ”B4: Experience with a globally-deployed software defined WAN,” in *Proceedings of the ACM SIGCOMM 2013 Conference on SIGCOMM*, ser. SIGCOMM ’13, New York, NY, USA: Association for Computing Machinery, Aug. 27, 2013, pp. 3-14.
16. A. Singh, J. Ong, A. Agarwal, et al., ”Jupiter rising: A decade of Clos topologies and centralized control in Google’s datacenter network,” in *Proceedings of the 2015 ACM Conference on Special Interest Group on Data Communication*, ser. SIGCOMM ’15, New York, NY, USA: Association for Computing Machinery, Aug. 17, 2015, pp. 183-197.
17. M. Casado, M. J. Freedman, J. Pettit, et al., ”Ethane: Taking control of the enterprise,” in *Proceedings of the 2007 Conference on Applications, Technologies, Architectures, and Protocols for Computer Communications*, ser. SIGCOMM ’07, New York, NY, USA: Association for Computing Machinery, Aug. 27, 2007, pp. 1-12.
18. A. Singh, J. Ong, A. Agarwal, et al., ”Jupiter rising: A decade of Clos topologies and centralized control in Google’s datacenter network,” 9, vol. 59, New York, NY, USA: Association for Computing Machinery, Aug. 24, 2016, pp. 88-97.
19. T. Koponen, M. Casado, N. Gude, et al., ”Onix: A distributed control platform for large-scale production networks,” in *Proceedings of the 9th USENIX Conference on Operating Systems Design and Implementation*, ser. OSDI’10, USA: USENIX Association, Oct. 4, 2010, pp. 351-364.
20. L. Poutievski, O. Mashayekhi, J. Ong, et al., ”Jupiter evolving: Transforming google’s datacenter network via optical circuit switches and software-defined networking,” in *Proceedings of the ACM SIGCOMM 2022 Conference*, ser. SIGCOMM ’22, New York, NY, USA: Association for Computing Machinery, Aug. 22, 2022, pp. 66-85.
21. A. Shaikh and J. George, SDN in the management plane: Openconfig and streaming telemetry, https://research.google/pubs/sdn-in-the-management-plane-openconfig-and-streaming-telemetry/, 2015.
22. Open Compute Project, SAI - Switch Abstraction Interface, GitHub Repository: https://github.com/opencomputeproject/SAI.
23. sonic-net, SONiC - Software for Open Networking in the Cloud, GitHub Repository: https://github.com/sonic-net/SONiC.
24. H. H. Bazzaz, Y. Bi, W. Pang, et al., ”Preventing network bottlenecks: Accelerating datacenter services with Hotspot-Aware placement for compute and storage,” in *22nd USENIX Symposium on Networked Systems Design and Implementation (NSDI 25)*, Philadelphia, PA: USENIX Association, Apr. 2025, pp. 317-333.
25. A. Kumar, S. Jain, U. Naik, et al., ”BwE: Flexible, hierarchical bandwidth allocation for WAN distributed computing,” in *Proceedings of the 2015 ACM Conference on Special Interest Group on Data Communication*, ser. SIGCOMM ’15, New York, NY, USA: Association for Computing Machinery, Aug. 17, 2015, pp. 1-14.
26. N. Cardwell, Y. Cheng, C. S. Gunn, S. H. Yeganeh, and V. Jacobson, ”BBR: Congestion-based congestion control,” 2, vol. 60, New York, NY, USA: Association for Computing Machinery, Jan. 23, 2017, pp. 58-66.
27. D. Wetherall, A. Kabbani, V. Jacobson, et al., ”Improving network availability with Protective ReRoute,” in *Proceedings of the ACM SIGCOMM 2023 Conference*, ser. ACM SIGCOMM ’23, New York, NY, USA: Association for Computing Machinery, Sep. 1, 2023, pp. 684-695.
28. K.-K. Yap, M. Motiwala, J. Rahe, et al., ”Taking the edge off with Espresso: scale, reliability and programmability for global internet peering,” in *Proceedings of the Conference of the ACM Special Interest Group on Data Communication*, ser. SIGCOMM ’17, New York, NY, USA: Association for Computing Machinery, Aug. 7, 2017, pp. 432-445.
29. Google Cloud, *Cloud Armor DoS Protection & WAF*, https://cloud.google.com/security/products/armor.
30. N. Jouppi, G. Kurian, S. Li, et al., ”TPU v4: An optically reconfigurable supercomputer for machine learning with hardware support for embeddings,” in *Proceedings of the 50th Annual International Symposium on Computer Architecture*, ser. ISCA ’23, New York, NY, USA: Association for Computing Machinery, Jun. 17, 2023, pp. 1-14.
31. Y. Zu, A. Ghaffarkhah, H.-V. Dang, et al., ”Resiliency at scale: Managing Google’s TPUv4 machine learning supercomputer,” in *21st USENIX Symposium on Networked Systems Design and Implementation (NSDI 24)*, 2024, pp. 761-774.
32. A. Krentsel, N. Saran, B. Koley, et al., ”A decentralized SDN architecture for the WAN,” in *Proceedings of the ACM SIGCOMM 2024 Conference*, ser. ACM SIGCOMM ’24, New York, NY, USA: Association for Computing Machinery, Aug. 4, 2024, pp. 938-953.
33. E. Brewer, L. Ying, L. Greenfield, R. Cypher, and T. T’so, *Disks for data centers*, https://research.google/pubs/disks-for-data-centers/, 2016.
34. C. Sabol and S. Desai, *SmartFTL architecture for SSDs*, https://www.youtube.com/watch?v=3O3zDrpt3uM, 2021.
35. Open Compute Project, *OCP Hybrid SMR Product Requirements*, https://www.opencompute.org/files/OCP18-Hybrid-SMR-Product-Requirements.pdf, 2018.
36. S. Li, X. Wang, F. Kalim, et al., ”Thunderbolt: Throughput-optimized, quality-of-service-aware power capping at scale,” in *14th USENIX Symposium on Operating Systems Design and Implementation (OSDI20)*, 2020, pp. 1241-1255.
37. K. Rzadca, P. Findeisen, J. Swiderski, et al., ”Autopilot: Workload autoscaling at Google,” in *Proceedings of the 15th European Conference on Computer Systems*, ser. EuroSys ’20, New York, NY, USA: Association for Computing Machinery, Apr. 17, 2020, pp. 1-16.
38. A. Mirhoseini, A. Goldie, M. Yazgan, et al., ”A graph placement methodology for fast chip design,” *Nature*, vol. 594, no. 7862, pp. 207-212, 2021.
39. DeepMind, *How AlphaChip transformed computer chip design*, DeepMind Blog: https://deepmind.google/discover/blog/how-alphachip-transformed-computer-chip-design/.

**Open Access** This chapter is licensed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license and indicate if changes were made.
The images or other third party material in this chapter are included in the chapter’s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the chapter’s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.